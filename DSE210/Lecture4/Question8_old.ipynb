{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Calculate Pi, the fraction of documents that belong to each class j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labels for train data\n",
    "train_label = open('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.label', 'r')\n",
    "\n",
    "# define dictionary for pi_j where j is each class 1,2,..., 20\n",
    "pi = {}\n",
    "for i in range(1,21):\n",
    "    pi[i] = 0\n",
    "\n",
    "# count the occurrence of each class j\n",
    "lines = train_label.readlines()\n",
    "for line in lines:\n",
    "    j_val = int(line.split()[0])\n",
    "    pi[j_val] += 1\n",
    "\n",
    "# divide each class count for the total number of documents\n",
    "for j in pi.keys():\n",
    "    pi[j] /= len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.04259472890229834,\n",
       " 2: 0.05155736977549028,\n",
       " 3: 0.05075871860857219,\n",
       " 4: 0.05208980388676901,\n",
       " 5: 0.051024935664211554,\n",
       " 6: 0.052533498979501284,\n",
       " 7: 0.051646108794036735,\n",
       " 8: 0.052533498979501284,\n",
       " 9: 0.052888455053687104,\n",
       " 10: 0.0527109770165942,\n",
       " 11: 0.05306593309078002,\n",
       " 12: 0.0527109770165942,\n",
       " 13: 0.05244475996095483,\n",
       " 14: 0.0527109770165942,\n",
       " 15: 0.052622237998047744,\n",
       " 16: 0.05315467210932647,\n",
       " 17: 0.04836276510781791,\n",
       " 18: 0.05004880646020055,\n",
       " 19: 0.04117490460555506,\n",
       " 20: 0.033365870973467035}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Create dataframe for training data and training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data and labels\n",
    "train_data = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.data', delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "train_labels = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.label', names=['classIdx'])\n",
    "\n",
    "# get array for documents and class indexes\n",
    "docIdx = train_data['docIdx']\n",
    "classIdx = train_labels['classIdx']\n",
    "\n",
    "# match data and label size by increasing label length\n",
    "new_train_labels = []\n",
    "i = 0\n",
    "for index in range(len(docIdx)-1):\n",
    "    new_train_labels.append(classIdx[i])\n",
    "    if docIdx[index] != docIdx[index+1]:\n",
    "        i += 1\n",
    "new_train_labels.append(classIdx[i])\n",
    "\n",
    "# create dataframe with both train and label\n",
    "df = train_data\n",
    "df['classIdx'] = new_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docIdx</th>\n",
       "      <th>wordIdx</th>\n",
       "      <th>count</th>\n",
       "      <th>classIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docIdx  wordIdx  count  classIdx\n",
       "0       1        1      4         1\n",
       "1       1        2      2         1\n",
       "2       1        3     10         1\n",
       "3       1        4      4         1\n",
       "4       1        5      2         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Use Laplace Smoothing to calculate the probability of each word per class, Pjw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_word_per_class(df):\n",
    "    #Alpha value for smoothing\n",
    "    a = 0.001\n",
    "\n",
    "    #Calculate probability \n",
    "    pb_jw = df.groupby(['classIdx','wordIdx'])\n",
    "    pb_j = df.groupby(['classIdx'])\n",
    "    Pr =  (pb_jw['count'].sum() + a) / (pb_j['count'].sum() + 61188 + 1)    \n",
    "\n",
    "    #Unstack series\n",
    "    Pr = Pr.unstack()\n",
    "\n",
    "    #Replace NaN or columns with 0 as word count with a/(count+|V|+1)\n",
    "    for c in range(1,21):\n",
    "        Pr.loc[c,:] = Pr.loc[c,:].fillna(a/(pb_j['count'].sum()[c] + 61188 + 1))\n",
    "\n",
    "    #Convert to dictionary for greater speed\n",
    "    return Pr.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pr_dict = Prob_word_per_class(df)\n",
    "len(Pr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Define Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multinomial_NB(df):\n",
    "  \n",
    "    #Using dictionaries for greater speed\n",
    "    df_dict = df.to_dict()\n",
    "    new_dict = {}\n",
    "    prediction = []\n",
    "    \n",
    "    #new_dict = {docIdx : {wordIdx: count},....}\n",
    "    for idx in range(len(df_dict['docIdx'])):\n",
    "        docIdx = df_dict['docIdx'][idx]\n",
    "        wordIdx = df_dict['wordIdx'][idx]\n",
    "        count = df_dict['count'][idx]\n",
    "        try: \n",
    "            new_dict[docIdx][wordIdx] = count \n",
    "        except:\n",
    "            new_dict[df_dict['docIdx'][idx]] = {}\n",
    "            new_dict[docIdx][wordIdx] = count\n",
    "\n",
    "    #Calculating the scores for each doc\n",
    "    for docIdx in range(1, len(new_dict)+1):\n",
    "        score_dict = {}\n",
    "        #Creating a probability row for each class\n",
    "        for classIdx in range(1,21):\n",
    "            score_dict[classIdx] = 1\n",
    "            #For each word:\n",
    "            for wordIdx in new_dict[docIdx]:\n",
    "               \n",
    "                try:\n",
    "                    probability=Pr_dict[wordIdx][classIdx]         \n",
    "#                     power = np.log(1+ new_dict[docIdx][wordIdx])   \n",
    "                    power = new_dict[docIdx][wordIdx]    \n",
    "\n",
    "                    score_dict[classIdx]+=power*np.log(probability)\n",
    "                except:\n",
    "                    #Missing V will have log(1+0)*log(a/16689)=0 \n",
    "                    score_dict[classIdx] += 0     \n",
    "                    \n",
    "            #Multiply final with pi         \n",
    "            score_dict[classIdx] +=  np.log(pi[classIdx])                          \n",
    "\n",
    "        #Get class with max probabilty for the given docIdx \n",
    "        max_score = max(score_dict, key=score_dict.get)\n",
    "        prediction.append(max_score)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Evaluate the performance of the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_error(predict, labels):\n",
    "    \n",
    "    correct = 0\n",
    "    for i,j in zip(predict, test_labels):\n",
    "        if i == j:\n",
    "            correct +=1\n",
    "    \n",
    "    perc_error = 100*(1-(correct/len(test_labels)))\n",
    "    \n",
    "    return round(perc_error,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/test.data', delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "test_labels = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/test.label', names=['classIdx'])\n",
    "test_labels = test_labels.classIdx.tolist()\n",
    "\n",
    "predict = Multinomial_NB(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.2385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_error(predict, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
