{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Text Classification Using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculate Pi, the fraction of documents that belong to each class j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate pi\n",
    "def fraction_doc_classj(labels):\n",
    "    \"\"\"\n",
    "    Find the class probabilities pi for each class j\n",
    "    \"\"\"\n",
    "    \n",
    "    # define dictionary for pi_j where j is each class 1,2,..., 20\n",
    "    pi = {}\n",
    "    No_Classes = 20\n",
    "    for j in range(1,No_Classes+1):\n",
    "        pi[j] = 0\n",
    "\n",
    "    # count occurrences for a dataframe type variable\n",
    "    if isinstance(labels, pd.core.series.Series):\n",
    "        lines = list(labels)\n",
    "    else:\n",
    "        lines = labels.readlines()\n",
    "    \n",
    "    # count the occurrence of each class j\n",
    "    for line in lines:\n",
    "        if isinstance(labels, pd.core.series.Series):\n",
    "            j_val = line\n",
    "        else:        \n",
    "            j_val = int(line.split()[0])\n",
    "        pi[j_val] += 1\n",
    "\n",
    "    # divide each class count for the total number of documents\n",
    "    for j in pi.keys():\n",
    "        pi[j] /= len(lines)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.04259472890229834, 2: 0.05155736977549028, 3: 0.05075871860857219, 4: 0.05208980388676901, 5: 0.051024935664211554, 6: 0.052533498979501284, 7: 0.051646108794036735, 8: 0.052533498979501284, 9: 0.052888455053687104, 10: 0.0527109770165942, 11: 0.05306593309078002, 12: 0.0527109770165942, 13: 0.05244475996095483, 14: 0.0527109770165942, 15: 0.052622237998047744, 16: 0.05315467210932647, 17: 0.04836276510781791, 18: 0.05004880646020055, 19: 0.04117490460555506, 20: 0.033365870973467035}\n"
     ]
    }
   ],
   "source": [
    "# read labels for train data\n",
    "train_label = open('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.label', 'r')\n",
    "\n",
    "pi = fraction_doc_classj(train_label)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Create dataframe for training data and training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to merge both\n",
    "def merge_data_labels_df(data, labels):\n",
    "    \"\"\"\n",
    "    Create dataframe by increasing size of labels to match data\n",
    "    \"\"\"\n",
    "    # get array for documents and class indexes\n",
    "    docIdx = train_data['docIdx']\n",
    "    classIdx = train_labels['classIdx']\n",
    "\n",
    "    # match data and label size by increasing label length\n",
    "    new_train_labels = []\n",
    "    i = 0\n",
    "    for idx in range(len(docIdx)-1):\n",
    "        new_train_labels.append(classIdx[i])\n",
    "        if docIdx[idx] != docIdx[idx+1]:\n",
    "            i += 1\n",
    "    new_train_labels.append(classIdx[i])\n",
    "\n",
    "    # create dataframe with both train and label\n",
    "    df = train_data\n",
    "    df['classIdx'] = new_train_labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docIdx</th>\n",
       "      <th>wordIdx</th>\n",
       "      <th>count</th>\n",
       "      <th>classIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docIdx  wordIdx  count  classIdx\n",
       "0       1        1      4         1\n",
       "1       1        2      2         1\n",
       "2       1        3     10         1\n",
       "3       1        4      4         1\n",
       "4       1        5      2         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train data and labels\n",
    "train_data = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.data', \n",
    "                         delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "train_labels = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/train.label', \n",
    "                           names=['classIdx'])\n",
    "\n",
    "df = merge_data_labels_df(train_data,train_labels)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Use Laplace Smoothing to calculate the probability of each word per class, Pjw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_word_per_class(df, remove_stopwords, stopwordsIdx):\n",
    "    \"\"\"\n",
    "    Find Pjw and apply Laplace smoothing with alpha parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove stopwords if wanted\n",
    "    if remove_stopwords:\n",
    "        df = df[~df.wordIdx.isin(idx)]\n",
    "    \n",
    "    # parameters\n",
    "    alpha = 0.001\n",
    "    No_class = 20\n",
    "    \n",
    "    # calculate the fraction of the concatenated doccuments occupied by w\n",
    "    word_wj = df.groupby(['classIdx','wordIdx'])\n",
    "    word_j = df.groupby(['classIdx'])\n",
    "    Pr_jw =  (word_wj['count'].sum() + alpha) / (word_j['count'].sum() + 61188 + 1)    \n",
    "    Pr_jw = Pr_jw.unstack()\n",
    "                \n",
    "    # replace missing values with the constant alpha/(count+|V|+1)\n",
    "    # where 'count' is how often w occurs and |V| is the size of the vocabulary\n",
    "    for j in range(1,No_class+1):\n",
    "        Pr_jw.loc[j,:] = Pr_jw.loc[j,:].fillna(alpha/(word_j['count'].sum()[j] + 61188 + 1))\n",
    "\n",
    "    return Pr_jw.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pr_jw = Prob_word_per_class(df, remove_stopwords=False, stopwordsIdx = [])\n",
    "len(Pr_jw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Routine with Naive Bayes to Classify a New Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multinomial_NB(df, pi, Pr_jw, log_replacement = False):\n",
    "    \"\"\"\n",
    "    Model Function for Multinomial Naive Bayes\n",
    "    \n",
    "    Inputs:\n",
    "    - df: columns = ['docIdx', 'wordIdx', 'count']\n",
    "    \n",
    "    Model Equation (in Log scale):\n",
    "    armax_j  log(pi_j) + Sigma Sum (from w = 1 to |V|) X_i * log (Pr_jw)\n",
    "    \n",
    "    where,\n",
    "    - pi_j = fraction of documents that belong to that class j\n",
    "    - Pr_jw = fraction of each word for a given class\n",
    "    - j = class\n",
    "    - w = each word from vocabulary\n",
    "    - |V| = lenght of vocabulary\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert dataframe to dict with format for faster speed\n",
    "    df_dict = df.to_dict()\n",
    "    data_dict = {}\n",
    "    for df_row in df_dict['docIdx'].keys():\n",
    "        doc_index = df_dict['docIdx'][df_row]\n",
    "        word_index = df_dict['wordIdx'][df_row]\n",
    "    \n",
    "        try: \n",
    "            data_dict[doc_index][word_index] = df_dict['count'][df_row]\n",
    "        except:\n",
    "            data_dict[df_dict['docIdx'][df_row]] = {}\n",
    "            data_dict[doc_index][word_index] = df_dict['count'][df_row]\n",
    "\n",
    "    # use equation to find the score and take arg max as the prediction\n",
    "    predicted = []\n",
    "    for doc in data_dict.keys(): # loop over every document\n",
    "        score_dict = {}     \n",
    "        No_class = 20\n",
    "        for class_ in range(1,No_class+1): # calculate a score for each class\n",
    "            score_dict[class_] = 1 # initialize score value\n",
    "            for word in data_dict[doc]: # loop over every word in the document\n",
    "               \n",
    "                # calculate right-hand side (Sigma sum) of the model equation\n",
    "                try:\n",
    "                    # calculate with log replacement log(1+f)\n",
    "                    if log_replacement:\n",
    "                        score_dict[class_] += np.log(1+data_dict[doc][word]) * np.log(Pr_jw[word][class_])\n",
    "                    else: # else do just f\n",
    "                        score_dict[class_] += data_dict[doc][word] * np.log(Pr_jw[word][class_])\n",
    "                except:\n",
    "                    # missing words in the vocabulary yield a zero score, X_i = 0\n",
    "                    score_dict[class_] += 0     \n",
    "                    \n",
    "            # add left-hand side (log pi) of the model equation \n",
    "            score_dict[class_] +=  np.log(pi[class_])                          \n",
    "\n",
    "        # get class with max probability in each document\n",
    "        max_score = max(score_dict, key=score_dict.get)\n",
    "        predicted.append(max_score)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Evaluate the performance of the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_error(prediction, labels):\n",
    "    \"\"\"\n",
    "    Find predicted error rate\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i,j in zip(prediction, labels):\n",
    "        if i == j:\n",
    "            correct +=1\n",
    "    \n",
    "    perc_error = 100*(1-(correct/len(labels)))\n",
    "    \n",
    "    return round(perc_error,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/test.data', \n",
    "                        delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "test_labels = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/20news-bydate/matlab/test.label', \n",
    "                          names=['classIdx'])\n",
    "\n",
    "test_labels = test_labels.classIdx.tolist()\n",
    "\n",
    "predict = Multinomial_NB(test_data, pi, Pr_jw, log_replacement = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.238508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_error(predict, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) split data into smaller training set and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = train_test_split(df[['docIdx','wordIdx','count']], \n",
    "                                                                  df['classIdx'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate validation set labels to match predicted size\n",
    "new_val_labels = pd.DataFrame({'docIdx': val_data['docIdx'], 'classIdx':val_labels})\n",
    "new_val_labels.drop_duplicates(keep = 'first', inplace = True)\n",
    "new_val_labels = new_val_labels['classIdx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) implement strategies to improve earlier model\n",
    "a) Replacing the frequency f of a word in a document by log(1 + f) <br>\n",
    "b) Removing Stopwords\n",
    "\n",
    "#### Different Models to evaluate with validation data\n",
    "    1) frequency f\n",
    "    2) frequency f and removing stop words\n",
    "    3) frequency log(1+f)\n",
    "    4) frequency log(1+f) and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# import stopwords list from nltk libraries\n",
    "# nltk.download()\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the stop word indexes from vocabulary\n",
    "def get_stopwords_idx(stopwords_list):\n",
    "    \"\"\"\n",
    "    Use vocabulary .txt file from 20 Newsgroups data set\n",
    "    \"\"\"\n",
    "    \n",
    "    # read current vocabulary\n",
    "    V = pd.read_csv('/Users/gio/Documents/DSE/2019-rgm001/DSE210/Lecture4/vocabulary.txt', names=['word'])\n",
    "    \n",
    "    # find stopwords index from the vocabulary\n",
    "    stopwords_idx = V[V.word.isin(stopwords_list)].index\n",
    "\n",
    "    return stopwords_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# define pi\n",
    "pi = fraction_doc_classj(train_labels)\n",
    "\n",
    "# define dataframe for train data\n",
    "df_train = train_data\n",
    "df_train['classIdx'] = train_labels \n",
    "\n",
    "# define probability of each word per class\n",
    "Pr_jw = Prob_word_per_class(df_train, remove_stopwords=False, stopwordsIdx = [])\n",
    "idx = get_stopwords_idx(stopwords_list)\n",
    "Pr_jw_wo_stopwords = Prob_word_per_class(df_train, remove_stopwords=True, stopwordsIdx = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use validation dataset on all 4 models listed above\n",
    "\n",
    "predict_1 = Multinomial_NB(val_data, pi, Pr_jw, log_replacement = False)\n",
    "predict_2 = Multinomial_NB(val_data, pi, Pr_jw_wo_stopwords, log_replacement = False)\n",
    "predict_3 = Multinomial_NB(val_data, pi, Pr_jw, log_replacement = True)\n",
    "predict_4 = Multinomial_NB(val_data, pi, Pr_jw_wo_stopwords, log_replacement = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) frequency f\n",
      "Error Rate = 28.425358\n",
      "\n",
      "2) frequency f and removing stop words\n",
      "Error Rate = 28.318663\n",
      "\n",
      "3) frequency log(1+f)\n",
      "Error Rate = 28.051925\n",
      "\n",
      "4) frequency log(1+f) and removing stop words\n",
      "Error Rate = 28.185294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the error for each of the 4 model options above\n",
    "models = ['frequency f', 'frequency f and removing stop words', 'frequency log(1+f)', \n",
    "          'frequency log(1+f) and removing stop words']\n",
    "predictions = [predict_1, predict_2, predict_3, predict_4]\n",
    "\n",
    "i = 1\n",
    "for m, p in zip(models, predictions):\n",
    "    error = predict_error(p, list(new_val_labels))\n",
    "    print(str(i) + ') ' + str(m) + '\\nError Rate = ' + str(error) + '\\n')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Evaluate the final model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model #3 above \"frequenct log(1+f)\" as it gave the best error rate with the validation set\n",
    "final_predict = Multinomial_NB(test_data, pi, Pr_jw, log_replacement = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.918055"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate error for final model\n",
    "predict_error(final_predict, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
