{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final - Raul G. Martinez (PID: A12461871)\n",
    "# DSE 220: Machine Learning \n",
    "# Due Date: 06/12 11:59 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
<<<<<<< HEAD
    "This report aims to provide a Machine Learning approach to predict how useful an Amazon Review is going to be, the data used in this analysis contains a total of 200,000 reviews in the years of 2003 to 2014 from a total of 39,249 reviewers and 19,913 products. Natural language processing techniques were used to learn new features from the review body text and summary text data, in addition to feature engineering in many other numerical features. Then, a Random Forest Regressor Model was implemented to predict the ratio between the number of helpful votes with the total number of votes for each review; train and validation split was done 80% and 20% respectively. After generating a baseline model with three fundamental features (itemID, reviewerID, and outOf_feature), model optimization was achieved with feature selection in two ways. First, each new feature was tested individually along with the baseline features and their model performance was evaluated with MAE (Mean Absolute Error) and MSE (Mean Squared Error), and any feature performing worst than the baseline was excluded. Second, an ablation study was performed by removing one feature at time, starting with the highest MAE, and the group of features yielding the lowest MAE were selected for downstream optimization. Next, hyper-parameter tunning was performed on max_depth and n_estimators parameters and the model with the lowest MAE was again selected. After final model selection, the confusion matrix was computed to evaluate the model's ability to classify the number of helpful votes; precision and recal metrics were observed in detail. All in all, this analysis and implementation emphasizes on feature engineering and feature selection rather than model or hyper-parameter optimization. A total of 36 new features were generated, tested, and selected to provide an automated optimal performance where the best MAE was found to be 0.15479 for the train dataset and 0.16357 for 60% of the test dataset.  "
=======
    "This report aims to provide a Machine Learning approach to predict how useful an Amazon Review is going to be, the data used in this analysis contains a total of 200,000 reviews in the years of 2003 to 2014 from a total of 39,249 reviewers and 19,913 products. Natural language processing techniques were used to learn new features from the review body text and summary text data, in addition to feature engineering in many other numerical features. Then, a Random Forest Regressor Model was implemented to predict the ratio between the number of helpful votes with the total number of votes for each review; train and validation split was done 80% and 20% respectively. After generating a baseline model with three fundamental features (itemID, reviewerID, and outOf_feature), model optimization was achieved with feature selection in two ways. First, each new feature was tested individually along with the baseline features and their model performance was evaluated with MAE (Mean Absolute Error), and any feature performing worst than the baseline was excluded. Second, an ablation study was performed by removing one feature at time, starting with the highest MAE, and the group of features yielding the lowest MAE were selected for downstream optimization. Next, hyper-parameter tunning was performed on max_depth and n_estimators parameters and the model with the lowest MAE was again selected. After final model selection, the confusion matrix was computed to evaluate the model's ability to classify the number of helpful votes; precision and recal metrics were observed in detail. All in all, this analysis and implementation emphasizes on feature engineering and feature selection rather than model or hyper-parameter optimization. A total of 36 new features were generated, tested, and selected to provide an automated optimal performance where the best MAE was found to be 0.15479 for the train dataset and 0.16357 for 60% of the test dataset.  "
>>>>>>> 9893ae22b44e21c0da9bed011daea44655110af0
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Pruning\n",
    "\n",
    "The training data consists of 200,000 entries inside the compressed file 'train.json.gz', while the test data is stored also in a compressed file named 'test_Helpful.json.gz' and it contains 14,000 entries. Both datasets contain a total of 12 raw features summarized in the table below (observations are based on training data):\n",
    "\n",
    "| Raw Feature | Observations | \n",
    "| --- | ---  |\n",
    "| categoryID | unique values are 0, 1, 2, 3, and 4 |\n",
    "| categories | there are 1042 unique categories (i.e. 'Active Hoodies') forming 1847 unique lists, each review has a collection of lists |\n",
    "| itemID | there are a total of 19,913 unique items |\n",
    "| reviewerID | there are a total of 39,249 unique reviewers |\n",
    "| rating | values assigned are 1, 2, 3, 4, and 5. Their frequency increases monotonically with the number, 1 being the less frequent |\n",
    "| reviewText | the min number of characters is 0 and the max is 22,646 |\n",
    "| reviewHash | each review has a unique hash ID |\n",
    "| reviewTime | time goes from 2003 to 2014, the most reviews are observed in 2013 and 2014 |\n",
    "| summary | the min number of characters is 1 and the max is 201 |\n",
    "| unixReviewTime | there are 2,532 unique times |\n",
    "| helpful | it contains a dictionary with 'outOf' and 'nHelpful'. Votes 0 and 1 comprise of 68.5% and 14.3% from the total number of reviews |\n",
    "| price | 62.9% of the reviews have missing values, they were filled with -999 in this analysis|\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "Raw features were read in a dataframe for the train (raw) dataset (see table 1 in the report section) then split into train and validation, 80% and 20% respectively, in order to validate feature selection and model optimization. The newly defined train data was then pruned to only include reviews where the number of votes (helpful - outOf) is greater than zero, therefore, the original train data (after the split) was used to compute performance metrics while the newly filtered data was only used to train the model. This is because the entries equal to zero are always predicted zero by the regression model from multiplying predicted label times the known 'outOf' feature (with value zero). Better performance was found empirically when implementing this approach, it basically allows the model to learn on the remaining 31.5% of the data where the predictions are not given or easily predicted.\n",
=======
    "Raw features were read in a dataframe for the train (raw) dataset (see table 1 in the report section) then split into train and validation, 80% and 20% respectively, in order to validate feature selection and model optimization. The newly defined train data was then further filtered to only include reviews where the number of votes (helpful - outOf) is greater than zero, therefore, the original train data (after the split) was used to compute performance metrics while the newly filtered data was only used to train the model. This is because the entries equal to zero are always predicted zero by the regression model from multiplying predicted label times the known 'outOf' feature (with value zero). Better performance was found empirically when implementing this approach, it basically allows the model to learn on the remaining 31.5% of the data where the predictions are not given or easily predicted.\n",
>>>>>>> 9893ae22b44e21c0da9bed011daea44655110af0
    "\n",
    "Lastly, the labels are extracted from the 'helpful' column and are defined as the ratio between 'nHelpful' and 'outOf'. Divisio by zero is prevented with the approach mentioned above of removing entries with votes equal to zero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
<<<<<<< HEAD
    "A total of 36 new features were generated as candidates to be included in the final model for test data predictions. The table below summarizes the new feature names (when applicable), the raw features used to generate it (when applicable), and lastly some description about it. Positive and negative word lists are taken from reference 1 and 2 below, and the list of stop words was downloaded from the NLTK library on python. A couple features were also inspired from reference 3. \n",
=======
    "A total of 36 new features were generated as candidates to be included in the final model for test data predictions. The table below summarizes the new feature name (when applicable), the raw features used to generate it (when applicable), and lastly some description about it. Positive and negative word lists are taken from reference 1 and 2 below, and the list of stop words was downloaded from the NLTK library on python. A couple features were also inspired from reference 3. \n",
>>>>>>> 9893ae22b44e21c0da9bed011daea44655110af0
    "\n",
    "| Feature Name | Features Used From Raw Data | Description |\n",
    "| --- | --- | --- |\n",
    "| itemID | NA | **Baseline Feature** - ID for each product or item |\n",
    "| reviewerID | NA | **Baseline Feature** - ID for each reviewer or user |\n",
    "| outOf_feature | helpful | **Baseline Feature** - Number of votes |\n",
    "| categoryID | NA | IDs for the collection of category lists, the unique IDs are 0, 1, 2, 3, and 4 |\n",
    "| categories_count | categories | Number collection of category lists inside 'categories' column |\n",
    "| category_numtrans | categories | Each category list gets a unique ID, then numeric transformation is applied by summation of IDs|\n",
    "| rating | NA | Rating for the given review |\n",
    "| rating_deviation | rating | Deviation from the mean rating for each product |\n",
    "| itemID_helpfulRate | itemID, helpful | Helpful rate calculated for each item on labeled data |\n",
    "| itemID_numReviews | itemID | Number of reviews for each product |\n",
    "| reviewerID_helpfulRate | reviewerID, helpful | Helpful rate calculated for each reviewer on labeled data |\n",
    "| reviewerID_numReviews | reviewerID | Number of reviews for each reviewer |\n",
    "| price | NA | Price for the item being reviewed, missing values are assigned the value -999 |\n",
    "| reviewText_count_words (or summary) | reviewText, summary | Count for the number of words, stop words removed |\n",
    "| reviewText_posWordCount (or summary) | reviewText, summary | Count for the number of positive words found, with pre-defined list of positive words |\n",
    "| reviewText_negWordCount (or summary) | reviewText, summary | Count for the number of negative words found, with pre-defined list of negative words |\n",
    "| reviewText_posWordRate (or summary) | reviewText, summary | Positive word rate for the text, with pre-defined list of positive words |\n",
    "| reviewText_negWordRate (or summary) | reviewText, summary | Negative word rate for the text, with pre-defined list of negative words |\n",
    "| reviewText_count_char (or summary) | reviewText, summary | Count for the number of characters |\n",
    "| reviewText_count_punctu (or summary) | reviewText, summary | Count for the number of punctuation symbols |\n",
    "| reviewText_count_firstCapital (or summary) | reviewText, summary | Count for the number of words where the first letter is capital |\n",
    "| reviewText_avgWordLength (or summary) | reviewText, summary | Average word length for the text, stop words removed |\n",
    "| reviewText_capitalwords (or summary) | reviewText, summary | Count for the number of capital words in the text |\n",
    "| reviewText_ExclQue_countchar (or summary) | reviewText, summary | Count for the number of exclamation and question symbols in the text|\n",
    "| reviewText_PunctChar_ratio (or summary) | reviewText, summary | Ratio for the count of punctuation symbols to characters in the text |\n",
    "| summary_reviewText_charRatio  | reviewText, summary | Ratio for the count of characters present in summary text by reviewText |\n",
    "| summary_reviewText_wordsRatio | reviewText, summary | Ratio for the count of words present in summary text by reviewText |\n",
    "| unixReviewTime | NA | Time elapsed in Unix time before the review was posted |\n",
    "| unixReviewTime_delta_firstreview | unixReviewTime | Time elapsed in Unix time from first review for each item |\n",
    "| unixReviewTime_delta_lastreview | unixReviewTime | Time elapsed in Unix time from the last review for each item |\n",
    "| votes_time | helpful, unixReviewTime | Ratio between the number of votes and the time elapsed in Unix time |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Multiple regression models were evaluated including Linear Regression, Multi-Later Perceptron Regressor, Decision Trees, and Random Forest Regressor from different sklearn libraries. After parameter tunning and different feature testing, the top performer and simpler to implement turned out to be Random Forest Regressor; data not shown in this report. The model is trained to predict a regressor label, which is the ratio between 'nHelpful' by 'outOf', for every individual review entry. The regressor label was then transformed to a classification label by multiplying it with the known 'outOf' values and rounding to the nearest integer; rounding was shown to improve MAE consistently (data not shown in the report). Accuracy was then calculated for the classification and only reported in the data table 2 from the report section. In summary, a simple approach was selected for model selection in this analysis in order to spend more time with feature engineering and feature selection, after all, experimenting with the features showed higher contribution for error predictions MAE and MSE as opposed to model optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
<<<<<<< HEAD
    "A two step approach was taken to subselect features, both used random forest models with hyper-parameters 'max_depth'=10 and 'n_estimators'=100; these were found to be relatively stable and fast to test empirically. The first approach compares the performance of a baseline model with only three features (itemID, reviewerID, and outOf_feature) with other 4 feature models by combining the baseline features and adding one of the 40 feature candidates (new and existing features) at a time. The top performing models are then ranked according to lower MAE (ascending) on the validation dataset and the features whose models performed lower than the baseline model are eliminated. Table 2 in the code section illustrates the approach, in this example a total of 7 features were eliminated and 33 selected for downstream selection. Next, the second approach aims to continue feature subselection by performing an ablation study, where features are eliminated one-by-one and model performance is measured. The features previously selected on baseline comparison are ranked by MAE (descending) and one feature is eliminated at a time, starting with no features eliminated to the first with the highest MAE and further continuing to eliminate all features. Again, the criteria to select a group of features is the test case with the lowest MAE on the validation dataset. Figure 1 shows scatter plots for MAE and MSE, both error metrics trend similarly and also clearly illustrate how model performance decreases as the number of eliminated features increases, the lowest MAE for this datset occured when 11 were removed, therefore a total of 22 features were finally selected for downstream model evaluation. \n",
=======
    "A two step approach was taken to subselect features, both used random forest models with hyper-parameters 'max_depth'=10 and 'n_estimators'=100; these were found to be relatively stable and fast to test empirically. The first approach compares the performance of a baseline model with only three features (itemID, reviewerID, and outOf_feature) with other 4 feature models by combining the baseline features and adding one of the 40 feature candidates (new and existing features) at a time. The top performing models are then ranked according to lower MAE (ascending) on the validation dataset and the features whose models performed lower than the baseline model are eliminated. Table 2 in the code section illustrates the approach, in this example a total of 7 features were eliminated and 33 selected for downstream selection. Next, the second approach aims to continue feature subselection by performing an ablation study, where features are eliminated one-by-one and model performance is measured. The features previously selected on baseline comparison are ranked by MAE descending and one feature is eliminated at a time, starting with no features eliminated to the first with the highest MAE and further continuing to eliminate all features. Again, the criteria to select a group of features is the test case with the lowest MAE on the validation dataset. Figure 1 shows scatter plots for MAE and MSE, both error metrics trend similarly and also clearly illustrate how model performance decreases as the number of eliminated features increases, the lowest MAE for this datset occured when 11 were removed, therefore a total of 22 features were finally selected for model evaluation. \n",
>>>>>>> 9893ae22b44e21c0da9bed011daea44655110af0
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization and Evaluation\n",
    "\n",
    "Many features were generated and then narrowed down to only subselect the ones with optimal performance. After selecting the final features, the same model used for testing above was then optimized by tuning the hyper-parameters 'max_depth' and 'n_estimators'; these parameters were found to be the most significant across 6 different ones tested by performing an expensive Randomized Search Cross-Validation with sklearn model_selection library (not shown in this report). The values 10 and 12 are tested for max_depth, and the values 100, 200, 400, and 600 for n_estimators. By testing every possible scenario, the optimal combination was found by taking the one with the lowest MAE on the validation dataset. To illustrate this approach, a printout from the model is shown in the 'Hyperparameter Tuning' part from the code section, where the optimal parameters were found to be 12 for 'max_depth' and 200 for 'n_estimators' with a score of 0.172575 for MAE on the validation dataset. \n",
    "\n",
    "To further evaluate the model's ability to classify, the confusion matrix was computed for the optimal predictions on the validation dataset. More evaluation metrics for the classes were also calculated such as True Positive Rate (recall), True Negative Rate, Precision, False Positive Rate, False Negative Rate, and Accuracy. Table 3 in the code section summarizes the results for these metrics for a total of 122 different classes. Is important to note that some labels show NaN values as the prediction rate, since not all predicted labels exist in the dataset and are marked as False Positives, also how accuracy is not a good metric for this analysis as a value of greater than 0.9 for every feature does not seem to be real. Conversely, when looking at precision and recall (see Figure 2) there is something interesting happening, it basically shows how the performance of both metrics is well correlated with label value magnitudes; or possibly label ranges. For instance, labels with values less than 2 have really good precision and recall (with greater than 0.7) and it then decreases to approximately 0.1 to 0.5 for labels with values around 3 to 50, and finally almost every label greater than 50 has precision and recall of zero. This behavior is not very surprising and somewhat expected due to the nature of the predictions made in the regression model and data inconsistency for the distribution of number of votes in the training set; for example, larger number of votes for each review are significantly less common, and to put it in perspective there are only around 350 out of 200,000 reviews where the number of helpful votes is greater than 50. Additionally, the model is very good at predicting smaller values because of the rounding approach used for integers which basically reduces the error on the prediction, and again, performance progressively reduces with medium size values and it finally completely breaks down for larger value labels and is no longer useful. In summary, this model has the potential to generate good predictions when the number of votes is very small, however for predicting larger ranges such as 0 to 384 votes it will likely face limitations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To summarize, a random forest regressor model was presented in this report to predict the number of helpful votes for Amazon reviews. A total of 36 features were learned, tested, and subselected by comparing model performance with baseline features and by performing an ablation study on a selected group of features; as a matter of fact, most of the time spent in this analysis was around the former two steps along with natural language processing, feature engineering, and data exploration. Next, model optimization was done with hyper-parameter tunning for two variables which are 'max_depth' and 'n_estimators'. And lastly, performance metrics such as precision and recall where used to assess model performance on the validation dataset. The final model obtained an MAE of 0.15479 for the training dataset and for 60% of the testing dataset the MAE was found to be 0.16357, the error for the remaining 40% of the test dataset is not reported in this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Steps\n",
    "\n",
    "The approach presented above revealed a significant amount of new features and information from the raw data, however, the results seem to show that a single Random Forest Regressor is not sufficient for capturing most of the patterns in the data. Therefore, as next steps it would be useful to use multiple models, either implemented individually or together as an averaged prediction, that could possibly capture information better whether is through classification or regression. For example, a logistic regression model could be used to classify binary labels that occur very frequently such as 1 and 2 (not zero because it stays the same). Similarly, other models could be used to predict different ranges for the number of total votes such as 5 to 10 or even for greater than 50, depending on how they perform during testing. Lastly, the use of ensemble methods could also be considered for model optimization, some techniques widely used are bagging and boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, Washington, USA.\n",
    "2. Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\" Proceedings of the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan.\n",
    "3. Song, Xia. “Predict Amazon Review Helpfulness WihtXgboost, Neural Network, and LSTM Neural Network.” Medium, Medium, 11 Aug. 2019, medium.com/@songxia.sophia/predict-amazon-review-helpfulness-wihtxgboost-neural-network-and-lstm-neural-network-837a1da44f49."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse raw data\n",
    "\n",
    "\"\"\"\n",
    "These functions parse data from compressed files.\n",
    "\"\"\"\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosNegWords_count_Rate(text):\n",
    "        \n",
    "    \"\"\"\n",
    "    This function finds the positive and negative word rates for the text by:\n",
    "        - using pre-defined lists of positive and negative words\n",
    "        - making all words lower-case\n",
    "        - removes blank spaces and punctuations\n",
    "    \"\"\"\n",
    "        \n",
    "    # import positive and negative word lists, define as set for higher efficiency\n",
    "    posWords_list = set([i.strip() for i in open(\"positive-words.txt\", \"r\").readlines()])\n",
    "    negWords_list = set([i.strip() for i in open(\"negative-words.txt\", \"r\", encoding=\"ISO-8859-1\").readlines()])\n",
    "    \n",
    "    # count the number of positive and negative words present in each review text\n",
    "    dict_ = defaultdict(list)\n",
    "    for review_text in text:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "        \n",
    "        # count number of positive and negative words in each review\n",
    "        pos_count, neg_count = 0, 0\n",
    "        for word in words:\n",
    "            if word in posWords_list:\n",
    "                pos_count+=1\n",
    "            elif word in negWords_list:\n",
    "                neg_count+=1\n",
    "            else: \n",
    "                continue\n",
    "        \n",
    "        # save count and rate \n",
    "        if len(words) == 0: # prevent division by zero\n",
    "            dict_['pos_count'].append(-1)\n",
    "            dict_['neg_count'].append(-1)\n",
    "            dict_['pos_rate'].append(-1)\n",
    "            dict_['neg_rate'].append(-1)\n",
    "        else:\n",
    "            dict_['pos_count'].append(pos_count)\n",
    "            dict_['neg_count'].append(neg_count)\n",
    "            dict_['pos_rate'].append(pos_count/len(words))\n",
    "            dict_['neg_rate'].append(neg_count/len(words))\n",
    "    \n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NumWords(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function counts the number of words in the text by:\n",
    "        - words are converted to lower-case\n",
    "        - blank spaces and punctuations are removed\n",
    "        - stopwords are removed using NLTK library\n",
    "    \"\"\"\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in text:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # count number of words, excluding stopwords\n",
    "        word_count = 0\n",
    "        for word in words:\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                 word_count+=1\n",
    "                    \n",
    "        # save counts\n",
    "        list_.append(word_count)\n",
    "        \n",
    "    return list_      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_category_numtrans(category_lists):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assigns an ID number to each unique list of categories, \n",
    "    then those IDs are used to create a sum for the collection of lists \n",
    "    found in each product Category column. \n",
    "    \"\"\"\n",
    "    \n",
    "    # get unique category lists\n",
    "    lists = []\n",
    "    for i in category_lists:\n",
    "        for j in i:\n",
    "            lists.append(tuple(j))\n",
    "\n",
    "    # make dictionary with IDs\n",
    "    categorylists_dict = {k:v for v,k in enumerate(set(lists))}\n",
    "\n",
    "    # transform list occurance to numbers using dictionary \n",
    "    category_numtrans = []\n",
    "    for i in category_lists:\n",
    "        sum_ = 0\n",
    "        for j in i:\n",
    "            sum_ += categorylists_dict[tuple(j)]\n",
    "        category_numtrans.append(sum_)\n",
    "\n",
    "    # return transformation\n",
    "    return category_numtrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_helpfulRate(col):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the ratio between number \n",
    "    of helpfull votes and total votes.\n",
    "    \"\"\"\n",
    "    \n",
    "    allHelpful = []\n",
    "    colHelpful = defaultdict(list)\n",
    "\n",
    "    col_data = X_train_raw[col]\n",
    "    allHelpful = y_train_raw\n",
    "\n",
    "    for x,y in zip(col_data, allHelpful):\n",
    "         colHelpful[x].append(y)\n",
    "\n",
    "    averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "\n",
    "    rate = {}\n",
    "    for u in colHelpful:\n",
    "        totalU = sum([x['outOf'] for x in colHelpful[u]])\n",
    "        if totalU > 0:\n",
    "            rate[u] = sum([x['nHelpful'] for x in colHelpful[u]]) * 1.0 / totalU\n",
    "        else:\n",
    "            rate[u] = averageRate \n",
    "    \n",
    "    return rate, averageRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Helpful_rate(data, colname):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the helpful rate for a specified column\n",
    "    For example: 'reviewerID' and 'itemID'.\n",
    "    \"\"\"\n",
    "    \n",
    "    rate_dict, avg_rate = get_helpfulRate(colname)\n",
    "\n",
    "    ratehelpful = []\n",
    "    for i in data:\n",
    "        # use average for entries not present\n",
    "        try:\n",
    "            ratehelpful.append(rate_dict[i])\n",
    "        except:\n",
    "            ratehelpful.append(avg_rate)\n",
    "            \n",
    "    return ratehelpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_punctuation_count(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function counts the number of punctuation characters found in the text\n",
    "    punctuation characters are taken from the 'string' library.\n",
    "    \"\"\"\n",
    "\n",
    "    punct_set = set(string.punctuation)\n",
    "    list_ = []\n",
    "    for str_ in data:\n",
    "        count_ = 0\n",
    "        for c in str_:\n",
    "            if c in punct_set:\n",
    "                count_+=1\n",
    "            else:\n",
    "                continue\n",
    "        list_.append(count_)\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_numreviews_summarized(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the number of reviews encountered for the column specified:\n",
    "    For example: 'itemID' and 'reviewerID'.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize dict\n",
    "    dict_ = {k:0 for k in set(data)}\n",
    "    \n",
    "    # count number \n",
    "    for r in data:\n",
    "        dict_[r]+=1\n",
    "        \n",
    "    # create list\n",
    "    list_ = []\n",
    "    for r in data:\n",
    "        try:\n",
    "            list_.append(dict_[r])\n",
    "        except:\n",
    "            list_.append(0)\n",
    "    \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_product_ratingDeviation(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the difference in rating for each review \n",
    "    as compared to the mean of all ratings for the item.\n",
    "    \"\"\"\n",
    "\n",
    "    ProdRating_mean_dict = df[['itemID', 'rating']].groupby(['itemID']).mean().rating.to_dict()\n",
    "\n",
    "    rating_deviation = []\n",
    "    for r, p in zip(df.rating, df.itemID):\n",
    "        try:\n",
    "            rating_deviation.append(r - ProdRating_mean_dict[p])\n",
    "        except:\n",
    "            rating_deviation.append(-444)\n",
    "        \n",
    "    return rating_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_count_firstLetterCapital(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function counts the number of words in the text\n",
    "    whose fist letter is capital.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_ = []\n",
    "    for review in data:\n",
    "        count_ = 0\n",
    "        for word in review.split():\n",
    "            if word[0].isupper():\n",
    "                count_+=1\n",
    "        list_.append(count_)\n",
    "        \n",
    "    return list_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_avg_word_length(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the average word length for the text, \n",
    "    stop words are removed using the list from NLTK library. \n",
    "    \"\"\"\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # remove stopwords\n",
    "        words = set(words) - stop_words\n",
    "                    \n",
    "        # save average length\n",
    "        try:\n",
    "            list_.append(sum([len(w) for w in words])/len(words))\n",
    "        except:\n",
    "            list_.append(-1)\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_delta_sinceFirstReview(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the Unix time difference \n",
    "    since the first review for each item.\n",
    "    \"\"\"\n",
    "    \n",
    "    # find time for first review in each product\n",
    "    first_product_reviewtime = df[['itemID','unixReviewTime']].groupby(['itemID']).min().unixReviewTime.to_dict()\n",
    "\n",
    "    # find delta for each review\n",
    "    delta = []\n",
    "    for i,t in zip(df.itemID, df.unixReviewTime):\n",
    "        delta.append(t-first_product_reviewtime[i])\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_delta_sinceLastReview(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the Unix time difference \n",
    "    since the last review for each item.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create reduced df\n",
    "    new_df = df[['itemID','unixReviewTime']].groupby(['itemID'])['unixReviewTime'].apply(list)\n",
    "\n",
    "    # create dictionary with deltas\n",
    "    delta_dict = defaultdict(dict)\n",
    "    \n",
    "    for idx, times_list in zip(new_df.index, new_df):\n",
    "\n",
    "        times_list = sorted(times_list)\n",
    "        times_list_deltas = np.append(np.array([0]) , np.diff(times_list))\n",
    "\n",
    "        for t, d in zip(times_list, times_list_deltas):\n",
    "            delta_dict[idx][t] = d\n",
    "\n",
    "    # generate list with deltas matching input dataframe\n",
    "    list_ = []\n",
    "    for u,t in zip(df.itemID, df.unixReviewTime):\n",
    "        list_.append(delta_dict[u][t])\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_colsRatio(col1, col2):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the ratio element-wise for two columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_ = []\n",
    "    for i,j in zip(col1, col2):\n",
    "\n",
    "        try:\n",
    "            list_.append(i/j)\n",
    "        except:\n",
    "            list_.append(-1)\n",
    "\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_numCapitalwords(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the number of words \n",
    "    in the text where all letters are capital. \n",
    "    \"\"\"\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # remove stopwords\n",
    "        words = set(words) - stop_words\n",
    "        \n",
    "        # append count of upper case words\n",
    "        list_.append(len([i for i in words if i.isupper()]))\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_ExclQues_charCount(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function counts the number of exclamation \n",
    "    and question characters in the text. \n",
    "    \"\"\"\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        # append count of question and exclamation characters\n",
    "        list_.append(review_text.count('?') + review_text.count('!'))\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_features(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function learns all the features from the raw data, \n",
    "    each feature is added as a new column to the input dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Modify ----------> \"categories\"\n",
    "    \n",
    "    # get number of characters\n",
    "    df.loc[:,'categories_count'] = [len(i) for i in df['categories']]\n",
    "    \n",
    "    # generate numerical category by transforming combination of lists to numbers\n",
    "    df.loc[:,'category_numtrans'] = Get_category_numtrans(df.categories)\n",
    "\n",
    "    # Modify ----------> \"itemID\" and \"reviewerID\"\n",
    "    \n",
    "    # create dictionaries for itemID and reviewerID, convert from categorical to numeric\n",
    "    items_dict = {k:v for v,k in enumerate(set(df.itemID))}\n",
    "    reviewer_dict = {k:v for v,k in enumerate(set(df.reviewerID))}\n",
    "    \n",
    "    # change item and reviewer IDs to numeric\n",
    "    df.loc[:,'itemID'] = [items_dict[i] for i in df['itemID']]\n",
    "    df.loc[:,'reviewerID'] = [reviewer_dict[i] for i in df['reviewerID']]\n",
    "    \n",
    "    # add helpful rate for itemID and reviewerID\n",
    "    df.loc[:,'itemID_helpfulRate'] = find_Helpful_rate(df['itemID'], 'itemID')\n",
    "    df.loc[:,'reviewerID_helpfulRate'] = find_Helpful_rate(df['reviewerID'], 'reviewerID')\n",
    "    \n",
    "    # get number of reviews for each user\n",
    "    df.loc[:,'reviewerID_numReviews'] = Get_numreviews_summarized(df['reviewerID'])\n",
    "    \n",
    "    # get number of reviews for each product\n",
    "    df.loc[:,'itemID_numReviews'] = Get_numreviews_summarized(df['itemID'])\n",
    "    \n",
    "    # Modify ----------> \"reviewText\" \n",
    "    \n",
    "    # get number of words, remove stopwords\n",
    "    df.loc[:,'reviewText_count_words'] = Get_NumWords(df['reviewText'])\n",
    "\n",
    "    # get character count\n",
    "    df.loc[:,'reviewText_count_char'] = [len(i) for i in df['reviewText']]\n",
    "    \n",
    "    # get punctuation count\n",
    "    df.loc[:,'reviewText_count_punctu'] = Get_punctuation_count(df['reviewText'])\n",
    "    \n",
    "    # get number of words that start with a capital leter\n",
    "    df.loc[:,'reviewText_count_firstCapital'] = Get_count_firstLetterCapital(df['reviewText'])\n",
    "    \n",
    "    # get average word length\n",
    "    df.loc[:,'reviewText_avgWordLength'] = Get_avg_word_length(df['reviewText'])\n",
    "    \n",
    "    # get number of capital words\n",
    "    df.loc[:,'reviewText_capitalwords'] = Get_numCapitalwords(df['reviewText'])\n",
    "    \n",
    "    # get number of question and exclamation characters\n",
    "    df.loc[:,'reviewText_ExclQue_countchar'] = Get_ExclQues_charCount(df['reviewText'])\n",
    "    \n",
    "    # get ratio between puctuations with character numbers\n",
    "    df.loc[:,'reviewText_PunctChar_ratio'] = Get_colsRatio(df['reviewText_count_punctu'], df['reviewText_count_char'])\n",
    "    \n",
    "    # get positive and negative word rate\n",
    "    reviewText_PosNeg = GetPosNegWords_count_Rate(df.reviewText)\n",
    "    df.loc[:,'reviewText_posWordCount'] = reviewText_PosNeg['pos_count']\n",
    "    df.loc[:,'reviewText_negWordCount'] = reviewText_PosNeg['neg_count']\n",
    "    df.loc[:,'reviewText_posWordRate'] = reviewText_PosNeg['pos_rate']\n",
    "    df.loc[:,'reviewText_negWordRate'] = reviewText_PosNeg['neg_rate']\n",
    "  \n",
    "    # Modify ----------> \"summary\"\n",
    "    \n",
    "    # get number of words, remove stopwords\n",
    "    df.loc[:,'summary_count_words'] = Get_NumWords(df['summary'])\n",
    "\n",
    "    # get character count\n",
    "    df.loc[:,'summary_count_char'] = [len(i) for i in df['summary']]\n",
    "    \n",
    "    # get punctuation count\n",
    "    df.loc[:,'summary_count_punctu'] = Get_punctuation_count(df['summary'])\n",
    "    \n",
    "    # get number of words that start with a capital leter\n",
    "    df.loc[:,'summary_count_firstCapital'] = Get_count_firstLetterCapital(df['summary'])\n",
    "    \n",
    "    # get average word length\n",
    "    df.loc[:,'summary_avgWordLength'] = Get_avg_word_length(df['summary'])\n",
    "    \n",
    "    # get number of capital words\n",
    "    df.loc[:,'summary_capitalwords'] = Get_numCapitalwords(df['summary'])\n",
    "    \n",
    "    # get number of question and exclamation characters\n",
    "    df.loc[:,'summary_ExclQue_countchar'] = Get_ExclQues_charCount(df['summary'])\n",
    "    \n",
    "    # get ratio between puctuations with character numbers\n",
    "    df.loc[:,'summary_PunctChar_ratio'] = Get_colsRatio(df['summary_count_punctu'], df['summary_count_char'])\n",
    "    \n",
    "    # get positive and negative word rate\n",
    "    summary_PosNeg = GetPosNegWords_count_Rate(df.summary)\n",
    "    df.loc[:,'summary_posWordCount'] = summary_PosNeg['pos_count']\n",
    "    df.loc[:,'summary_negWordCount'] = summary_PosNeg['neg_count']\n",
    "    df.loc[:,'summary_posWordRate'] = summary_PosNeg['pos_rate']\n",
    "    df.loc[:,'summary_negWordRate'] = summary_PosNeg['neg_rate']\n",
    "    \n",
    "    # Modify ----------> \"helpful\" \n",
    "    \n",
    "    # parse helpful votes\n",
    "    df.loc[:,'outOf_feature'] = [i['outOf'] for i in df['helpful']]\n",
    "    \n",
    "    # Modify ----------> \"price\" \n",
    "    \n",
    "    # change NA values to -999\n",
    "    df.loc[df.price.isna(),'price'] = -999\n",
    "    \n",
    "    # Modify ----------> \"unixReviewTime\" \n",
    "    \n",
    "    # find time since first review\n",
    "    df.loc[:,'unixReviewTime_delta_firstreview'] = Get_delta_sinceFirstReview(df)\n",
    "    \n",
    "    # find time since last review for same product\n",
    "    df.loc[:,'unixReviewTime_delta_lastreview'] = Get_delta_sinceLastReview(df)\n",
    "    \n",
    "    # Modify ----------> \"reviewText\" \n",
    "    \n",
    "    # get rating deviation from the mean\n",
    "    df.loc[:,'rating_deviation'] = Get_product_ratingDeviation(df)\n",
    "    \n",
    "    # Add -------------> New Columns\n",
    "    \n",
    "    # votes over time\n",
    "    df.loc[:,'votes_time'] = df.outOf_feature/df.unixReviewTime\n",
    "    \n",
    "    # ratio of summary to reviewText for characters and words\n",
    "    df.loc[:,'summary_reviewText_charRatio'] = Get_colsRatio(df.summary_count_char, df.reviewText_count_char)\n",
    "    df.loc[:,'summary_reviewText_wordsRatio'] = Get_colsRatio(df.summary_count_words, df.reviewText_count_words)\n",
    "    \n",
    "    # define columns to keep\n",
    "    cols = ['categoryID','categories_count', 'category_numtrans','summary_count_words', 'itemID', 'reviewerID', 'rating', \n",
    "            'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "            'reviewerID_numReviews', 'rating_deviation', \n",
    "            'outOf_feature', 'unixReviewTime', 'price', 'reviewText_posWordCount', 'reviewText_negWordCount',\n",
    "            'reviewText_posWordRate', 'reviewText_negWordRate', 'summary_count_char', 'reviewText_count_char',\n",
    "            'reviewText_count_punctu','summary_count_punctu','summary_posWordCount', \n",
    "            'summary_negWordCount', 'summary_posWordRate','summary_negWordRate',\n",
    "           'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "           'reviewText_avgWordLength','summary_avgWordLength', 'unixReviewTime_delta_firstreview',\n",
    "           'votes_time', 'summary_reviewText_charRatio', 'summary_reviewText_wordsRatio', 'itemID_numReviews',\n",
    "           'reviewText_capitalwords', 'summary_capitalwords',\n",
    "           'reviewText_ExclQue_countchar', 'summary_ExclQue_countchar',\n",
    "           'reviewText_PunctChar_ratio', 'summary_PunctChar_ratio', 'unixReviewTime_delta_lastreview']\n",
    "    \n",
    "    # return features\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_labels_ratio(df):    \n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the ratio between helpful votes \n",
    "    with total votes from raw data. This ratio is the \n",
    "    regression label used to train the model. \n",
    "    \"\"\"\n",
    "    \n",
    "    return [i['nHelpful']/i['outOf'] if i['outOf']!=0 else 0 for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads a formatted file and writes \n",
    "    the predictions found for the test data. The file \n",
    "    is used as input to the DSE 220 Kaggle competition. \n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = open(\"predictions_Helpful.txt\", 'w')\n",
    "    \n",
    "    count = 0\n",
    "    for l in open(\"pairs_Helpful.txt\"):\n",
    "        \n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        \n",
    "        u,i,outOf = l.strip().split('-')\n",
    "        \n",
    "        predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(pred[count]) + '\\n')\n",
    "        \n",
    "        count+=1\n",
    "    \n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfmetrics_RFmodel(max_depth, n_estimators, X_train_filt, y_train_filt, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies the random forest model, \n",
    "    the inputs and outputs are listed below:\n",
    "        \n",
    "    Inputs:\n",
    "        Random Forest Hyperparameters\n",
    "            - max_depth: max depth of the tree\n",
    "            - n_estimators: number of trees in the forest\n",
    "        Trainning Data\n",
    "            - X_train_filt: train the model with train data where number of votes (labels) are > 0 \n",
    "            - y_train_filt train the model with train data where number of votes (labels) are > 0 \n",
    "            - X_train: data includes all labels \n",
    "            - y_train: data includes all labels\n",
    "        Testing Data (or Validation)\n",
    "            - X_test: data includes all labels\n",
    "            - y_test: data includes all labels\n",
    "            \n",
    "    Outputs:\n",
    "        - train_accuracy\n",
    "        - test_accuracy\n",
    "        - train_mae (Mean Absolute Error)\n",
    "        - test_mae\n",
    "        - train_mse (Mean Squared Error)\n",
    "        - test_mse\n",
    "        - y_pred_test (or validation predictions)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define model\n",
    "    regr = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, n_jobs=-1)\n",
    "    \n",
    "    # evaluate, with filtered data\n",
    "    regr.fit(X_train_filt, y_train_filt)\n",
    "    \n",
    "    # predict test and train, multiply prediction by the number of votes\n",
    "    y_pred_train = regr.predict(X_train)*np.array(X_train.outOf_feature)\n",
    "    y_pred_test = regr.predict(X_test)*np.array(X_test.outOf_feature)\n",
    "\n",
    "    # round to the nearest integer, labels are integers\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "    y_pred_test = [int(round(i)) for i in y_pred_test]\n",
    "\n",
    "    # calculate accuracy, mean absolute error, and mean squared error\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "    if y_test != None: # case when test labels are known\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    else: # case when test labels are predicted\n",
    "        return (train_accuracy, train_mae, train_mse, y_pred_test)\n",
    "\n",
    "    # return all performance metrics\n",
    "    return (train_accuracy, test_accuracy, train_mae, test_mae, train_mse, test_mse, y_pred_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 1.47 s, total: 28.8 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read train\n",
    "train = getDF('train.json.gz')\n",
    "\n",
    "# define features and labels for train data\n",
    "train_features = train\n",
    "train_labels = train['helpful']\n",
    "\n",
    "# read test\n",
    "test = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train and validation\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(train_features, train_labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1. Trainning data example (raw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44011</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, D, Dreams], [Clot...</td>\n",
       "      <td>I322658212</td>\n",
       "      <td>U656051947</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These pajamas are a perfect weight for me. I'm...</td>\n",
       "      <td>R196940592</td>\n",
       "      <td>03 25, 2014</td>\n",
       "      <td>Nice weight &amp; comfy.</td>\n",
       "      <td>1395705600</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53593</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Shoes &amp; Accessori...</td>\n",
       "      <td>I913405870</td>\n",
       "      <td>U604395367</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I returned these because I thought they looked...</td>\n",
       "      <td>R612741609</td>\n",
       "      <td>09 16, 2013</td>\n",
       "      <td>Nice quality</td>\n",
       "      <td>1379289600</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141214</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Shoes, San...</td>\n",
       "      <td>I036574902</td>\n",
       "      <td>U886882212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Saddle is very pretty, and I think it will be ...</td>\n",
       "      <td>R077184873</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>Very pretty</td>\n",
       "      <td>1399248000</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179392</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women], [Clothing...</td>\n",
       "      <td>I134433773</td>\n",
       "      <td>U154865904</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This ring is truly stunning and dramatic while...</td>\n",
       "      <td>R611116635</td>\n",
       "      <td>03 16, 2014</td>\n",
       "      <td>Stainless Steel Band With CZ</td>\n",
       "      <td>1394928000</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>5.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32982</th>\n",
       "      <td>1</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Men, Accessories,...</td>\n",
       "      <td>I532478566</td>\n",
       "      <td>U578222660</td>\n",
       "      <td>4.0</td>\n",
       "      <td>At first the tension on this was too tight, bu...</td>\n",
       "      <td>R286930585</td>\n",
       "      <td>05 16, 2014</td>\n",
       "      <td>No nonsense, just how I like it.</td>\n",
       "      <td>1400198400</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID                                         categories  \\\n",
       "44011            0  [[Clothing, Shoes & Jewelry, D, Dreams], [Clot...   \n",
       "53593            0  [[Clothing, Shoes & Jewelry, Shoes & Accessori...   \n",
       "141214           0  [[Clothing, Shoes & Jewelry, Women, Shoes, San...   \n",
       "179392           0  [[Clothing, Shoes & Jewelry, Women], [Clothing...   \n",
       "32982            1  [[Clothing, Shoes & Jewelry, Men, Accessories,...   \n",
       "\n",
       "            itemID  reviewerID  rating  \\\n",
       "44011   I322658212  U656051947     5.0   \n",
       "53593   I913405870  U604395367     3.0   \n",
       "141214  I036574902  U886882212     3.0   \n",
       "179392  I134433773  U154865904     5.0   \n",
       "32982   I532478566  U578222660     4.0   \n",
       "\n",
       "                                               reviewText  reviewHash  \\\n",
       "44011   These pajamas are a perfect weight for me. I'm...  R196940592   \n",
       "53593   I returned these because I thought they looked...  R612741609   \n",
       "141214  Saddle is very pretty, and I think it will be ...  R077184873   \n",
       "179392  This ring is truly stunning and dramatic while...  R611116635   \n",
       "32982   At first the tension on this was too tight, bu...  R286930585   \n",
       "\n",
       "         reviewTime                           summary  unixReviewTime  \\\n",
       "44011   03 25, 2014              Nice weight & comfy.      1395705600   \n",
       "53593   09 16, 2013                      Nice quality      1379289600   \n",
       "141214   05 5, 2014                       Very pretty      1399248000   \n",
       "179392  03 16, 2014      Stainless Steel Band With CZ      1394928000   \n",
       "32982   05 16, 2014  No nonsense, just how I like it.      1400198400   \n",
       "\n",
       "                            helpful  price  \n",
       "44011   {'outOf': 0, 'nHelpful': 0}    NaN  \n",
       "53593   {'outOf': 0, 'nHelpful': 0}    NaN  \n",
       "141214  {'outOf': 0, 'nHelpful': 0}    NaN  \n",
       "179392  {'outOf': 0, 'nHelpful': 0}   5.94  \n",
       "32982   {'outOf': 0, 'nHelpful': 0}   7.99  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation - Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 2.78 s, total: 2min 42s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# learn features\n",
    "X_train = Get_features(X_train_raw)\n",
    "X_val = Get_features(X_val_raw)\n",
    "\n",
    "# create labels\n",
    "y_train = [i['nHelpful'] for i in y_train_raw]\n",
    "y_val = [i['nHelpful'] for i in y_val_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 302 ms, total: 52.3 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model is only trained for reviews where number of votes is > 0 \n",
    "\n",
    "# find indices \n",
    "idx = np.array([i['outOf'] for i in X_train_raw.helpful]) > 0\n",
    "\n",
    "# filter new train data and learn features on filtered data\n",
    "X_train_filt = Get_features(X_train_raw.loc[idx,:])\n",
    "y_train_ratio_filt = Get_labels_ratio(list(compress(y_train_raw, idx))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection - Keep Features with Better Performance than Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 7s, sys: 7.57 s, total: 12min 15s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define hyperparameters to test\n",
    "max_depth = 10\n",
    "n_estimators = 100\n",
    "\n",
    "# define baseline and other features\n",
    "baseline_features = ['itemID', 'reviewerID', 'outOf_feature']\n",
    "features = [i for i in X_train.columns if i not in baseline_features]\n",
    "\n",
    "# run model with baseline features + one feature, see MAE if improves\n",
    "metrics = []\n",
    "for i in range(len(features)+1):\n",
    "    \n",
    "    # define features to test\n",
    "    if i == 0: # baseline\n",
    "        curr_features = baseline_features\n",
    "        feature_name = 'baseline'\n",
    "    else: # other features\n",
    "        curr_features = baseline_features + [features[i-1]]\n",
    "        feature_name = features[i-1]\n",
    "    \n",
    "    # get metrics (train_accuracy, test_accuracy, train_mae, test_mae, train_mse, test_mse, y_pred_test)\n",
    "    metrics_tuple = perfmetrics_RFmodel(max_depth, n_estimators, X_train_filt[curr_features], \n",
    "                                        y_train_ratio_filt, X_train[curr_features], y_train, \n",
    "                                        X_val[curr_features], y_val)\n",
    "\n",
    "    # save metrics\n",
    "    metrics.append((feature_name,) + metrics_tuple[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2. Features tested one-by-one along with baseline, those with higher than baseline performance (lower MAE) are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>train_accur</th>\n",
       "      <th>val_accur</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rating_deviation</td>\n",
       "      <td>0.857513</td>\n",
       "      <td>0.863350</td>\n",
       "      <td>0.183419</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.753856</td>\n",
       "      <td>0.742850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>summary_posWordCount</td>\n",
       "      <td>0.858394</td>\n",
       "      <td>0.859800</td>\n",
       "      <td>0.182506</td>\n",
       "      <td>0.183150</td>\n",
       "      <td>0.615256</td>\n",
       "      <td>0.812350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>summary_posWordRate</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.183706</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>0.643056</td>\n",
       "      <td>0.802025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unixReviewTime</td>\n",
       "      <td>0.855681</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>0.183688</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.582037</td>\n",
       "      <td>0.828750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reviewText_posWordRate</td>\n",
       "      <td>0.856012</td>\n",
       "      <td>0.858625</td>\n",
       "      <td>0.181719</td>\n",
       "      <td>0.184650</td>\n",
       "      <td>0.514431</td>\n",
       "      <td>0.914550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>0.859163</td>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.178381</td>\n",
       "      <td>0.184875</td>\n",
       "      <td>0.482044</td>\n",
       "      <td>1.891625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>summary_negWordRate</td>\n",
       "      <td>0.855675</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.184012</td>\n",
       "      <td>0.184975</td>\n",
       "      <td>0.616337</td>\n",
       "      <td>0.858525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reviewText_posWordCount</td>\n",
       "      <td>0.855444</td>\n",
       "      <td>0.856925</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.831150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>summary_negWordCount</td>\n",
       "      <td>0.853819</td>\n",
       "      <td>0.856400</td>\n",
       "      <td>0.186306</td>\n",
       "      <td>0.185575</td>\n",
       "      <td>0.627181</td>\n",
       "      <td>0.846875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>reviewText_PunctChar_ratio</td>\n",
       "      <td>0.854006</td>\n",
       "      <td>0.855700</td>\n",
       "      <td>0.186356</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.554556</td>\n",
       "      <td>0.836600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>reviewText_count_char</td>\n",
       "      <td>0.857587</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.180156</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.554769</td>\n",
       "      <td>0.914700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>price</td>\n",
       "      <td>0.854738</td>\n",
       "      <td>0.856050</td>\n",
       "      <td>0.184037</td>\n",
       "      <td>0.185850</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.857850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>reviewText_ExclQue_countchar</td>\n",
       "      <td>0.853450</td>\n",
       "      <td>0.854650</td>\n",
       "      <td>0.187562</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.685662</td>\n",
       "      <td>0.841750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>summary_reviewText_charRatio</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.855250</td>\n",
       "      <td>0.184113</td>\n",
       "      <td>0.186175</td>\n",
       "      <td>0.617812</td>\n",
       "      <td>0.879275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reviewText_count_words</td>\n",
       "      <td>0.856363</td>\n",
       "      <td>0.856500</td>\n",
       "      <td>0.182669</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.607556</td>\n",
       "      <td>0.888850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>summary_ExclQue_countchar</td>\n",
       "      <td>0.853762</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>0.185938</td>\n",
       "      <td>0.186375</td>\n",
       "      <td>0.623075</td>\n",
       "      <td>0.849875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>unixReviewTime_delta_firstreview</td>\n",
       "      <td>0.854838</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>0.186425</td>\n",
       "      <td>0.657975</td>\n",
       "      <td>0.854025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>categoryID</td>\n",
       "      <td>0.847069</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.193944</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.687056</td>\n",
       "      <td>0.848750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>reviewText_count_firstCapital</td>\n",
       "      <td>0.855750</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.184306</td>\n",
       "      <td>0.186550</td>\n",
       "      <td>0.617419</td>\n",
       "      <td>0.846350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>summary_count_firstCapital</td>\n",
       "      <td>0.855481</td>\n",
       "      <td>0.855225</td>\n",
       "      <td>0.187044</td>\n",
       "      <td>0.186625</td>\n",
       "      <td>0.674181</td>\n",
       "      <td>0.845625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>summary_capitalwords</td>\n",
       "      <td>0.854475</td>\n",
       "      <td>0.853825</td>\n",
       "      <td>0.186550</td>\n",
       "      <td>0.186725</td>\n",
       "      <td>0.665575</td>\n",
       "      <td>0.836625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>summary_PunctChar_ratio</td>\n",
       "      <td>0.854675</td>\n",
       "      <td>0.854650</td>\n",
       "      <td>0.184806</td>\n",
       "      <td>0.186825</td>\n",
       "      <td>0.661294</td>\n",
       "      <td>0.849475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>summary_count_punctu</td>\n",
       "      <td>0.853744</td>\n",
       "      <td>0.854475</td>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.677963</td>\n",
       "      <td>0.847800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>unixReviewTime_delta_lastreview</td>\n",
       "      <td>0.854044</td>\n",
       "      <td>0.854100</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.647744</td>\n",
       "      <td>0.851700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>summary_avgWordLength</td>\n",
       "      <td>0.855537</td>\n",
       "      <td>0.854900</td>\n",
       "      <td>0.183356</td>\n",
       "      <td>0.186925</td>\n",
       "      <td>0.608669</td>\n",
       "      <td>0.877225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reviewText_count_punctu</td>\n",
       "      <td>0.855206</td>\n",
       "      <td>0.853725</td>\n",
       "      <td>0.184331</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.549556</td>\n",
       "      <td>0.739850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>summary_reviewText_wordsRatio</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.854550</td>\n",
       "      <td>0.185087</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.623687</td>\n",
       "      <td>0.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reviewText_negWordCount</td>\n",
       "      <td>0.854550</td>\n",
       "      <td>0.853525</td>\n",
       "      <td>0.186031</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.654481</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>itemID_numReviews</td>\n",
       "      <td>0.851650</td>\n",
       "      <td>0.852875</td>\n",
       "      <td>0.201437</td>\n",
       "      <td>0.187550</td>\n",
       "      <td>0.829775</td>\n",
       "      <td>0.857650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_numtrans</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.853425</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>0.187575</td>\n",
       "      <td>0.558163</td>\n",
       "      <td>0.858025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>votes_time</td>\n",
       "      <td>0.853525</td>\n",
       "      <td>0.852875</td>\n",
       "      <td>0.187888</td>\n",
       "      <td>0.187750</td>\n",
       "      <td>0.688375</td>\n",
       "      <td>0.866300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>reviewText_capitalwords</td>\n",
       "      <td>0.853900</td>\n",
       "      <td>0.852875</td>\n",
       "      <td>0.185938</td>\n",
       "      <td>0.187875</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.853925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reviewerID_helpfulRate</td>\n",
       "      <td>0.857487</td>\n",
       "      <td>0.853150</td>\n",
       "      <td>0.182163</td>\n",
       "      <td>0.187925</td>\n",
       "      <td>0.671488</td>\n",
       "      <td>0.857475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.853556</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.186312</td>\n",
       "      <td>0.188325</td>\n",
       "      <td>0.677188</td>\n",
       "      <td>0.865975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summary_count_words</td>\n",
       "      <td>0.854725</td>\n",
       "      <td>0.853525</td>\n",
       "      <td>0.186587</td>\n",
       "      <td>0.188350</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>0.866250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itemID_helpfulRate</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.184888</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>summary_count_char</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.853175</td>\n",
       "      <td>0.186069</td>\n",
       "      <td>0.188425</td>\n",
       "      <td>0.657131</td>\n",
       "      <td>0.869125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>categories_count</td>\n",
       "      <td>0.853712</td>\n",
       "      <td>0.852300</td>\n",
       "      <td>0.188206</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.575481</td>\n",
       "      <td>0.860575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reviewText_negWordRate</td>\n",
       "      <td>0.855213</td>\n",
       "      <td>0.856225</td>\n",
       "      <td>0.183631</td>\n",
       "      <td>0.189450</td>\n",
       "      <td>0.501481</td>\n",
       "      <td>1.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reviewerID_numReviews</td>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.851750</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.189550</td>\n",
       "      <td>0.643663</td>\n",
       "      <td>0.859650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>reviewText_avgWordLength</td>\n",
       "      <td>0.854031</td>\n",
       "      <td>0.853475</td>\n",
       "      <td>0.185463</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>0.592287</td>\n",
       "      <td>1.120425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            features  train_accur  val_accur  train_mae  \\\n",
       "10                  rating_deviation     0.857513   0.863350   0.183419   \n",
       "21              summary_posWordCount     0.858394   0.859800   0.182506   \n",
       "23               summary_posWordRate     0.856988   0.858400   0.183706   \n",
       "11                    unixReviewTime     0.855681   0.857625   0.183688   \n",
       "15            reviewText_posWordRate     0.856012   0.858625   0.181719   \n",
       "5                             rating     0.859163   0.864450   0.178381   \n",
       "24               summary_negWordRate     0.855675   0.857600   0.184012   \n",
       "13           reviewText_posWordCount     0.855444   0.856925   0.184200   \n",
       "22              summary_negWordCount     0.853819   0.856400   0.186306   \n",
       "38        reviewText_PunctChar_ratio     0.854006   0.855700   0.186356   \n",
       "18             reviewText_count_char     0.857587   0.857500   0.180156   \n",
       "12                             price     0.854738   0.856050   0.184037   \n",
       "36      reviewText_ExclQue_countchar     0.853450   0.854650   0.187562   \n",
       "31      summary_reviewText_charRatio     0.854962   0.855250   0.184113   \n",
       "6             reviewText_count_words     0.856363   0.856500   0.182669   \n",
       "37         summary_ExclQue_countchar     0.853762   0.854300   0.185938   \n",
       "29  unixReviewTime_delta_firstreview     0.854838   0.854300   0.184275   \n",
       "1                         categoryID     0.847069   0.856250   0.193944   \n",
       "25     reviewText_count_firstCapital     0.855750   0.854925   0.184306   \n",
       "26        summary_count_firstCapital     0.855481   0.855225   0.187044   \n",
       "35              summary_capitalwords     0.854475   0.853825   0.186550   \n",
       "39           summary_PunctChar_ratio     0.854675   0.854650   0.184806   \n",
       "20              summary_count_punctu     0.853744   0.854475   0.187250   \n",
       "40   unixReviewTime_delta_lastreview     0.854044   0.854100   0.186406   \n",
       "28             summary_avgWordLength     0.855537   0.854900   0.183356   \n",
       "19           reviewText_count_punctu     0.855206   0.853725   0.184331   \n",
       "32     summary_reviewText_wordsRatio     0.854050   0.854550   0.185087   \n",
       "14           reviewText_negWordCount     0.854550   0.853525   0.186031   \n",
       "33                 itemID_numReviews     0.851650   0.852875   0.201437   \n",
       "3                  category_numtrans     0.853400   0.853425   0.187638   \n",
       "30                        votes_time     0.853525   0.852875   0.187888   \n",
       "34           reviewText_capitalwords     0.853900   0.852875   0.185938   \n",
       "8             reviewerID_helpfulRate     0.857487   0.853150   0.182163   \n",
       "0                           baseline     0.853556   0.852500   0.186312   \n",
       "4                summary_count_words     0.854725   0.853525   0.186587   \n",
       "7                 itemID_helpfulRate     0.856669   0.852975   0.184888   \n",
       "17                summary_count_char     0.854369   0.853175   0.186069   \n",
       "2                   categories_count     0.853712   0.852300   0.188206   \n",
       "16            reviewText_negWordRate     0.855213   0.856225   0.183631   \n",
       "9              reviewerID_numReviews     0.853731   0.851750   0.187300   \n",
       "27          reviewText_avgWordLength     0.854031   0.853475   0.185463   \n",
       "\n",
       "     val_mae  train_mse   val_mse  \n",
       "10  0.179500   0.753856  0.742850  \n",
       "21  0.183150   0.615256  0.812350  \n",
       "23  0.183825   0.643056  0.802025  \n",
       "11  0.184100   0.582037  0.828750  \n",
       "15  0.184650   0.514431  0.914550  \n",
       "5   0.184875   0.482044  1.891625  \n",
       "24  0.184975   0.616337  0.858525  \n",
       "13  0.185400   0.524800  0.831150  \n",
       "22  0.185575   0.627181  0.846875  \n",
       "38  0.185800   0.554556  0.836600  \n",
       "18  0.185800   0.554769  0.914700  \n",
       "12  0.185850   0.553400  0.857850  \n",
       "36  0.186000   0.685662  0.841750  \n",
       "31  0.186175   0.617812  0.879275  \n",
       "6   0.186300   0.607556  0.888850  \n",
       "37  0.186375   0.623075  0.849875  \n",
       "29  0.186425   0.657975  0.854025  \n",
       "1   0.186500   0.687056  0.848750  \n",
       "25  0.186550   0.617419  0.846350  \n",
       "26  0.186625   0.674181  0.845625  \n",
       "35  0.186725   0.665575  0.836625  \n",
       "39  0.186825   0.661294  0.849475  \n",
       "20  0.186900   0.677963  0.847800  \n",
       "40  0.186900   0.647744  0.851700  \n",
       "28  0.186925   0.608669  0.877225  \n",
       "19  0.187200   0.549556  0.739850  \n",
       "32  0.187500   0.623687  0.881500  \n",
       "14  0.187500   0.654481  0.846400  \n",
       "33  0.187550   0.829775  0.857650  \n",
       "3   0.187575   0.558163  0.858025  \n",
       "30  0.187750   0.688375  0.866300  \n",
       "34  0.187875   0.655900  0.853925  \n",
       "8   0.187925   0.671488  0.857475  \n",
       "0   0.188325   0.677188  0.865975  \n",
       "4   0.188350   0.650500  0.866250  \n",
       "7   0.188400   0.697700  0.860200  \n",
       "17  0.188425   0.657131  0.869125  \n",
       "2   0.188775   0.575481  0.860575  \n",
       "16  0.189450   0.501481  1.175300  \n",
       "9   0.189550   0.643663  0.859650  \n",
       "27  0.190525   0.592287  1.120425  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe \n",
    "df_metrics = pd.DataFrame(metrics, columns=['features', 'train_accur', 'val_accur', 'train_mae', 'val_mae',\n",
    "                                            'train_mse', 'val_mse'])\n",
    "\n",
    "# sort by MAE in validation, descending\n",
    "df_metrics = df_metrics.sort_values(by='val_mae')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itemID', 'reviewerID', 'outOf_feature', 'rating_deviation', 'summary_posWordCount', 'summary_posWordRate', 'unixReviewTime', 'reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n"
     ]
    }
   ],
   "source": [
    "# keep features with better performance than baseline\n",
    "baseline_valMAE = df_metrics.val_mae[df_metrics.features == 'baseline'].values[0]\n",
    "\n",
    "features_aboveBaseline = list(df_metrics.features[df_metrics.val_mae < baseline_valMAE])\n",
    "all_features = baseline_features + features_aboveBaseline\n",
    "\n",
    "print(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection - Ablation Study with Features Elimination (Ordered by MAE descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Eliminated: None\n",
      "\tTrain Accuracy: 0.8679625\n",
      "\tValidation Accuracy: 0.86735\n",
      "\tTrain MAE: 0.1681\n",
      "\tValidation MAE: 0.1741\n",
      "\tTrain MSE: 0.5105125\n",
      "\tValidation MSE: 0.769\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86815\n",
      "\tValidation Accuracy: 0.867725\n",
      "\tTrain MAE: 0.1678125\n",
      "\tValidation MAE: 0.173675\n",
      "\tTrain MSE: 0.5429125\n",
      "\tValidation MSE: 0.772075\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8676375\n",
      "\tValidation Accuracy: 0.8675\n",
      "\tTrain MAE: 0.1694\n",
      "\tValidation MAE: 0.17405\n",
      "\tTrain MSE: 0.5346125\n",
      "\tValidation MSE: 0.71645\n",
      "\n",
      "\n",
      "Features Eliminated: ['votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86820625\n",
      "\tValidation Accuracy: 0.86715\n",
      "\tTrain MAE: 0.1682625\n",
      "\tValidation MAE: 0.17425\n",
      "\tTrain MSE: 0.54125\n",
      "\tValidation MSE: 0.72675\n",
      "\n",
      "\n",
      "Features Eliminated: ['category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8680375\n",
      "\tValidation Accuracy: 0.86735\n",
      "\tTrain MAE: 0.168725\n",
      "\tValidation MAE: 0.1749\n",
      "\tTrain MSE: 0.5389875\n",
      "\tValidation MSE: 0.80905\n",
      "\n",
      "\n",
      "Features Eliminated: ['itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8701875\n",
      "\tValidation Accuracy: 0.8668\n",
      "\tTrain MAE: 0.162575\n",
      "\tValidation MAE: 0.17375\n",
      "\tTrain MSE: 0.48335\n",
      "\tValidation MSE: 0.7025\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.87045\n",
      "\tValidation Accuracy: 0.86705\n",
      "\tTrain MAE: 0.16189375\n",
      "\tValidation MAE: 0.173525\n",
      "\tTrain MSE: 0.51855625\n",
      "\tValidation MSE: 0.708675\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.87003125\n",
      "\tValidation Accuracy: 0.866925\n",
      "\tTrain MAE: 0.16253125\n",
      "\tValidation MAE: 0.173325\n",
      "\tTrain MSE: 0.50564375\n",
      "\tValidation MSE: 0.708675\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.870525\n",
      "\tValidation Accuracy: 0.8671\n",
      "\tTrain MAE: 0.1616125\n",
      "\tValidation MAE: 0.173825\n",
      "\tTrain MSE: 0.479925\n",
      "\tValidation MSE: 0.715575\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.869575\n",
      "\tValidation Accuracy: 0.866725\n",
      "\tTrain MAE: 0.16244375\n",
      "\tValidation MAE: 0.174\n",
      "\tTrain MSE: 0.50869375\n",
      "\tValidation MSE: 0.73725\n",
      "\n",
      "\n",
      "Features Eliminated: ['unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.87056875\n",
      "\tValidation Accuracy: 0.867375\n",
      "\tTrain MAE: 0.16161875\n",
      "\tValidation MAE: 0.17375\n",
      "\tTrain MSE: 0.48356875\n",
      "\tValidation MSE: 0.7448\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.870425\n",
      "\tValidation Accuracy: 0.867075\n",
      "\tTrain MAE: 0.16193125\n",
      "\tValidation MAE: 0.1733\n",
      "\tTrain MSE: 0.48360625\n",
      "\tValidation MSE: 0.7058\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8704125\n",
      "\tValidation Accuracy: 0.867275\n",
      "\tTrain MAE: 0.1619375\n",
      "\tValidation MAE: 0.1736\n",
      "\tTrain MSE: 0.5141\n",
      "\tValidation MSE: 0.735\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.869875\n",
      "\tValidation Accuracy: 0.867325\n",
      "\tTrain MAE: 0.16215\n",
      "\tValidation MAE: 0.17355\n",
      "\tTrain MSE: 0.4518375\n",
      "\tValidation MSE: 0.7451\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8698\n",
      "\tValidation Accuracy: 0.867225\n",
      "\tTrain MAE: 0.1622875\n",
      "\tValidation MAE: 0.173975\n",
      "\tTrain MSE: 0.4795625\n",
      "\tValidation MSE: 0.744025\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86995\n",
      "\tValidation Accuracy: 0.8667\n",
      "\tTrain MAE: 0.1619125\n",
      "\tValidation MAE: 0.174425\n",
      "\tTrain MSE: 0.47415\n",
      "\tValidation MSE: 0.744225\n",
      "\n",
      "\n",
      "Features Eliminated: ['categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86934375\n",
      "\tValidation Accuracy: 0.8664\n",
      "\tTrain MAE: 0.1634125\n",
      "\tValidation MAE: 0.176625\n",
      "\tTrain MSE: 0.554575\n",
      "\tValidation MSE: 0.921025\n",
      "\n",
      "\n",
      "Features Eliminated: ['unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.869575\n",
      "\tValidation Accuracy: 0.867475\n",
      "\tTrain MAE: 0.16406875\n",
      "\tValidation MAE: 0.175425\n",
      "\tTrain MSE: 0.57839375\n",
      "\tValidation MSE: 0.907625\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86935625\n",
      "\tValidation Accuracy: 0.8679\n",
      "\tTrain MAE: 0.16398125\n",
      "\tValidation MAE: 0.174725\n",
      "\tTrain MSE: 0.54790625\n",
      "\tValidation MSE: 0.894625\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86899375\n",
      "\tValidation Accuracy: 0.867075\n",
      "\tTrain MAE: 0.16439375\n",
      "\tValidation MAE: 0.176375\n",
      "\tTrain MSE: 0.52345625\n",
      "\tValidation MSE: 0.984725\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Eliminated: ['summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.868775\n",
      "\tValidation Accuracy: 0.867775\n",
      "\tTrain MAE: 0.16463125\n",
      "\tValidation MAE: 0.17545\n",
      "\tTrain MSE: 0.53184375\n",
      "\tValidation MSE: 0.96365\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86899375\n",
      "\tValidation Accuracy: 0.8674\n",
      "\tTrain MAE: 0.1639875\n",
      "\tValidation MAE: 0.17685\n",
      "\tTrain MSE: 0.512375\n",
      "\tValidation MSE: 1.0431\n",
      "\n",
      "\n",
      "Features Eliminated: ['price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8684375\n",
      "\tValidation Accuracy: 0.867325\n",
      "\tTrain MAE: 0.16644375\n",
      "\tValidation MAE: 0.1771\n",
      "\tTrain MSE: 0.56099375\n",
      "\tValidation MSE: 0.9935\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86693125\n",
      "\tValidation Accuracy: 0.8672\n",
      "\tTrain MAE: 0.16788125\n",
      "\tValidation MAE: 0.178075\n",
      "\tTrain MSE: 0.54553125\n",
      "\tValidation MSE: 1.050725\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8660875\n",
      "\tValidation Accuracy: 0.8668\n",
      "\tTrain MAE: 0.16935\n",
      "\tValidation MAE: 0.178025\n",
      "\tTrain MSE: 0.5467\n",
      "\tValidation MSE: 1.176475\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8662375\n",
      "\tValidation Accuracy: 0.8667\n",
      "\tTrain MAE: 0.168975\n",
      "\tValidation MAE: 0.17905\n",
      "\tTrain MSE: 0.52705\n",
      "\tValidation MSE: 1.25515\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.866\n",
      "\tValidation Accuracy: 0.867\n",
      "\tTrain MAE: 0.17045\n",
      "\tValidation MAE: 0.178475\n",
      "\tTrain MSE: 0.5603875\n",
      "\tValidation MSE: 1.141925\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86541875\n",
      "\tValidation Accuracy: 0.8664\n",
      "\tTrain MAE: 0.1709375\n",
      "\tValidation MAE: 0.1783\n",
      "\tTrain MSE: 0.5847125\n",
      "\tValidation MSE: 1.08385\n",
      "\n",
      "\n",
      "Features Eliminated: ['rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.86361875\n",
      "\tValidation Accuracy: 0.864475\n",
      "\tTrain MAE: 0.1736625\n",
      "\tValidation MAE: 0.1783\n",
      "\tTrain MSE: 0.729225\n",
      "\tValidation MSE: 0.97285\n",
      "\n",
      "\n",
      "Features Eliminated: ['reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8612375\n",
      "\tValidation Accuracy: 0.863875\n",
      "\tTrain MAE: 0.17938125\n",
      "\tValidation MAE: 0.178175\n",
      "\tTrain MSE: 0.77003125\n",
      "\tValidation MSE: 0.830275\n",
      "\n",
      "\n",
      "Features Eliminated: ['unixReviewTime', 'reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.85985625\n",
      "\tValidation Accuracy: 0.863275\n",
      "\tTrain MAE: 0.1816125\n",
      "\tValidation MAE: 0.1796\n",
      "\tTrain MSE: 0.7793125\n",
      "\tValidation MSE: 0.9308\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Eliminated: ['summary_posWordRate', 'unixReviewTime', 'reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.8595125\n",
      "\tValidation Accuracy: 0.864\n",
      "\tTrain MAE: 0.1830875\n",
      "\tValidation MAE: 0.1788\n",
      "\tTrain MSE: 0.8068875\n",
      "\tValidation MSE: 0.81785\n",
      "\n",
      "\n",
      "Features Eliminated: ['summary_posWordCount', 'summary_posWordRate', 'unixReviewTime', 'reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.858275\n",
      "\tValidation Accuracy: 0.86325\n",
      "\tTrain MAE: 0.1827875\n",
      "\tValidation MAE: 0.18015\n",
      "\tTrain MSE: 0.77225\n",
      "\tValidation MSE: 0.7815\n",
      "\n",
      "\n",
      "Features Eliminated: ['rating_deviation', 'summary_posWordCount', 'summary_posWordRate', 'unixReviewTime', 'reviewText_posWordRate', 'rating', 'summary_negWordRate', 'reviewText_posWordCount', 'summary_negWordCount', 'reviewText_PunctChar_ratio', 'reviewText_count_char', 'price', 'reviewText_ExclQue_countchar', 'summary_reviewText_charRatio', 'reviewText_count_words', 'summary_ExclQue_countchar', 'unixReviewTime_delta_firstreview', 'categoryID', 'reviewText_count_firstCapital', 'summary_count_firstCapital', 'summary_capitalwords', 'summary_PunctChar_ratio', 'summary_count_punctu', 'unixReviewTime_delta_lastreview', 'summary_avgWordLength', 'reviewText_count_punctu', 'summary_reviewText_wordsRatio', 'reviewText_negWordCount', 'itemID_numReviews', 'category_numtrans', 'votes_time', 'reviewText_capitalwords', 'reviewerID_helpfulRate']\n",
      "\tTrain Accuracy: 0.85410625\n",
      "\tValidation Accuracy: 0.852775\n",
      "\tTrain MAE: 0.1873\n",
      "\tValidation MAE: 0.18855\n",
      "\tTrain MSE: 0.6837875\n",
      "\tValidation MSE: 0.8667\n",
      "\n",
      "\n",
      "CPU times: user 30min 25s, sys: 14.3 s, total: 30min 39s\n",
      "Wall time: 9min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define hyperparameters to test\n",
    "max_depth = 10\n",
    "n_estimators = 100\n",
    "\n",
    "# save list of features eliminated and the calulcated MAE\n",
    "features_list_mae_mse = []\n",
    "\n",
    "# eliminate each feature, one-by-one, starting with the highest MAE feature to the lowest on the validation dataset\n",
    "for f in range(len(all_features)-2): # features list is sorted with MAE ascending\n",
    "    \n",
    "    # eliminate starting from the end\n",
    "    temp_featurelist = all_features[:len(all_features)-f]\n",
    "    \n",
    "    # get feature name\n",
    "    if f == 0:\n",
    "        f_eliminated = 'None'\n",
    "    else:\n",
    "        f_eliminated = all_features[-f:]\n",
    "    \n",
    "    # get metrics (train_accuracy, test_accuracy, train_mae, test_mae, train_mse, test_mse, y_pred_test)\n",
    "    metrics_tuple = perfmetrics_RFmodel(max_depth, n_estimators, X_train_filt[temp_featurelist], \n",
    "                                        y_train_ratio_filt, X_train[temp_featurelist], \n",
    "                                        y_train, X_val[temp_featurelist], y_val)\n",
    "    \n",
    "    # print metrics \n",
    "    print('Features Eliminated: {}'.format(f_eliminated))\n",
    "    print('\\tTrain Accuracy: {}'.format(metrics_tuple[0]))\n",
    "    print('\\tValidation Accuracy: {}'.format(metrics_tuple[1]))\n",
    "    print('\\tTrain MAE: {}'.format(metrics_tuple[2]))\n",
    "    print('\\tValidation MAE: {}'.format(metrics_tuple[3]))\n",
    "    print('\\tTrain MSE: {}'.format(metrics_tuple[4]))\n",
    "    print('\\tValidation MSE: {}'.format(metrics_tuple[5]))\n",
    "    print('\\n')\n",
    "    \n",
    "    # save mae and eliminated features lists\n",
    "    features_list_mae_mse.append((metrics_tuple[3], metrics_tuple[5], f_eliminated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1. Ablation study results, MAE and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics vs. number of features removed\n",
    "\n",
    "# get number of features and mae values\n",
    "feature_counts = [len(i[2]) if i[2] != 'None' else 0 for i in features_list_mae_mse]\n",
    "mae_values = [i[0] for i in features_list_mae_mse]\n",
    "mse_values = [i[1] for i in features_list_mae_mse]\n",
    "\n",
    "# plot MAE\n",
    "plt.figure(figsize=(15,5)) # define figure\n",
    "plt.scatter(feature_counts, mae_values, facecolors='none', edgecolors='r')\n",
    "plt.plot(feature_counts, mae_values, '--', color='r')\n",
    "plt.title('Ablation Study Results - One Feature Removed at a Time', fontsize=14)\n",
    "plt.xlabel('Number of Features Eliminated', fontsize=14)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot MSE\n",
    "plt.figure(figsize=(15,5)) # define figure\n",
    "plt.scatter(feature_counts, mse_values, facecolors='none', edgecolors='b')\n",
    "plt.plot(feature_counts, mse_values, '--', color='b')\n",
    "plt.title('Ablation Study Results - One Feature Removed at a Time', fontsize=14)\n",
    "plt.xlabel('Number of Features Eliminated', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 11 features were eliminated and not included downstream\n",
      "\n",
      "22 new features were selected, they are listed below:\n",
      "{'itemID', 'reviewText_count_char', 'summary_negWordCount', 'summary_PunctChar_ratio', 'summary_negWordRate', 'price', 'reviewerID', 'summary_capitalwords', 'reviewText_posWordRate', 'reviewText_ExclQue_countchar', 'outOf_feature', 'unixReviewTime', 'rating_deviation', 'summary_posWordCount', 'reviewText_PunctChar_ratio', 'summary_posWordRate', 'summary_ExclQue_countchar', 'categoryID', 'reviewText_posWordCount', 'unixReviewTime_delta_firstreview', 'summary_count_firstCapital', 'summary_reviewText_charRatio', 'rating', 'reviewText_count_words', 'reviewText_count_firstCapital'}\n"
     ]
    }
   ],
   "source": [
    "# define features to keep based on ablation study results, criteria = lowest MAE\n",
    "features_tokeep = set(all_features) - set(sorted(features_list_mae_mse, key= lambda x: x[0])[0][2])\n",
    "\n",
    "print('A total of {} features were eliminated and not included downstream'\n",
    "          .format(len(all_features)-len(features_tokeep)))\n",
    "print('\\n{} new features were selected, they are listed below:'.format(len(features_tokeep)-3))\n",
    "print(features_tokeep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning - Traning and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10, n_estimators:100\n",
      "\tTrain Accuracy: 0.87045625\n",
      "\tValidation Accuracy: 0.86675\n",
      "\tTrain MAE: 0.1618625\n",
      "\tValidation MAE: 0.172775\n",
      "\tTrain MSE: 0.5269875\n",
      "\tValidation MSE: 0.668575\n",
      "\n",
      "\n",
      "max_depth: 10, n_estimators:200\n",
      "\tTrain Accuracy: 0.87031875\n",
      "\tValidation Accuracy: 0.86695\n",
      "\tTrain MAE: 0.1617375\n",
      "\tValidation MAE: 0.1735\n",
      "\tTrain MSE: 0.492075\n",
      "\tValidation MSE: 0.7034\n",
      "\n",
      "\n",
      "max_depth: 10, n_estimators:400\n",
      "\tTrain Accuracy: 0.87043125\n",
      "\tValidation Accuracy: 0.867\n",
      "\tTrain MAE: 0.1617375\n",
      "\tValidation MAE: 0.1734\n",
      "\tTrain MSE: 0.4919125\n",
      "\tValidation MSE: 0.70715\n",
      "\n",
      "\n",
      "max_depth: 10, n_estimators:600\n",
      "\tTrain Accuracy: 0.8703125\n",
      "\tValidation Accuracy: 0.867025\n",
      "\tTrain MAE: 0.1616375\n",
      "\tValidation MAE: 0.17395\n",
      "\tTrain MSE: 0.489175\n",
      "\tValidation MSE: 0.7656\n",
      "\n",
      "\n",
      "max_depth: 12, n_estimators:100\n",
      "\tTrain Accuracy: 0.8752625\n",
      "\tValidation Accuracy: 0.8676\n",
      "\tTrain MAE: 0.15469375\n",
      "\tValidation MAE: 0.173075\n",
      "\tTrain MSE: 0.48120625\n",
      "\tValidation MSE: 0.726925\n",
      "\n",
      "\n",
      "max_depth: 12, n_estimators:200\n",
      "\tTrain Accuracy: 0.875175\n",
      "\tValidation Accuracy: 0.867475\n",
      "\tTrain MAE: 0.15435625\n",
      "\tValidation MAE: 0.172575\n",
      "\tTrain MSE: 0.43398125\n",
      "\tValidation MSE: 0.701275\n",
      "\n",
      "\n",
      "max_depth: 12, n_estimators:400\n",
      "\tTrain Accuracy: 0.87535\n",
      "\tValidation Accuracy: 0.8675\n",
      "\tTrain MAE: 0.15424375\n",
      "\tValidation MAE: 0.1726\n",
      "\tTrain MSE: 0.46011875\n",
      "\tValidation MSE: 0.7209\n",
      "\n",
      "\n",
      "max_depth: 12, n_estimators:600\n",
      "\tTrain Accuracy: 0.87516875\n",
      "\tValidation Accuracy: 0.867825\n",
      "\tTrain MAE: 0.15446875\n",
      "\tValidation MAE: 0.172625\n",
      "\tTrain MSE: 0.46076875\n",
      "\tValidation MSE: 0.702175\n",
      "\n",
      "\n",
      "CPU times: user 30min 28s, sys: 10.9 s, total: 30min 39s\n",
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run test and validation dataset to tune parameters: max_depth, n_estimators\n",
    "hyper_parameter_list = []\n",
    "y_pred_val_list = []\n",
    "for max_depth in [10,12]:\n",
    "    for n_estimators in [100, 200, 400, 600]:\n",
    "        \n",
    "        # get metrics (train_accuracy, test_accuracy, train_mae, test_mae, train_mse, test_mse, y_pred_test)\n",
    "        metrics_tuple = perfmetrics_RFmodel(max_depth, n_estimators, X_train_filt[features_tokeep], \n",
    "                                            y_train_ratio_filt, X_train[features_tokeep], \n",
    "                                            y_train, X_val[features_tokeep], y_val)\n",
    "        # print metrics\n",
    "        print('max_depth: {}, n_estimators:{}'.format(max_depth, n_estimators))\n",
    "        print('\\tTrain Accuracy: {}'.format(metrics_tuple[0]))\n",
    "        print('\\tValidation Accuracy: {}'.format(metrics_tuple[1]))\n",
    "        print('\\tTrain MAE: {}'.format(metrics_tuple[2]))\n",
    "        print('\\tValidation MAE: {}'.format(metrics_tuple[3]))\n",
    "        print('\\tTrain MSE: {}'.format(metrics_tuple[4]))\n",
    "        print('\\tValidation MSE: {}'.format(metrics_tuple[5]))\n",
    "        print('\\n')\n",
    "        \n",
    "        # save hyperparameters, mae, and predictions\n",
    "        hyper_parameter_list.append((max_depth, n_estimators, metrics_tuple[3], metrics_tuple[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best hyper parameters for test data evaluation\n",
    "best_params = sorted(hyper_parameter_list, key = lambda x: x[2])[0]\n",
    "\n",
    "max_depth = best_params[0]\n",
    "n_estimators = best_params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classification on Validation Data - Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions on validation data\n",
    "y_pred_val = [i for i in hyper_parameter_list if i[0] == max_depth and i[1] == n_estimators][0][3]\n",
    "\n",
    "len(y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/gio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/gio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "# compute evaluation metrics\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "# TPR, sensitivity, or recall\n",
    "TPR = TP / (TP + FN)\n",
    "\n",
    "# TNR or specificity\n",
    "TNR = TN / (TN + FP) \n",
    "\n",
    "# precision\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# FPR\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "# FNR\n",
    "FNR = FN / (TP + FN)\n",
    "\n",
    "# accuracy\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3. Confusion matrix and classification metrics for each number of vote (outOf feature, label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>precision</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label (Number of Votes)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>1530</td>\n",
       "      <td>27595</td>\n",
       "      <td>10839</td>\n",
       "      <td>0.947468</td>\n",
       "      <td>0.996690</td>\n",
       "      <td>0.998697</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.052532</td>\n",
       "      <td>0.960850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1928</td>\n",
       "      <td>625</td>\n",
       "      <td>4689</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.882386</td>\n",
       "      <td>0.944416</td>\n",
       "      <td>0.708629</td>\n",
       "      <td>0.055584</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>0.936175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>863</td>\n",
       "      <td>795</td>\n",
       "      <td>1034</td>\n",
       "      <td>37308</td>\n",
       "      <td>0.565336</td>\n",
       "      <td>0.977391</td>\n",
       "      <td>0.545071</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.434664</td>\n",
       "      <td>0.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620</td>\n",
       "      <td>387</td>\n",
       "      <td>651</td>\n",
       "      <td>38342</td>\n",
       "      <td>0.627168</td>\n",
       "      <td>0.984087</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>0.372832</td>\n",
       "      <td>0.974825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>397</td>\n",
       "      <td>360</td>\n",
       "      <td>219</td>\n",
       "      <td>39024</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.989929</td>\n",
       "      <td>0.355519</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.621762</td>\n",
       "      <td>0.981075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>182</td>\n",
       "      <td>315</td>\n",
       "      <td>89</td>\n",
       "      <td>39414</td>\n",
       "      <td>0.220297</td>\n",
       "      <td>0.995404</td>\n",
       "      <td>0.328413</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.779703</td>\n",
       "      <td>0.987575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209</td>\n",
       "      <td>169</td>\n",
       "      <td>101</td>\n",
       "      <td>39521</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.994739</td>\n",
       "      <td>0.325806</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.625926</td>\n",
       "      <td>0.990550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138</td>\n",
       "      <td>161</td>\n",
       "      <td>56</td>\n",
       "      <td>39645</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.996531</td>\n",
       "      <td>0.288660</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.992525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>46</td>\n",
       "      <td>39734</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82</td>\n",
       "      <td>97</td>\n",
       "      <td>29</td>\n",
       "      <td>39792</td>\n",
       "      <td>0.230159</td>\n",
       "      <td>0.997944</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.995525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>88</td>\n",
       "      <td>28</td>\n",
       "      <td>39817</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.998320</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.996125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>39838</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>0.996750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>39878</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.997275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>39888</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.997550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>39912</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.998025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>39907</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.998849</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>39910</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.999124</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>39940</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.998750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>39942</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>39948</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>39964</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>39959</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.999100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>39959</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.999125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>39967</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.999250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>39972</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.999325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>39964</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39981</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.999550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>39973</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>39976</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.999475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>39975</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.999425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>39979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>39984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>39980</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.999575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>39985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39990</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39991</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>39983</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.999650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>39987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>39984</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.999625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39993</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>39991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39988</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39991</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39992</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.999825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39996</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FP    FN     TP     TN       TPR       TNR  \\\n",
       "Label (Number of Votes)                                                 \n",
       "0                          36  1530  27595  10839  0.947468  0.996690   \n",
       "1                        1928   625   4689  32758  0.882386  0.944416   \n",
       "2                         863   795   1034  37308  0.565336  0.977391   \n",
       "3                         620   387    651  38342  0.627168  0.984087   \n",
       "4                         397   360    219  39024  0.378238  0.989929   \n",
       "5                         182   315     89  39414  0.220297  0.995404   \n",
       "6                         209   169    101  39521  0.374074  0.994739   \n",
       "7                         138   161     56  39645  0.258065  0.996531   \n",
       "8                         111   109     46  39734  0.296774  0.997214   \n",
       "9                          82    97     29  39792  0.230159  0.997944   \n",
       "10                         67    88     28  39817  0.241379  0.998320   \n",
       "11                         71    59     32  39838  0.351648  0.998221   \n",
       "12                         44    65     13  39878  0.166667  0.998898   \n",
       "13                         49    49     14  39888  0.222222  0.998773   \n",
       "14                         38    41      9  39912  0.180000  0.999049   \n",
       "15                         46    34     13  39907  0.276596  0.998849   \n",
       "16                         35    48      7  39910  0.127273  0.999124   \n",
       "17                         28    22     10  39940  0.312500  0.999299   \n",
       "18                         25    27      6  39942  0.181818  0.999374   \n",
       "19                         28    16      8  39948  0.333333  0.999300   \n",
       "20                         15    17      4  39964  0.190476  0.999625   \n",
       "21                         18    18      5  39959  0.217391  0.999550   \n",
       "22                         22    13      6  39959  0.315789  0.999450   \n",
       "23                         15    15      3  39967  0.166667  0.999625   \n",
       "24                         13    14      1  39972  0.066667  0.999675   \n",
       "25                         15    17      4  39964  0.190476  0.999625   \n",
       "26                          6    12      1  39981  0.076923  0.999850   \n",
       "27                         14    10      3  39973  0.230769  0.999650   \n",
       "28                         11    10      3  39976  0.230769  0.999725   \n",
       "29                         14     9      2  39975  0.181818  0.999650   \n",
       "30                          9    12      0  39979  0.000000  0.999775   \n",
       "31                          7     9      0  39984  0.000000  0.999825   \n",
       "32                          8     9      3  39980  0.250000  0.999800   \n",
       "33                          4    11      0  39985  0.000000  0.999900   \n",
       "34                          4     5      1  39990  0.166667  0.999900   \n",
       "35                          5     2      2  39991  0.500000  0.999875   \n",
       "36                         12     2      3  39983  0.600000  0.999700   \n",
       "37                          4     9      0  39987  0.000000  0.999900   \n",
       "38                          7     8      1  39984  0.111111  0.999825   \n",
       "39                          2     3      0  39995  0.000000  0.999950   \n",
       "40                          3     3      0  39994  0.000000  0.999925   \n",
       "41                          2     4      1  39993  0.200000  0.999950   \n",
       "42                          4     2      0  39994  0.000000  0.999900   \n",
       "43                          4     1      0  39995  0.000000  0.999900   \n",
       "44                          4     5      0  39991  0.000000  0.999900   \n",
       "45                          8     3      1  39988  0.250000  0.999800   \n",
       "46                          4     4      1  39991  0.200000  0.999900   \n",
       "47                          2     4      0  39994  0.000000  0.999950   \n",
       "48                          3     4      1  39992  0.200000  0.999925   \n",
       "49                          1     3      0  39996  0.000000  0.999975   \n",
       "50                          0     3      1  39996  0.250000  1.000000   \n",
       "51                          1     2      0  39997  0.000000  0.999975   \n",
       "52                          7     3      0  39990  0.000000  0.999825   \n",
       "53                          4     3      0  39993  0.000000  0.999900   \n",
       "54                          2     3      0  39995  0.000000  0.999950   \n",
       "55                          3     4      0  39993  0.000000  0.999925   \n",
       "56                          2     2      0  39996  0.000000  0.999950   \n",
       "57                          1     1      0  39998  0.000000  0.999975   \n",
       "58                          2     2      1  39995  0.333333  0.999950   \n",
       "59                          2     1      0  39997  0.000000  0.999950   \n",
       "60                          2     0      0  39998       NaN  0.999950   \n",
       "62                          1     3      0  39996  0.000000  0.999975   \n",
       "63                          1     0      0  39999       NaN  0.999975   \n",
       "64                          0     4      0  39996  0.000000  1.000000   \n",
       "65                          1     0      0  39999       NaN  0.999975   \n",
       "66                          1     2      0  39997  0.000000  0.999975   \n",
       "67                          1     0      0  39999       NaN  0.999975   \n",
       "68                          1     0      0  39999       NaN  0.999975   \n",
       "69                          0     1      0  39999  0.000000  1.000000   \n",
       "70                          1     0      0  39999       NaN  0.999975   \n",
       "71                          1     1      0  39998  0.000000  0.999975   \n",
       "72                          1     2      0  39997  0.000000  0.999975   \n",
       "73                          1     1      0  39998  0.000000  0.999975   \n",
       "74                          0     1      0  39999  0.000000  1.000000   \n",
       "75                          1     1      0  39998  0.000000  0.999975   \n",
       "76                          1     1      0  39998  0.000000  0.999975   \n",
       "77                          1     0      0  39999       NaN  0.999975   \n",
       "79                          2     0      0  39998       NaN  0.999950   \n",
       "81                          0     1      0  39999  0.000000  1.000000   \n",
       "83                          0     1      0  39999  0.000000  1.000000   \n",
       "84                          0     1      0  39999  0.000000  1.000000   \n",
       "86                          1     0      0  39999       NaN  0.999975   \n",
       "87                          1     0      0  39999       NaN  0.999975   \n",
       "88                          1     0      0  39999       NaN  0.999975   \n",
       "90                          1     0      0  39999       NaN  0.999975   \n",
       "92                          0     3      0  39997  0.000000  1.000000   \n",
       "93                          0     1      0  39999  0.000000  1.000000   \n",
       "94                          1     0      0  39999       NaN  0.999975   \n",
       "96                          0     0      1  39999  1.000000  1.000000   \n",
       "97                          0     1      0  39999  0.000000  1.000000   \n",
       "98                          1     1      0  39998  0.000000  0.999975   \n",
       "102                         0     0      1  39999  1.000000  1.000000   \n",
       "104                         1     0      0  39999       NaN  0.999975   \n",
       "105                         1     0      0  39999       NaN  0.999975   \n",
       "106                         1     0      0  39999       NaN  0.999975   \n",
       "108                         1     1      0  39998  0.000000  0.999975   \n",
       "109                         1     1      0  39998  0.000000  0.999975   \n",
       "112                         0     1      0  39999  0.000000  1.000000   \n",
       "113                         0     1      0  39999  0.000000  1.000000   \n",
       "114                         1     0      0  39999       NaN  0.999975   \n",
       "116                         0     1      0  39999  0.000000  1.000000   \n",
       "117                         0     1      0  39999  0.000000  1.000000   \n",
       "118                         1     0      0  39999       NaN  0.999975   \n",
       "125                         0     1      0  39999  0.000000  1.000000   \n",
       "130                         1     0      0  39999       NaN  0.999975   \n",
       "135                         0     1      0  39999  0.000000  1.000000   \n",
       "138                         1     0      0  39999       NaN  0.999975   \n",
       "160                         1     1      0  39998  0.000000  0.999975   \n",
       "161                         1     0      0  39999       NaN  0.999975   \n",
       "165                         0     1      0  39999  0.000000  1.000000   \n",
       "182                         1     0      0  39999       NaN  0.999975   \n",
       "187                         0     1      0  39999  0.000000  1.000000   \n",
       "204                         1     0      0  39999       NaN  0.999975   \n",
       "209                         1     0      0  39999       NaN  0.999975   \n",
       "221                         0     1      0  39999  0.000000  1.000000   \n",
       "227                         0     1      0  39999  0.000000  1.000000   \n",
       "231                         1     0      0  39999       NaN  0.999975   \n",
       "236                         0     1      0  39999  0.000000  1.000000   \n",
       "242                         1     0      0  39999       NaN  0.999975   \n",
       "286                         0     1      0  39999  0.000000  1.000000   \n",
       "377                         1     0      0  39999       NaN  0.999975   \n",
       "384                         0     1      0  39999  0.000000  1.000000   \n",
       "\n",
       "                         precision       FPR       FNR  accuracy  \n",
       "Label (Number of Votes)                                           \n",
       "0                         0.998697  0.003310  0.052532  0.960850  \n",
       "1                         0.708629  0.055584  0.117614  0.936175  \n",
       "2                         0.545071  0.022609  0.434664  0.958550  \n",
       "3                         0.512195  0.015913  0.372832  0.974825  \n",
       "4                         0.355519  0.010071  0.621762  0.981075  \n",
       "5                         0.328413  0.004596  0.779703  0.987575  \n",
       "6                         0.325806  0.005261  0.625926  0.990550  \n",
       "7                         0.288660  0.003469  0.741935  0.992525  \n",
       "8                         0.292994  0.002786  0.703226  0.994500  \n",
       "9                         0.261261  0.002056  0.769841  0.995525  \n",
       "10                        0.294737  0.001680  0.758621  0.996125  \n",
       "11                        0.310680  0.001779  0.648352  0.996750  \n",
       "12                        0.228070  0.001102  0.833333  0.997275  \n",
       "13                        0.222222  0.001227  0.777778  0.997550  \n",
       "14                        0.191489  0.000951  0.820000  0.998025  \n",
       "15                        0.220339  0.001151  0.723404  0.998000  \n",
       "16                        0.166667  0.000876  0.872727  0.997925  \n",
       "17                        0.263158  0.000701  0.687500  0.998750  \n",
       "18                        0.193548  0.000626  0.818182  0.998700  \n",
       "19                        0.222222  0.000700  0.666667  0.998900  \n",
       "20                        0.210526  0.000375  0.809524  0.999200  \n",
       "21                        0.217391  0.000450  0.782609  0.999100  \n",
       "22                        0.214286  0.000550  0.684211  0.999125  \n",
       "23                        0.166667  0.000375  0.833333  0.999250  \n",
       "24                        0.071429  0.000325  0.933333  0.999325  \n",
       "25                        0.210526  0.000375  0.809524  0.999200  \n",
       "26                        0.142857  0.000150  0.923077  0.999550  \n",
       "27                        0.176471  0.000350  0.769231  0.999400  \n",
       "28                        0.214286  0.000275  0.769231  0.999475  \n",
       "29                        0.125000  0.000350  0.818182  0.999425  \n",
       "30                        0.000000  0.000225  1.000000  0.999475  \n",
       "31                        0.000000  0.000175  1.000000  0.999600  \n",
       "32                        0.272727  0.000200  0.750000  0.999575  \n",
       "33                        0.000000  0.000100  1.000000  0.999625  \n",
       "34                        0.200000  0.000100  0.833333  0.999775  \n",
       "35                        0.285714  0.000125  0.500000  0.999825  \n",
       "36                        0.200000  0.000300  0.400000  0.999650  \n",
       "37                        0.000000  0.000100  1.000000  0.999675  \n",
       "38                        0.125000  0.000175  0.888889  0.999625  \n",
       "39                        0.000000  0.000050  1.000000  0.999875  \n",
       "40                        0.000000  0.000075  1.000000  0.999850  \n",
       "41                        0.333333  0.000050  0.800000  0.999850  \n",
       "42                        0.000000  0.000100  1.000000  0.999850  \n",
       "43                        0.000000  0.000100  1.000000  0.999875  \n",
       "44                        0.000000  0.000100  1.000000  0.999775  \n",
       "45                        0.111111  0.000200  0.750000  0.999725  \n",
       "46                        0.200000  0.000100  0.800000  0.999800  \n",
       "47                        0.000000  0.000050  1.000000  0.999850  \n",
       "48                        0.250000  0.000075  0.800000  0.999825  \n",
       "49                        0.000000  0.000025  1.000000  0.999900  \n",
       "50                        1.000000  0.000000  0.750000  0.999925  \n",
       "51                        0.000000  0.000025  1.000000  0.999925  \n",
       "52                        0.000000  0.000175  1.000000  0.999750  \n",
       "53                        0.000000  0.000100  1.000000  0.999825  \n",
       "54                        0.000000  0.000050  1.000000  0.999875  \n",
       "55                        0.000000  0.000075  1.000000  0.999825  \n",
       "56                        0.000000  0.000050  1.000000  0.999900  \n",
       "57                        0.000000  0.000025  1.000000  0.999950  \n",
       "58                        0.333333  0.000050  0.666667  0.999900  \n",
       "59                        0.000000  0.000050  1.000000  0.999925  \n",
       "60                        0.000000  0.000050       NaN  0.999950  \n",
       "62                        0.000000  0.000025  1.000000  0.999900  \n",
       "63                        0.000000  0.000025       NaN  0.999975  \n",
       "64                             NaN  0.000000  1.000000  0.999900  \n",
       "65                        0.000000  0.000025       NaN  0.999975  \n",
       "66                        0.000000  0.000025  1.000000  0.999925  \n",
       "67                        0.000000  0.000025       NaN  0.999975  \n",
       "68                        0.000000  0.000025       NaN  0.999975  \n",
       "69                             NaN  0.000000  1.000000  0.999975  \n",
       "70                        0.000000  0.000025       NaN  0.999975  \n",
       "71                        0.000000  0.000025  1.000000  0.999950  \n",
       "72                        0.000000  0.000025  1.000000  0.999925  \n",
       "73                        0.000000  0.000025  1.000000  0.999950  \n",
       "74                             NaN  0.000000  1.000000  0.999975  \n",
       "75                        0.000000  0.000025  1.000000  0.999950  \n",
       "76                        0.000000  0.000025  1.000000  0.999950  \n",
       "77                        0.000000  0.000025       NaN  0.999975  \n",
       "79                        0.000000  0.000050       NaN  0.999950  \n",
       "81                             NaN  0.000000  1.000000  0.999975  \n",
       "83                             NaN  0.000000  1.000000  0.999975  \n",
       "84                             NaN  0.000000  1.000000  0.999975  \n",
       "86                        0.000000  0.000025       NaN  0.999975  \n",
       "87                        0.000000  0.000025       NaN  0.999975  \n",
       "88                        0.000000  0.000025       NaN  0.999975  \n",
       "90                        0.000000  0.000025       NaN  0.999975  \n",
       "92                             NaN  0.000000  1.000000  0.999925  \n",
       "93                             NaN  0.000000  1.000000  0.999975  \n",
       "94                        0.000000  0.000025       NaN  0.999975  \n",
       "96                        1.000000  0.000000  0.000000  1.000000  \n",
       "97                             NaN  0.000000  1.000000  0.999975  \n",
       "98                        0.000000  0.000025  1.000000  0.999950  \n",
       "102                       1.000000  0.000000  0.000000  1.000000  \n",
       "104                       0.000000  0.000025       NaN  0.999975  \n",
       "105                       0.000000  0.000025       NaN  0.999975  \n",
       "106                       0.000000  0.000025       NaN  0.999975  \n",
       "108                       0.000000  0.000025  1.000000  0.999950  \n",
       "109                       0.000000  0.000025  1.000000  0.999950  \n",
       "112                            NaN  0.000000  1.000000  0.999975  \n",
       "113                            NaN  0.000000  1.000000  0.999975  \n",
       "114                       0.000000  0.000025       NaN  0.999975  \n",
       "116                            NaN  0.000000  1.000000  0.999975  \n",
       "117                            NaN  0.000000  1.000000  0.999975  \n",
       "118                       0.000000  0.000025       NaN  0.999975  \n",
       "125                            NaN  0.000000  1.000000  0.999975  \n",
       "130                       0.000000  0.000025       NaN  0.999975  \n",
       "135                            NaN  0.000000  1.000000  0.999975  \n",
       "138                       0.000000  0.000025       NaN  0.999975  \n",
       "160                       0.000000  0.000025  1.000000  0.999950  \n",
       "161                       0.000000  0.000025       NaN  0.999975  \n",
       "165                            NaN  0.000000  1.000000  0.999975  \n",
       "182                       0.000000  0.000025       NaN  0.999975  \n",
       "187                            NaN  0.000000  1.000000  0.999975  \n",
       "204                       0.000000  0.000025       NaN  0.999975  \n",
       "209                       0.000000  0.000025       NaN  0.999975  \n",
       "221                            NaN  0.000000  1.000000  0.999975  \n",
       "227                            NaN  0.000000  1.000000  0.999975  \n",
       "231                       0.000000  0.000025       NaN  0.999975  \n",
       "236                            NaN  0.000000  1.000000  0.999975  \n",
       "242                       0.000000  0.000025       NaN  0.999975  \n",
       "286                            NaN  0.000000  1.000000  0.999975  \n",
       "377                       0.000000  0.000025       NaN  0.999975  \n",
       "384                            NaN  0.000000  1.000000  0.999975  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "columns = ['FP', 'FN', 'TP', 'TN', 'TPR', 'TNR', 'precision', 'FPR', 'FNR', 'accuracy']\n",
    "rows = set(y_val).union(set(y_pred_val))\n",
    "data = list(zip(FP, FN, TP, TN, TPR, TNR, precision, FPR, FNR, accuracy))\n",
    "df = pd.DataFrame(data=data, index=rows, columns=columns)\n",
    "df.index.names = ['Label (Number of Votes)']\n",
    "\n",
    "# print\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2. Precision and recall for random forest model implementation (max_depth: 12, n_estimators: 200, number of features: 22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot precision and recall\n",
    "\n",
    "plt.figure(figsize=(15,7)) # define figure\n",
    "\n",
    "# precision\n",
    "plt.scatter(list(rows), precision, facecolors='none', edgecolors='b')\n",
    "\n",
    "# recall\n",
    "plt.scatter(list(rows), TPR, facecolors='none', edgecolors='r')\n",
    "\n",
    "# add labels\n",
    "plt.legend(['Precision', 'Recall'], fontsize=14)\n",
    "plt.title('Precision and Recall for Random Forest Model on Validation Dataset', fontsize=14)\n",
    "plt.xlabel('Number of Votes (Labels)', fontsize=14)\n",
    "plt.ylabel('Evaluation Metric', fontsize=14)\n",
    "\n",
    "# show plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 4s, sys: 4.61 s, total: 4min 8s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get indices\n",
    "idx = np.array([i['outOf'] for i in train_features.helpful]) > 0\n",
    "\n",
    "# create features\n",
    "X_train_val = Get_features(train_features)\n",
    "X_test = Get_features(test)\n",
    "\n",
    "# create labels\n",
    "y_train_val = [i['nHelpful'] for i in train_labels]\n",
    "y_test = None\n",
    "\n",
    "# find filtered test data\n",
    "X_train_val_filt = Get_features(train_features.loc[idx,:])\n",
    "y_train_val_ratio_filt = Get_labels_ratio(list(compress(train_labels, idx))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 12, n_estimators:200\n",
      "Train Accuracy: 0.875125\n",
      "Train MAE: 0.15479\n",
      "Train MSE: 0.41986\n",
      "\n",
      "\n",
      "CPU times: user 3min 18s, sys: 1.59 s, total: 3min 20s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# (train_accuracy, train_mae, train_mse, y_pred_test)\n",
    "metrics_tuple = perfmetrics_RFmodel(max_depth, n_estimators, X_train_val_filt[features_tokeep], \n",
    "                                    y_train_val_ratio_filt, X_train_val[features_tokeep], \n",
    "                                    y_train_val, X_test[features_tokeep], y_test)\n",
    "# print metrics\n",
    "print('max_depth: {}, n_estimators:{}'.format(max_depth, n_estimators))\n",
    "print('Train Accuracy: {}'.format(metrics_tuple[0]))\n",
    "print('Train MAE: {}'.format(metrics_tuple[1]))\n",
    "print('Train MSE: {}'.format(metrics_tuple[2]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions on file \"predictions_Helpful.txt\"\n",
    "save_predictions(metrics_tuple[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
