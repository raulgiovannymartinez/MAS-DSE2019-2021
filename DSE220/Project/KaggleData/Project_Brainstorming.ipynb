{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, laplacian_kernel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "# allHelpful = []\n",
    "# userHelpful = defaultdict(list)\n",
    "\n",
    "# for l in readGz(\"train.json.gz\"):\n",
    "#   user,item = l['reviewerID'],l['itemID']\n",
    "#   allHelpful.append(l['helpful'])\n",
    "#   userHelpful[user].append(l['helpful'])\n",
    "\n",
    "# averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "# userRate = {}\n",
    "# for u in userHelpful:\n",
    "#   totalU = sum([x['outOf'] for x in userHelpful[u]])\n",
    "#   if totalU > 0:\n",
    "#     userRate[u] = sum([x['nHelpful'] for x in userHelpful[u]]) * 1.0 / totalU\n",
    "#   else:\n",
    "#     userRate[u] = averageRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "# df = getDF('train.json.gz')\n",
    "# test_df = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a simple model and calculate MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 2.3 s, total: 26.9 s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = getDF('train.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are cute, but they are a little small.  When I put them on, my legs stretch the fabric making the black fade out.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Sports &amp; Outdoors, Other Sports, Dance, Clot...</td>\n",
       "      <td>I520932398</td>\n",
       "      <td>U816789534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I ordered according to the size chart but it's...</td>\n",
       "      <td>R157684793</td>\n",
       "      <td>07 15, 2011</td>\n",
       "      <td>Too small</td>\n",
       "      <td>1310688000</td>\n",
       "      <td>{'outOf': 2}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Sports &amp; Outdoors, Clothing, Women, Hoodies]...</td>\n",
       "      <td>I969532331</td>\n",
       "      <td>U987148846</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Super thin but really cute and not cheap-looki...</td>\n",
       "      <td>R732719858</td>\n",
       "      <td>07 17, 2013</td>\n",
       "      <td>Fun hoodie</td>\n",
       "      <td>1374019200</td>\n",
       "      <td>{'outOf': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Accessorie...</td>\n",
       "      <td>I149943341</td>\n",
       "      <td>U628436634</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was a present for my sis, and she loves Fle...</td>\n",
       "      <td>R352659313</td>\n",
       "      <td>12 8, 2013</td>\n",
       "      <td>A Perfect hook up</td>\n",
       "      <td>1386460800</td>\n",
       "      <td>{'outOf': 1}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Accessorie...</td>\n",
       "      <td>I909025835</td>\n",
       "      <td>U924107228</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love this thing!  I guess they don't make th...</td>\n",
       "      <td>R277416618</td>\n",
       "      <td>11 22, 2012</td>\n",
       "      <td>I love this thing...</td>\n",
       "      <td>1353542400</td>\n",
       "      <td>{'outOf': 1}</td>\n",
       "      <td>7.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>I228439768</td>\n",
       "      <td>U060135484</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked it and I wear it...it's a little bit s...</td>\n",
       "      <td>R645892076</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>I liked it...</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>{'outOf': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryID                                         categories      itemID  \\\n",
       "0           0  [[Sports & Outdoors, Other Sports, Dance, Clot...  I520932398   \n",
       "1           0  [[Sports & Outdoors, Clothing, Women, Hoodies]...  I969532331   \n",
       "2           0  [[Clothing, Shoes & Jewelry, Women, Accessorie...  I149943341   \n",
       "3           0  [[Clothing, Shoes & Jewelry, Women, Accessorie...  I909025835   \n",
       "4           0  [[Clothing, Shoes & Jewelry, Women, Clothing, ...  I228439768   \n",
       "\n",
       "   reviewerID  rating                                         reviewText  \\\n",
       "0  U816789534     3.0  I ordered according to the size chart but it's...   \n",
       "1  U987148846     4.0  Super thin but really cute and not cheap-looki...   \n",
       "2  U628436634     5.0  It was a present for my sis, and she loves Fle...   \n",
       "3  U924107228     5.0  I love this thing!  I guess they don't make th...   \n",
       "4  U060135484     4.0  I liked it and I wear it...it's a little bit s...   \n",
       "\n",
       "   reviewHash   reviewTime               summary  unixReviewTime  \\\n",
       "0  R157684793  07 15, 2011             Too small      1310688000   \n",
       "1  R732719858  07 17, 2013            Fun hoodie      1374019200   \n",
       "2  R352659313   12 8, 2013     A Perfect hook up      1386460800   \n",
       "3  R277416618  11 22, 2012  I love this thing...      1353542400   \n",
       "4  R645892076   04 1, 2014         I liked it...      1396310400   \n",
       "\n",
       "        helpful  price  \n",
       "0  {'outOf': 2}    NaN  \n",
       "1  {'outOf': 0}    NaN  \n",
       "2  {'outOf': 1}    NaN  \n",
       "3  {'outOf': 1}   7.51  \n",
       "4  {'outOf': 0}    NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = df.drop(['helpful'], axis=1)\n",
    "df_features = df\n",
    "df_labels = df['helpful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(df_features, df_labels, \n",
    "                                                                  test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model - Finds user rate for helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "MAE for val data: 0.2633751340380996\n"
     ]
    }
   ],
   "source": [
    "# calculate MAE for baseline on validation data\n",
    "\n",
    "# find user rates for training data\n",
    "allHelpful = []\n",
    "userHelpful = defaultdict(list)\n",
    "\n",
    "user,item = X_train_raw['reviewerID'], X_train_raw['itemID']\n",
    "allHelpful = y_train_raw.values\n",
    "\n",
    "for x,y in zip(user, allHelpful):\n",
    "     userHelpful[x].append(y)\n",
    "\n",
    "averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "\n",
    "userRate = {}\n",
    "for u in userHelpful:\n",
    "    totalU = sum([x['outOf'] for x in userHelpful[u]])\n",
    "    if totalU > 0:\n",
    "        userRate[u] = sum([x['nHelpful'] for x in userHelpful[u]]) * 1.0 / totalU\n",
    "    else:\n",
    "        userRate[u] = averageRate\n",
    "        \n",
    "# predict nHelpful on validation data\n",
    "pred = []\n",
    "for u,i,outOf in zip(X_val_raw['reviewerID'], X_val_raw['itemID'], y_val_raw):\n",
    "    if u in userRate:\n",
    "        pred.append((outOf['outOf']*userRate[u]))\n",
    "    else:\n",
    "        pred.append((outOf['outOf']*averageRate))\n",
    "        \n",
    "# calculate MAE \n",
    "print('Baseline Model')\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Multiple models on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosNegWords_count_Rate(text):\n",
    "        \n",
    "    # import positive and negative word lists, define as set for higher efficiency\n",
    "    posWords_list = set([i.strip() for i in open(\"positive-words.txt\", \"r\").readlines()])\n",
    "    negWords_list = set([i.strip() for i in open(\"negative-words.txt\", \"r\", encoding=\"ISO-8859-1\").readlines()])\n",
    "    \n",
    "    # count the number of positive and negative words present in each review text\n",
    "    dict_ = defaultdict(list)\n",
    "    for review_text in text:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "        \n",
    "        # count number of positive and negative words in each review\n",
    "        pos_count, neg_count = 0, 0\n",
    "        for word in words:\n",
    "            if word in posWords_list:\n",
    "                pos_count+=1\n",
    "            elif word in negWords_list:\n",
    "                neg_count+=1\n",
    "            else: \n",
    "                continue\n",
    "        \n",
    "        # save count and rate \n",
    "        if len(words) == 0: # prevent division by zero\n",
    "            dict_['pos_count'].append(-1)\n",
    "            dict_['neg_count'].append(-1)\n",
    "            dict_['pos_rate'].append(-1)\n",
    "            dict_['neg_rate'].append(-1)\n",
    "        else:\n",
    "            dict_['pos_count'].append(pos_count)\n",
    "            dict_['neg_count'].append(neg_count)\n",
    "            dict_['pos_rate'].append(pos_count/len(words))\n",
    "            dict_['neg_rate'].append(neg_count/len(words))\n",
    "    \n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NumWords(text):\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in text:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # count number of words, excluding stopwords\n",
    "        word_count = 0\n",
    "        for word in words:\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                 word_count+=1\n",
    "                    \n",
    "        # save counts\n",
    "        list_.append(word_count)\n",
    "        \n",
    "    return list_      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_category_numtrans(category_lists):\n",
    "    \n",
    "    # get unique category lists\n",
    "    lists = []\n",
    "    for i in category_lists:\n",
    "        for j in i:\n",
    "            lists.append(tuple(j))\n",
    "\n",
    "    # make dictionary with IDs\n",
    "    categorylists_dict = {k:v for v,k in enumerate(set(lists))}\n",
    "\n",
    "    # transform list occurance to numbers using dictionary \n",
    "    category_numtrans = []\n",
    "    for i in category_lists:\n",
    "        sum_ = 0\n",
    "        for j in i:\n",
    "            sum_ += categorylists_dict[tuple(j)]\n",
    "        category_numtrans.append(sum_)\n",
    "\n",
    "    # return transformation\n",
    "    return category_numtrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_helpfulRate(col):\n",
    "    \n",
    "    allHelpful = []\n",
    "    colHelpful = defaultdict(list)\n",
    "\n",
    "    col_data = X_train_raw[col]\n",
    "    allHelpful = y_train_raw\n",
    "\n",
    "    for x,y in zip(col_data, allHelpful):\n",
    "         colHelpful[x].append(y)\n",
    "\n",
    "    averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "\n",
    "    rate = {}\n",
    "    for u in colHelpful:\n",
    "        totalU = sum([x['outOf'] for x in colHelpful[u]])\n",
    "        if totalU > 0:\n",
    "            rate[u] = sum([x['nHelpful'] for x in colHelpful[u]]) * 1.0 / totalU\n",
    "        else:\n",
    "            rate[u] = averageRate \n",
    "    \n",
    "    return rate, averageRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Helpful_rate(data, colname):\n",
    "    \n",
    "    rate_dict, avg_rate = get_helpfulRate(colname)\n",
    "\n",
    "    ratehelpful = []\n",
    "    for i in data:\n",
    "        # use average for entries not present\n",
    "        try:\n",
    "            ratehelpful.append(rate_dict[i])\n",
    "        except:\n",
    "            ratehelpful.append(avg_rate)\n",
    "            \n",
    "    return ratehelpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_punctuation_count(data):\n",
    "\n",
    "    punct_set = set(string.punctuation)\n",
    "    list_ = []\n",
    "    for str_ in data:\n",
    "        count_ = 0\n",
    "        for c in str_:\n",
    "            if c in punct_set:\n",
    "                count_+=1\n",
    "            else:\n",
    "                continue\n",
    "        list_.append(count_)\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_numreviews_summarized(data):\n",
    "\n",
    "    # initialize dict\n",
    "    dict_ = {k:0 for k in set(data)}\n",
    "    \n",
    "    # count number \n",
    "    for r in data:\n",
    "        dict_[r]+=1\n",
    "        \n",
    "    # create list\n",
    "    list_ = []\n",
    "    for r in data:\n",
    "        try:\n",
    "            list_.append(dict_[r])\n",
    "        except:\n",
    "            list_.append(0)\n",
    "    \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_product_ratingDeviation(df):\n",
    "\n",
    "    ProdRating_mean_dict = df[['itemID', 'rating']].groupby(['itemID']).mean().rating.to_dict()\n",
    "\n",
    "    rating_deviation = []\n",
    "    for r, p in zip(df.rating, df.itemID):\n",
    "        try:\n",
    "            rating_deviation.append(r - ProdRating_mean_dict[p])\n",
    "        except:\n",
    "            rating_deviation.append(-444)\n",
    "        \n",
    "    return rating_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_count_firstLetterCapital(data):\n",
    "    \n",
    "    list_ = []\n",
    "    for review in data:\n",
    "        count_ = 0\n",
    "        for word in review.split():\n",
    "            if word[0].isupper():\n",
    "                count_+=1\n",
    "        list_.append(count_)\n",
    "        \n",
    "    return list_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_avg_word_length(data):\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.lower().translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # remove stopwords\n",
    "        words = set(words) - stop_words\n",
    "                    \n",
    "        # save average length\n",
    "        try:\n",
    "            list_.append(sum([len(w) for w in words])/len(words))\n",
    "        except:\n",
    "            list_.append(-1)\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_delta_sinceFirstReview(df):\n",
    "    \n",
    "    # find time for first review in each product\n",
    "    first_product_reviewtime = df[['itemID','unixReviewTime']].groupby(['itemID']).min().unixReviewTime.to_dict()\n",
    "\n",
    "    # find delta for each review\n",
    "    delta = []\n",
    "    for i,t in zip(df.itemID, df.unixReviewTime):\n",
    "        delta.append(t-first_product_reviewtime[i])\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_delta_sinceLastReview(df):\n",
    "    \n",
    "    # create reduced df\n",
    "    new_df = df[['itemID','unixReviewTime']].groupby(['itemID'])['unixReviewTime'].apply(list)\n",
    "\n",
    "    # create dictionary with deltas\n",
    "    delta_dict = defaultdict(dict)\n",
    "    \n",
    "    for idx, times_list in zip(new_df.index, new_df):\n",
    "\n",
    "        times_list = sorted(times_list)\n",
    "        times_list_deltas = np.append(np.array([0]) , np.diff(times_list))\n",
    "\n",
    "        for t, d in zip(times_list, times_list_deltas):\n",
    "            delta_dict[idx][t] = d\n",
    "\n",
    "    # generate list with deltas matching input dataframe\n",
    "    list_ = []\n",
    "    for u,t in zip(df.itemID, df.unixReviewTime):\n",
    "        list_.append(delta_dict[u][t])\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_colsRatio(col1, col2):\n",
    "    \n",
    "    list_ = []\n",
    "    for i,j in zip(col1, col2):\n",
    "\n",
    "        try:\n",
    "            list_.append(i/j)\n",
    "        except:\n",
    "            list_.append(-1)\n",
    "\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_numCapitalwords(data):\n",
    "    \n",
    "    # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        \n",
    "        # remove punctuation symbols and spaces\n",
    "        words = [n.translate(str.maketrans('','',string.punctuation)) for n in review_text.split(' ')]\n",
    "        words = [i for i in words if i != ''] # remove spaces\n",
    "                \n",
    "        # remove stopwords\n",
    "        words = set(words) - stop_words\n",
    "        \n",
    "        # append count of upper case words\n",
    "        list_.append(len([i for i in words if i.isupper()]))\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_ExclQues_charCount(data):\n",
    "    \n",
    "    # loop over each review\n",
    "    list_ = []\n",
    "    for review_text in data:\n",
    "        # append count of question and exclamation characters\n",
    "        list_.append(review_text.count('?') + review_text.count('!'))\n",
    "        \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Get_TFIDF(text):\n",
    "    \n",
    "#     # get stopwords from nltk library\n",
    "#     nltk.download('stopwords')\n",
    "#     stopW_list = stopwords.words('english')\n",
    "    \n",
    "#     # create the transform\n",
    "#     vectorizer = TfidfVectorizer(stop_words = stopW_list, lowercase=True, smooth_idf=True)\n",
    "    \n",
    "#     # tokenize and build vocab\n",
    "#     vectorizer.fit(text)\n",
    "    \n",
    "#     # encode document\n",
    "#     vector = vectorizer.transform(text)\n",
    "    \n",
    "#     return pd.DataFrame(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_features(df):\n",
    "    \n",
    "    # Modify ----------> \"categories\"\n",
    "    \n",
    "    # get number of characters\n",
    "    df.loc[:,'categories_count'] = [len(i) for i in df['categories']]\n",
    "    \n",
    "#     # generate numerical category by transforming combination of lists to numbers\n",
    "    df.loc[:,'category_numtrans'] = Get_category_numtrans(df.categories)\n",
    "\n",
    "    # Modify ----------> \"itemID\" and \"reviewerID\"\n",
    "    \n",
    "    # create dictionaries for itemID and reviewerID, convert from categorical to numeric\n",
    "    items_dict = {k:v for v,k in enumerate(set(df.itemID))}\n",
    "    reviewer_dict = {k:v for v,k in enumerate(set(df.reviewerID))}\n",
    "    \n",
    "    # change item and reviewer IDs to numeric\n",
    "    df.loc[:,'itemID'] = [items_dict[i] for i in df['itemID']]\n",
    "    df.loc[:,'reviewerID'] = [reviewer_dict[i] for i in df['reviewerID']]\n",
    "    \n",
    "    # add helpful rate for itemID and reviewerID\n",
    "    df.loc[:,'itemID_helpfulRate'] = find_Helpful_rate(df['itemID'], 'itemID')\n",
    "    df.loc[:,'reviewerID_helpfulRate'] = find_Helpful_rate(df['reviewerID'], 'reviewerID')\n",
    "    \n",
    "    # get number of reviews for each user\n",
    "    df.loc[:,'reviewerID_numReviews'] = Get_numreviews_summarized(df['reviewerID'])\n",
    "    \n",
    "    # get number of reviews for each product\n",
    "    df.loc[:,'itemID_numReviews'] = Get_numreviews_summarized(df['itemID'])\n",
    "    \n",
    "    # Modify ----------> \"reviewText\" \n",
    "    \n",
    "    # get number of words, remove stopwords\n",
    "    df.loc[:,'reviewText_count_words'] = Get_NumWords(df['reviewText'])\n",
    "\n",
    "    # get character count\n",
    "    df.loc[:,'reviewText_count_char'] = [len(i) for i in df['reviewText']]\n",
    "    \n",
    "    # get punctuation count\n",
    "    df.loc[:,'reviewText_count_punctu'] = Get_punctuation_count(df['reviewText'])\n",
    "    \n",
    "    # get number of words that start with a capital leter\n",
    "    df.loc[:,'reviewText_count_firstCapital'] = Get_count_firstLetterCapital(df['reviewText'])\n",
    "    \n",
    "    # get average word length\n",
    "    df.loc[:,'reviewText_avgWordLength'] = Get_avg_word_length(df['reviewText'])\n",
    "    \n",
    "    # get number of capital words\n",
    "    df.loc[:,'reviewText_capitalwords'] = Get_numCapitalwords(df['reviewText'])\n",
    "    \n",
    "    # get number of question and exclamation characters\n",
    "    df.loc[:,'reviewText_ExclQue_countchar'] = Get_ExclQues_charCount(df['reviewText'])\n",
    "    \n",
    "    # get ratio between puctuations with character numbers\n",
    "    df.loc[:,'reviewText_PunctChar_ratio'] = Get_colsRatio(df['reviewText_count_punctu'], df['reviewText_count_char'])\n",
    "    \n",
    "    # get positive and negative word rate\n",
    "    reviewText_PosNeg = GetPosNegWords_count_Rate(df.reviewText)\n",
    "    df.loc[:,'reviewText_posWordCount'] = reviewText_PosNeg['pos_count']\n",
    "    df.loc[:,'reviewText_negWordCount'] = reviewText_PosNeg['neg_count']\n",
    "    df.loc[:,'reviewText_posWordRate'] = reviewText_PosNeg['pos_rate']\n",
    "    df.loc[:,'reviewText_negWordRate'] = reviewText_PosNeg['neg_rate']\n",
    "  \n",
    "    # Modify ----------> \"summary\"\n",
    "    \n",
    "    # get number of words, remove stopwords\n",
    "    df.loc[:,'summary_count_words'] = Get_NumWords(df['summary'])\n",
    "\n",
    "    # get character count\n",
    "    df.loc[:,'summary_count_char'] = [len(i) for i in df['summary']]\n",
    "    \n",
    "    # get punctuation count\n",
    "    df.loc[:,'summary_count_punctu'] = Get_punctuation_count(df['summary'])\n",
    "    \n",
    "    # get number of words that start with a capital leter\n",
    "    df.loc[:,'summary_count_firstCapital'] = Get_count_firstLetterCapital(df['summary'])\n",
    "    \n",
    "    # get average word length\n",
    "    df.loc[:,'summary_avgWordLength'] = Get_avg_word_length(df['summary'])\n",
    "    \n",
    "    # get number of capital words\n",
    "    df.loc[:,'summary_capitalwords'] = Get_numCapitalwords(df['summary'])\n",
    "    \n",
    "    # get number of question and exclamation characters\n",
    "    df.loc[:,'summary_ExclQue_countchar'] = Get_ExclQues_charCount(df['summary'])\n",
    "    \n",
    "    # get ratio between puctuations with character numbers\n",
    "    df.loc[:,'summary_PunctChar_ratio'] = Get_colsRatio(df['summary_count_punctu'], df['summary_count_char'])\n",
    "    \n",
    "    # get positive and negative word rate\n",
    "    summary_PosNeg = GetPosNegWords_count_Rate(df.summary)\n",
    "    df.loc[:,'summary_posWordCount'] = summary_PosNeg['pos_count']\n",
    "    df.loc[:,'summary_negWordCount'] = summary_PosNeg['neg_count']\n",
    "    df.loc[:,'summary_posWordRate'] = summary_PosNeg['pos_rate']\n",
    "    df.loc[:,'summary_negWordRate'] = summary_PosNeg['neg_rate']\n",
    "    \n",
    "    # Modify ----------> \"helpful\" \n",
    "    \n",
    "    # parse helpful votes\n",
    "    df.loc[:,'outOf_feature'] = [i['outOf'] for i in df['helpful']]\n",
    "    \n",
    "    # Modify ----------> \"price\" \n",
    "    \n",
    "    # change NA values to -999\n",
    "    df.loc[df.price.isna(),'price'] = -999\n",
    "    \n",
    "    # Modify ----------> \"unixReviewTime\" \n",
    "    \n",
    "    # find time since first review\n",
    "    df.loc[:,'unixReviewTime_delta_firstreview'] = Get_delta_sinceFirstReview(df)\n",
    "    \n",
    "    # find time since last review for same product\n",
    "    df.loc[:,'unixReviewTime_delta_lastreview'] = Get_delta_sinceLastReview(df)\n",
    "    \n",
    "    # normalize UnixReviewTime\n",
    "#     df.loc[:,'unixReviewTime'] = ((df.unixReviewTime-df.unixReviewTime.mean())/df.unixReviewTime.std())\n",
    "    \n",
    "    # Modify ----------> \"reviewText\" \n",
    "    \n",
    "    # get rating deviation from the mean\n",
    "    df.loc[:,'rating_deviation'] = Get_product_ratingDeviation(df)\n",
    "    \n",
    "    # Add -------------> New Columns\n",
    "    \n",
    "    # votes over time\n",
    "    df.loc[:,'votes_time'] = df.outOf_feature/df.unixReviewTime\n",
    "    \n",
    "    # ratio of summary to reviewText for characters and words\n",
    "    df.loc[:,'summary_reviewText_charRatio'] = Get_colsRatio(df.summary_count_char, df.reviewText_count_char)\n",
    "    df.loc[:,'summary_reviewText_wordsRatio'] = Get_colsRatio(df.summary_count_words, df.reviewText_count_words)\n",
    "    \n",
    "    # define columns to keep\n",
    "    cols = ['categoryID','categories_count', 'category_numtrans','summary_count_words', 'itemID', 'reviewerID', 'rating', \n",
    "            'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "            'reviewerID_numReviews', 'rating_deviation', \n",
    "            'outOf_feature', 'unixReviewTime', 'price', 'reviewText_posWordCount', 'reviewText_negWordCount',\n",
    "            'reviewText_posWordRate', 'reviewText_negWordRate', 'summary_count_char', 'reviewText_count_char',\n",
    "            'reviewText_count_punctu','summary_count_punctu','summary_posWordCount', \n",
    "            'summary_negWordCount', 'summary_posWordRate','summary_negWordRate',\n",
    "           'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "           'reviewText_avgWordLength','summary_avgWordLength', 'unixReviewTime_delta_firstreview',\n",
    "           'votes_time', 'summary_reviewText_charRatio', 'summary_reviewText_wordsRatio', 'itemID_numReviews',\n",
    "           'reviewText_capitalwords', 'summary_capitalwords',\n",
    "           'reviewText_ExclQue_countchar', 'summary_ExclQue_countchar',\n",
    "           'reviewText_PunctChar_ratio', 'summary_PunctChar_ratio', 'unixReviewTime_delta_lastreview']\n",
    "    \n",
    "    # return features\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_labels(df):    \n",
    "    return [i['nHelpful']/i['outOf'] if i['outOf']!=0 else 0 for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # add TF-IDF for reviewText\n",
    "\n",
    "# # get stopwords from nltk library\n",
    "# # nltk.download('stopwords')\n",
    "# stopW_list = stopwords.words('english')\n",
    "\n",
    "# # create the transform\n",
    "# vectorizer = TfidfVectorizer(stop_words = stopW_list, lowercase=True, smooth_idf=True)\n",
    "\n",
    "# # tokenize and build vocab\n",
    "# vectorizer.fit(X_train_raw.summary)\n",
    "\n",
    "# # encode document\n",
    "# vector_train = vectorizer.transform(X_train_raw.summary)\n",
    "# vector_val = vectorizer.transform(X_val_raw.summary)\n",
    "\n",
    "# # convert to dataframe\n",
    "# vector_train = pd.DataFrame(vector_train.toarray())\n",
    "# vector_val = pd.DataFrame(vector_val.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Get features\n",
    "# X_train_features = Get_features(X_train_raw)\n",
    "# y_train = Get_labels(y_train_raw) # continuous\n",
    "# # y_train = [int(i*100) for i in Get_labels(y_train_raw)] # categorical\n",
    "\n",
    "# X_val_features = Get_features(X_val_raw)\n",
    "# y_val = y_val_raw\n",
    "\n",
    "\n",
    "# # combine features with TF-IDF\n",
    "# X_train = vector_train\n",
    "# for i in X_train_features.columns:\n",
    "#     X_train[i] = X_train_features[i].tolist()\n",
    "    \n",
    "# X_val = vector_val\n",
    "# for i in X_val_features.columns:\n",
    "#     X_val[i] = X_val_features[i].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features for train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 1.49 s, total: 1min 34s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# from itertools import compress\n",
    "\n",
    "# # get indices from raw dataset where number of votes is greater than zero\n",
    "# idx_train = np.array([i['outOf'] for i in X_train_raw.helpful]) > 0\n",
    "\n",
    "# # filter raw data for training only\n",
    "# X_train_raw = X_train_raw.loc[idx_train,:]\n",
    "# y_train_raw = list(compress(y_train_raw, idx_train))\n",
    "\n",
    "# # get training features and labels\n",
    "# X_train_1 = Get_features(X_train_raw)\n",
    "# y_train = Get_labels(y_train_raw) \n",
    "\n",
    "# # get validation features and labels\n",
    "# X_val_1 = Get_features(X_val_raw)\n",
    "# y_val = y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 37s, sys: 2.7 s, total: 3min 40s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import compress\n",
    "\n",
    "# get indices from raw dataset where number of votes is greater than zero\n",
    "idx_train = np.array([i['outOf'] for i in X_train_raw.helpful]) > 0\n",
    "\n",
    "# get training features and labels\n",
    "X_train_filtered = Get_features(X_train_raw.loc[idx_train,:])\n",
    "y_train_filtered = Get_labels(list(compress(y_train_raw, idx_train))) \n",
    "\n",
    "X_train = Get_features(X_train_raw)\n",
    "y_train = Get_labels(y_train_raw)\n",
    "\n",
    "# get validation features and labels\n",
    "X_val = Get_features(X_val_raw)\n",
    "y_val = y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>itemID_helpfulRate</th>\n",
       "      <th>reviewerID_helpfulRate</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_reviewText_charRatio</th>\n",
       "      <th>summary_reviewText_wordsRatio</th>\n",
       "      <th>itemID_numReviews</th>\n",
       "      <th>reviewText_capitalwords</th>\n",
       "      <th>summary_capitalwords</th>\n",
       "      <th>reviewText_ExclQue_countchar</th>\n",
       "      <th>summary_ExclQue_countchar</th>\n",
       "      <th>reviewText_PunctChar_ratio</th>\n",
       "      <th>summary_PunctChar_ratio</th>\n",
       "      <th>unixReviewTime_delta_lastreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130396</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3192</td>\n",
       "      <td>2</td>\n",
       "      <td>16908</td>\n",
       "      <td>30819</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048673</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86666</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2696</td>\n",
       "      <td>1</td>\n",
       "      <td>8006</td>\n",
       "      <td>13591</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94994</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>9127</td>\n",
       "      <td>208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104230</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>758</td>\n",
       "      <td>4</td>\n",
       "      <td>6082</td>\n",
       "      <td>6757</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194871</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2252</td>\n",
       "      <td>5</td>\n",
       "      <td>18149</td>\n",
       "      <td>27172</td>\n",
       "      <td>5.0</td>\n",
       "      <td>157</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020343</td>\n",
       "      <td>0.031847</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>259200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "130396           0                 3               3192                    2   \n",
       "86666            1                 3               2696                    1   \n",
       "94994            0                 1                171                    1   \n",
       "104230           0                 1                758                    4   \n",
       "194871           0                 2               2252                    5   \n",
       "\n",
       "        itemID  reviewerID  rating  reviewText_count_words  \\\n",
       "130396   16908       30819     5.0                      24   \n",
       "86666     8006       13591     5.0                      11   \n",
       "94994     9127         208     4.0                      14   \n",
       "104230    6082        6757     5.0                      13   \n",
       "194871   18149       27172     5.0                     157   \n",
       "\n",
       "        itemID_helpfulRate  reviewerID_helpfulRate  ...  \\\n",
       "130396            1.000000                0.857143  ...   \n",
       "86666             1.000000                1.000000  ...   \n",
       "94994             0.833333                0.818182  ...   \n",
       "104230            0.900000                0.500000  ...   \n",
       "194871            0.923077                0.812500  ...   \n",
       "\n",
       "        summary_reviewText_charRatio  summary_reviewText_wordsRatio  \\\n",
       "130396                      0.044248                       0.083333   \n",
       "86666                       0.042735                       0.090909   \n",
       "94994                       0.054422                       0.071429   \n",
       "104230                      0.141892                       0.307692   \n",
       "194871                      0.020343                       0.031847   \n",
       "\n",
       "        itemID_numReviews  reviewText_capitalwords  summary_capitalwords  \\\n",
       "130396                  5                        1                     0   \n",
       "86666                  15                        0                     0   \n",
       "94994                   4                        1                     0   \n",
       "104230                 21                        1                     0   \n",
       "194871                 40                        3                     0   \n",
       "\n",
       "        reviewText_ExclQue_countchar  summary_ExclQue_countchar  \\\n",
       "130396                             1                          0   \n",
       "86666                              0                          0   \n",
       "94994                              0                          0   \n",
       "104230                             0                          0   \n",
       "194871                             2                          0   \n",
       "\n",
       "        reviewText_PunctChar_ratio  summary_PunctChar_ratio  \\\n",
       "130396                    0.048673                   0.0000   \n",
       "86666                     0.042735                   0.0000   \n",
       "94994                     0.020408                   0.0000   \n",
       "104230                    0.013514                   0.0000   \n",
       "194871                    0.044501                   0.0625   \n",
       "\n",
       "        unixReviewTime_delta_lastreview  \n",
       "130396                                0  \n",
       "86666                           2073600  \n",
       "94994                                 0  \n",
       "104230                         24624000  \n",
       "194871                           259200  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Get features\n",
    "# X_train_1 = Get_features(X_train_raw)\n",
    "# y_train = Get_labels(y_train_raw) # continuous\n",
    "# # y_train = [int(i*100) for i in Get_labels(y_train_raw)] # categorical\n",
    "\n",
    "# X_val_1 = Get_features(X_val_raw)\n",
    "# y_val = y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove reviews where votes are zero - training data only\n",
    "# from itertools import compress\n",
    "\n",
    "# # idx_train = (X_train_1.outOf_feature > 0) & (X_train_1.outOf_feature < 3)\n",
    "# idx_train = X_train_1.outOf_feature > 0\n",
    "# X_train_1 = X_train_1.loc[idx_train,:]\n",
    "# y_train = list(compress(y_train, idx_train))\n",
    "# X_train_raw = X_train_raw.loc[idx_train,:]\n",
    "# y_train_raw = list(compress(y_train_raw, idx_train))\n",
    "\n",
    "# # idx_val = (X_val_1.outOf_feature > 0) & (X_val_1.outOf_feature < 3)\n",
    "# idx_val = X_val_1.outOf_feature > 0\n",
    "# X_val_1 = X_val_1.loc[idx_val,:]\n",
    "# y_val = list(compress(y_val, idx_val))\n",
    "# X_val_raw = X_val_raw.loc[idx_val,:]\n",
    "# y_val_raw = list(compress(y_val_raw, idx_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>itemID_helpfulRate</th>\n",
       "      <th>reviewerID_helpfulRate</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_reviewText_charRatio</th>\n",
       "      <th>summary_reviewText_wordsRatio</th>\n",
       "      <th>itemID_numReviews</th>\n",
       "      <th>reviewText_capitalwords</th>\n",
       "      <th>summary_capitalwords</th>\n",
       "      <th>reviewText_ExclQue_countchar</th>\n",
       "      <th>summary_ExclQue_countchar</th>\n",
       "      <th>reviewText_PunctChar_ratio</th>\n",
       "      <th>summary_PunctChar_ratio</th>\n",
       "      <th>unixReviewTime_delta_lastreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130248</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>551</td>\n",
       "      <td>3</td>\n",
       "      <td>15265</td>\n",
       "      <td>20193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.793464</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>4924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182454</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>437</td>\n",
       "      <td>3</td>\n",
       "      <td>10110</td>\n",
       "      <td>20969</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176029</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "      <td>2813</td>\n",
       "      <td>6219</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1104</td>\n",
       "      <td>1</td>\n",
       "      <td>11768</td>\n",
       "      <td>14780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25017</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2276</td>\n",
       "      <td>2</td>\n",
       "      <td>5445</td>\n",
       "      <td>1962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5097600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "130248           0                 2                551                    3   \n",
       "182454           0                 1                437                    3   \n",
       "176029           0                 1                327                    1   \n",
       "13049            0                 1               1104                    1   \n",
       "25017            0                 2               2276                    2   \n",
       "\n",
       "        itemID  reviewerID  rating  reviewText_count_words  \\\n",
       "130248   15265       20193     4.0                     108   \n",
       "182454   10110       20969     2.0                       9   \n",
       "176029    2813        6219     5.0                      14   \n",
       "13049    11768       14780     5.0                      30   \n",
       "25017     5445        1962     1.0                      19   \n",
       "\n",
       "        itemID_helpfulRate  reviewerID_helpfulRate  ...  \\\n",
       "130248            0.793464                0.714286  ...   \n",
       "182454            0.750000                0.625000  ...   \n",
       "176029            0.695652                0.000000  ...   \n",
       "13049             0.897436                0.882979  ...   \n",
       "25017             0.428571                0.500000  ...   \n",
       "\n",
       "        summary_reviewText_charRatio  summary_reviewText_wordsRatio  \\\n",
       "130248                      0.022203                       0.027778   \n",
       "182454                      0.234783                       0.333333   \n",
       "176029                      0.076433                       0.071429   \n",
       "13049                       0.024922                       0.033333   \n",
       "25017                       0.057471                       0.105263   \n",
       "\n",
       "        itemID_numReviews  reviewText_capitalwords  summary_capitalwords  \\\n",
       "130248                 49                        1                     0   \n",
       "182454                  5                        1                     0   \n",
       "176029                 10                        0                     0   \n",
       "13049                   5                        1                     0   \n",
       "25017                   4                        2                     0   \n",
       "\n",
       "        reviewText_ExclQue_countchar  summary_ExclQue_countchar  \\\n",
       "130248                             2                          0   \n",
       "182454                             0                          0   \n",
       "176029                             1                          1   \n",
       "13049                              1                          0   \n",
       "25017                              0                          0   \n",
       "\n",
       "        reviewText_PunctChar_ratio  summary_PunctChar_ratio  \\\n",
       "130248                    0.021349                 0.038462   \n",
       "182454                    0.043478                 0.111111   \n",
       "176029                    0.025478                 0.083333   \n",
       "13049                     0.037383                 0.000000   \n",
       "25017                     0.030651                 0.066667   \n",
       "\n",
       "        unixReviewTime_delta_lastreview  \n",
       "130248                          4924800  \n",
       "182454                          1036800  \n",
       "176029                           172800  \n",
       "13049                             86400  \n",
       "25017                           5097600  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>itemID_helpfulRate</th>\n",
       "      <th>reviewerID_helpfulRate</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_reviewText_charRatio</th>\n",
       "      <th>summary_reviewText_wordsRatio</th>\n",
       "      <th>itemID_numReviews</th>\n",
       "      <th>reviewText_capitalwords</th>\n",
       "      <th>summary_capitalwords</th>\n",
       "      <th>reviewText_ExclQue_countchar</th>\n",
       "      <th>summary_ExclQue_countchar</th>\n",
       "      <th>reviewText_PunctChar_ratio</th>\n",
       "      <th>summary_PunctChar_ratio</th>\n",
       "      <th>unixReviewTime_delta_lastreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188807</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>14635</td>\n",
       "      <td>8560</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199122</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2359</td>\n",
       "      <td>1</td>\n",
       "      <td>14729</td>\n",
       "      <td>10725</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17944</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>11532</td>\n",
       "      <td>619</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11923200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199504</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>4</td>\n",
       "      <td>7407</td>\n",
       "      <td>11173</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060194</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168703</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1086</td>\n",
       "      <td>2</td>\n",
       "      <td>9815</td>\n",
       "      <td>17197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "188807           0                 1                879                    1   \n",
       "199122           0                 2               2359                    1   \n",
       "17944            1                 2               1143                    1   \n",
       "199504           1                 4               2755                    4   \n",
       "168703           0                 1               1086                    2   \n",
       "\n",
       "        itemID  reviewerID  rating  reviewText_count_words  \\\n",
       "188807   14635        8560     5.0                      13   \n",
       "199122   14729       10725     3.0                      27   \n",
       "17944    11532         619     5.0                       5   \n",
       "199504    7407       11173     5.0                      45   \n",
       "168703    9815       17197     5.0                      39   \n",
       "\n",
       "        itemID_helpfulRate  reviewerID_helpfulRate  ...  \\\n",
       "188807            0.812500                1.000000  ...   \n",
       "199122            0.944444                1.000000  ...   \n",
       "17944             0.739130                0.000000  ...   \n",
       "199504            0.625000                0.922727  ...   \n",
       "168703            1.000000                0.571429  ...   \n",
       "\n",
       "        summary_reviewText_charRatio  summary_reviewText_wordsRatio  \\\n",
       "188807                      0.076271                       0.076923   \n",
       "199122                      0.035503                       0.037037   \n",
       "17944                       0.117647                       0.200000   \n",
       "199504                      0.060194                       0.088889   \n",
       "168703                      0.028902                       0.051282   \n",
       "\n",
       "        itemID_numReviews  reviewText_capitalwords  summary_capitalwords  \\\n",
       "188807                 13                        1                     0   \n",
       "199122                  2                        1                     0   \n",
       "17944                   8                        0                     0   \n",
       "199504                  6                        1                     0   \n",
       "168703                  1                        1                     0   \n",
       "\n",
       "        reviewText_ExclQue_countchar  summary_ExclQue_countchar  \\\n",
       "188807                             0                          0   \n",
       "199122                             0                          0   \n",
       "17944                              0                          0   \n",
       "199504                             9                          0   \n",
       "168703                             1                          0   \n",
       "\n",
       "        reviewText_PunctChar_ratio  summary_PunctChar_ratio  \\\n",
       "188807                    0.025424                 0.000000   \n",
       "199122                    0.011834                 0.083333   \n",
       "17944                     0.000000                 0.000000   \n",
       "199504                    0.034951                 0.000000   \n",
       "168703                    0.034682                 0.000000   \n",
       "\n",
       "        unixReviewTime_delta_lastreview  \n",
       "188807                          9590400  \n",
       "199122                                0  \n",
       "17944                          11923200  \n",
       "199504                         10022400  \n",
       "168703                                0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32485, 31)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8088, 31)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing was done with random forest regressor\n",
    "RandomForestRegressor(max_depth=C, random_state=0)\n",
    "\"\"\"\n",
    "\n",
    "# data from help votes\n",
    "cols1 = ['itemID', 'reviewerID','outOf_feature']\n",
    "\n",
    "\"\"\"\n",
    "10\n",
    "MAE for train data: 0.1763875\n",
    "MAE for val data: 0.184775\n",
    "CPU times: user 15.2 s, sys: 250 ms, total: 15.5 s\n",
    "Wall time: 15.6 s\n",
    "\"\"\"\n",
    "\n",
    "# raw features from data\n",
    "cols2 = ['itemID', 'reviewerID', 'rating', 'outOf_feature', 'unixReviewTime', 'price']\n",
    "\n",
    "\"\"\"\n",
    "10\n",
    "MAE for train data: 0.16409375\n",
    "MAE for val data: 0.1682\n",
    "CPU times: user 20.1 s, sys: 212 ms, total: 20.3 s\n",
    "Wall time: 20.4 s\n",
    "\n",
    "with unixReviewTime normalized:\n",
    "10\n",
    "MAE for train data: 0.1641\n",
    "MAE for val data: 0.169225\n",
    "CPU times: user 20.7 s, sys: 433 ms, total: 21.1 s\n",
    "Wall time: 21.3 s\n",
    "\"\"\"\n",
    "\n",
    "# # new features around word manipulations in reviewText and summary\n",
    "# cols3 = ['itemID', 'reviewerID', 'reviewText_count_words',\n",
    "#        'reviewText_posWordCount', 'reviewText_negWordCount',\n",
    "#        'reviewText_posWordRate', 'reviewText_negWordRate', 'summary_count_words']\n",
    "\n",
    "# \"\"\"\n",
    "# 10\n",
    "# MAE for train data: 0.68605625\n",
    "# MAE for val data: 0.714175\n",
    "# CPU times: user 1min, sys: 803 ms, total: 1min 1s\n",
    "# Wall time: 1min 2s\n",
    "\n",
    "# # counting number of characters\n",
    "# 10\n",
    "# MAE for train data: 0.68730625\n",
    "# MAE for val data: 0.718175\n",
    "# CPU times: user 1min 1s, sys: 424 ms, total: 1min 1s\n",
    "# Wall time: 1min 1s\n",
    "# \"\"\"\n",
    "\n",
    "# # new features around word manipulations in reviewText and summary, without pos/neg rates\n",
    "# cols4 = ['itemID', 'reviewerID', 'reviewText_count_words',\n",
    "#        'reviewText_posWordCount', 'reviewText_negWordCount', 'summary_count_words']\n",
    "\n",
    "# \"\"\"\n",
    "# 10\n",
    "# MAE for train data: 0.6877375\n",
    "# MAE for val data: 0.715225\n",
    "# CPU times: user 46 s, sys: 309 ms, total: 46.3 s\n",
    "# Wall time: 46.5 s\n",
    "# \"\"\"\n",
    "\n",
    "# # all features\n",
    "# cols5 = ['categories_count', 'summary_count_words', 'itemID', 'reviewerID', 'rating',\n",
    "#        'reviewText_count_words', 'outOf_feature', 'unixReviewTime', 'price',\n",
    "#        'reviewText_posWordCount', 'reviewText_negWordCount',\n",
    "#        'reviewText_posWordRate', 'reviewText_negWordRate']\n",
    "\n",
    "# \"\"\"\n",
    "# 10\n",
    "# MAE for train data: 0.1636125\n",
    "# MAE for val data: 0.1661\n",
    "# CPU times: user 34 s, sys: 313 ms, total: 34.3 s\n",
    "# Wall time: 34.5 s\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "cols6 = ['itemID', 'reviewerID', 'rating', 'outOf_feature', 'unixReviewTime', 'price', 'reviewText_count_words']\n",
    "\n",
    "\n",
    "\n",
    "# try features elimination\n",
    "all_ = ['categoryID','categories_count', 'category_numtrans','summary_count_words', 'itemID', 'reviewerID', 'rating', \n",
    "            'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "            'reviewerID_numReviews', 'rating_deviation', \n",
    "            'outOf_feature', 'unixReviewTime', 'price', 'reviewText_posWordCount', 'reviewText_negWordCount',\n",
    "            'reviewText_posWordRate', 'reviewText_negWordRate', 'summary_count_char', 'reviewText_count_char',\n",
    "            'reviewText_count_punctu','summary_count_punctu','summary_posWordCount', \n",
    "            'summary_negWordCount', 'summary_posWordRate','summary_negWordRate',\n",
    "           'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "           'reviewText_avgWordLength','summary_avgWordLength']\n",
    "\n",
    "\n",
    "X_train = X_train_1[all_]\n",
    "X_val = X_val_1[all_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>itemID_helpfulRate</th>\n",
       "      <th>reviewerID_helpfulRate</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewText_count_punctu</th>\n",
       "      <th>summary_count_punctu</th>\n",
       "      <th>summary_posWordCount</th>\n",
       "      <th>summary_negWordCount</th>\n",
       "      <th>summary_posWordRate</th>\n",
       "      <th>summary_negWordRate</th>\n",
       "      <th>reviewText_count_firstCapital</th>\n",
       "      <th>summary_count_firstCapital</th>\n",
       "      <th>reviewText_avgWordLength</th>\n",
       "      <th>summary_avgWordLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62732</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3392</td>\n",
       "      <td>2</td>\n",
       "      <td>16904</td>\n",
       "      <td>18201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850732</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182454</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>28682</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158745</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>11231</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5.318182</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176029</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>12868</td>\n",
       "      <td>14824</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64520</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1715</td>\n",
       "      <td>2</td>\n",
       "      <td>6313</td>\n",
       "      <td>12493</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "62732            0                 3               3392                    2   \n",
       "182454           0                 1                161                    3   \n",
       "158745           0                 1                161                    1   \n",
       "176029           0                 1                756                    1   \n",
       "64520            0                 3               1715                    2   \n",
       "\n",
       "        itemID  reviewerID  rating  reviewText_count_words  \\\n",
       "62732    16904       18201     5.0                      17   \n",
       "182454    2023       28682     2.0                       9   \n",
       "158745    1940       11231     4.0                      25   \n",
       "176029   12868       14824     5.0                      14   \n",
       "64520     6313       12493     5.0                      22   \n",
       "\n",
       "        itemID_helpfulRate  reviewerID_helpfulRate  ...  \\\n",
       "62732             1.000000                0.850732  ...   \n",
       "182454            0.750000                0.625000  ...   \n",
       "158745            0.500000                0.800000  ...   \n",
       "176029            0.695652                0.000000  ...   \n",
       "64520             0.500000                0.000000  ...   \n",
       "\n",
       "        reviewText_count_punctu  summary_count_punctu  summary_posWordCount  \\\n",
       "62732                         4                     0                     0   \n",
       "182454                        5                     3                     0   \n",
       "158745                        3                     0                     1   \n",
       "176029                        4                     1                     1   \n",
       "64520                         5                     1                     1   \n",
       "\n",
       "        summary_negWordCount  summary_posWordRate  summary_negWordRate  \\\n",
       "62732                      1                  0.0             0.333333   \n",
       "182454                     0                  0.0             0.000000   \n",
       "158745                     0                  1.0             0.000000   \n",
       "176029                     0                  0.5             0.000000   \n",
       "64520                      0                  0.5             0.000000   \n",
       "\n",
       "        reviewText_count_firstCapital  summary_count_firstCapital  \\\n",
       "62732                               5                           0   \n",
       "182454                              4                           1   \n",
       "158745                              9                           1   \n",
       "176029                              3                           0   \n",
       "64520                               8                           1   \n",
       "\n",
       "        reviewText_avgWordLength  summary_avgWordLength  \n",
       "62732                   5.941176                    4.0  \n",
       "182454                  5.000000                    5.0  \n",
       "158745                  5.318182                    4.0  \n",
       "176029                  6.000000                    6.0  \n",
       "64520                   5.045455                    6.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132424, 31)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Feature Contribution to MAE LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Features\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "\n",
      "\n",
      "rating\n",
      "Accuracy for train data: 0.9519422461185284\n",
      "Accuracy for val data: 0.9598924828606807\n",
      "MAE for train data: 0.04805775388147163\n",
      "MAE for val data: 0.04010751713931926\n",
      "Difference from baseline: 0.09217480595572469\n",
      "\n",
      "\n",
      "unixReviewTime\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "price\n",
      "Accuracy for train data: 0.8696761916268955\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13032380837310456\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "categoryID\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "categories_count\n",
      "Accuracy for train data: 0.9578324170845164\n",
      "Accuracy for val data: 0.9598924828606807\n",
      "MAE for train data: 0.0421675829154836\n",
      "MAE for val data: 0.04010751713931926\n",
      "Difference from baseline: 0.09217480595572469\n",
      "\n",
      "\n",
      "category_numtrans\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_count_words\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_count_words\n",
      "Accuracy for train data: 0.9507566604240923\n",
      "Accuracy for val data: 0.9595300655371327\n",
      "MAE for train data: 0.049243339575907694\n",
      "MAE for val data: 0.04046993446286733\n",
      "Difference from baseline: 0.09181238863217663\n",
      "\n",
      "\n",
      "itemID_helpfulRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewerID_helpfulRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewerID_numReviews\n",
      "Accuracy for train data: 0.9497976197668097\n",
      "Accuracy for val data: 0.9598924828606807\n",
      "MAE for train data: 0.05020238023319036\n",
      "MAE for val data: 0.04010751713931926\n",
      "Difference from baseline: 0.09217480595572469\n",
      "\n",
      "\n",
      "rating_deviation\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_posWordCount\n",
      "Accuracy for train data: 0.9578324170845164\n",
      "Accuracy for val data: 0.9598924828606807\n",
      "MAE for train data: 0.0421675829154836\n",
      "MAE for val data: 0.04010751713931926\n",
      "Difference from baseline: 0.09217480595572469\n",
      "\n",
      "\n",
      "reviewText_negWordCount\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_posWordRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_negWordRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_count_char\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_count_char\n",
      "Accuracy for train data: 0.9508548299401921\n",
      "Accuracy for val data: 0.9595300655371327\n",
      "MAE for train data: 0.04914517005980789\n",
      "MAE for val data: 0.04046993446286733\n",
      "Difference from baseline: 0.09181238863217663\n",
      "\n",
      "\n",
      "reviewText_count_punctu\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_count_punctu\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_posWordCount\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_negWordCount\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_posWordRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_negWordRate\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_count_firstCapital\n",
      "Accuracy for train data: 0.9509529994562919\n",
      "Accuracy for val data: 0.9595904684243907\n",
      "MAE for train data: 0.049047000543708086\n",
      "MAE for val data: 0.040409531575609316\n",
      "Difference from baseline: 0.09187279151943464\n",
      "\n",
      "\n",
      "summary_count_firstCapital\n",
      "Accuracy for train data: 0.869668640125657\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033135987434302\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "reviewText_avgWordLength\n",
      "Accuracy for train data: 0.8696610886244185\n",
      "Accuracy for val data: 0.867717676904956\n",
      "MAE for train data: 0.13033891137558146\n",
      "MAE for val data: 0.13228232309504395\n",
      "Difference from baseline: 0.0\n",
      "\n",
      "\n",
      "summary_avgWordLength\n",
      "Accuracy for train data: 0.9496465897420407\n",
      "Accuracy for val data: 0.9561173024070551\n",
      "MAE for train data: 0.05035341025795928\n",
      "MAE for val data: 0.04388269759294494\n",
      "Difference from baseline: 0.08839962550209901\n",
      "\n",
      "\n",
      "CPU times: user 28.6 s, sys: 2.84 s, total: 31.4 s\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#################################### Baseline ####################################\n",
    "# define original feature lists\n",
    "original_features = ['itemID', 'reviewerID', 'outOf_feature']\n",
    "\n",
    "# apply logistic regression to votes equal to 0 and 1\n",
    "\n",
    "X_train = X_train_1[original_features]\n",
    "X_val = X_val_1[original_features]\n",
    "\n",
    "# parameters = { 'penalty': ['l1','l2'], \n",
    "#               'C':[0.1, 0.5, 1, 2, 3, 4, 5, 10]}\n",
    "clf = LogisticRegression(penalty='l2', C=1.0, n_jobs=-1)\n",
    "# clf = GridSearchCV(logreg, parameters, verbose=True, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = clf.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('Baseline Features')\n",
    "print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "baseline_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "print('MAE for val data: {}'.format(baseline_mae))\n",
    "print('\\n')\n",
    "\n",
    "#################################### New Features ####################################\n",
    "# define new feature lists\n",
    "new_feature_list = ['rating', 'unixReviewTime', 'price',\n",
    "                    'categoryID','categories_count', 'category_numtrans','summary_count_words', \n",
    "                    'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "                    'reviewerID_numReviews', 'rating_deviation', 'reviewText_posWordCount', \n",
    "                    'reviewText_negWordCount','reviewText_posWordRate', 'reviewText_negWordRate', \n",
    "                    'summary_count_char', 'reviewText_count_char', 'reviewText_count_punctu',\n",
    "                    'summary_count_punctu','summary_posWordCount', \n",
    "                    'summary_negWordCount', 'summary_posWordRate','summary_negWordRate', \n",
    "                    'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "                    'reviewText_avgWordLength','summary_avgWordLength']\n",
    "\n",
    "features_tokeep = []\n",
    "for feature in new_feature_list:\n",
    "    X_train = X_train_1[original_features + [feature]]\n",
    "    X_val = X_val_1[original_features + [feature]]\n",
    "    \n",
    "#     parameters = { 'penalty': ['l1','l2'], \n",
    "#               'C':[0.1, 0.5, 1, 2, 3, 4, 5, 10]}\n",
    "    \n",
    "    clf = LogisticRegression(penalty='l2', C=1.0, n_jobs=-1)\n",
    "#     clf = GridSearchCV(logreg, parameters, verbose=True, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "    y_pred_train = clf.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "    # round to the nearest integer\n",
    "    y_pred = [int(round(i)) for i in y_pred]\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "    print(feature)\n",
    "    \n",
    "    print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "    print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "    \n",
    "    print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "    feature_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "    print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))\n",
    "    print('Difference from baseline: {}'.format(baseline_mae-feature_mae))\n",
    "    print('\\n')\n",
    "    \n",
    "    # keep features with lower MAE than baseline\n",
    "    if feature_mae < baseline_mae:\n",
    "        features_tokeep.append(feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rating',\n",
       " 'categories_count',\n",
       " 'reviewText_count_words',\n",
       " 'reviewerID_numReviews',\n",
       " 'reviewText_posWordCount',\n",
       " 'reviewText_count_char',\n",
       " 'reviewText_count_firstCapital',\n",
       " 'summary_avgWordLength']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print features that help improve\n",
    "features_tokeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary_count_char', 'summary_posWordCount', 'reviewText_avgWordLength', 'reviewText_count_punctu', 'reviewerID_helpfulRate', 'reviewText_negWordRate', 'reviewText_posWordRate', 'unixReviewTime', 'price', 'summary_posWordRate', 'itemID_helpfulRate', 'summary_count_words', 'summary_count_punctu', 'categoryID', 'category_numtrans', 'summary_negWordRate', 'rating_deviation', 'summary_count_firstCapital', 'summary_negWordCount', 'reviewText_negWordCount'}\n"
     ]
    }
   ],
   "source": [
    "# print features that did not help improve\n",
    "print(set(new_feature_list)-set(features_tokeep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Feature Contribution to MAE RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Features\n",
      "MAE for train data: 0.21789333333333333\n",
      "MAE for val data: 0.18766\n",
      "\n",
      "\n",
      "rating\n",
      "Accuracy for train data: 0.8498733333333334\n",
      "Accuracy for val data: 0.86334\n",
      "MAE for train data: 0.21588\n",
      "MAE for val data: 0.17534\n",
      "Difference from baseline: 0.012319999999999998\n",
      "\n",
      "\n",
      "unixReviewTime\n",
      "Accuracy for train data: 0.8476866666666667\n",
      "Accuracy for val data: 0.85496\n",
      "MAE for train data: 0.20734\n",
      "MAE for val data: 0.185\n",
      "Difference from baseline: 0.0026599999999999957\n",
      "\n",
      "\n",
      "price\n",
      "Accuracy for train data: 0.8473666666666667\n",
      "Accuracy for val data: 0.8538\n",
      "MAE for train data: 0.21122666666666667\n",
      "MAE for val data: 0.18532\n",
      "Difference from baseline: 0.002339999999999981\n",
      "\n",
      "\n",
      "categoryID\n",
      "Accuracy for train data: 0.84416\n",
      "Accuracy for val data: 0.85534\n",
      "MAE for train data: 0.20857333333333333\n",
      "MAE for val data: 0.18502\n",
      "Difference from baseline: 0.0026400000000000035\n",
      "\n",
      "\n",
      "categories_count\n",
      "Accuracy for train data: 0.84088\n",
      "Accuracy for val data: 0.85258\n",
      "MAE for train data: 0.21888666666666667\n",
      "MAE for val data: 0.18704\n",
      "Difference from baseline: 0.0006199999999999817\n",
      "\n",
      "\n",
      "category_numtrans\n",
      "Accuracy for train data: 0.84294\n",
      "Accuracy for val data: 0.85488\n",
      "MAE for train data: 0.21687333333333333\n",
      "MAE for val data: 0.18574\n",
      "Difference from baseline: 0.001920000000000005\n",
      "\n",
      "\n",
      "summary_count_words\n",
      "Accuracy for train data: 0.8412666666666667\n",
      "Accuracy for val data: 0.85256\n",
      "MAE for train data: 0.21633333333333332\n",
      "MAE for val data: 0.18722\n",
      "Difference from baseline: 0.00043999999999999595\n",
      "\n",
      "\n",
      "reviewText_count_words\n",
      "Accuracy for train data: 0.84172\n",
      "Accuracy for val data: 0.85556\n",
      "MAE for train data: 0.21718\n",
      "MAE for val data: 0.186\n",
      "Difference from baseline: 0.0016599999999999948\n",
      "\n",
      "\n",
      "itemID_helpfulRate\n",
      "Accuracy for train data: 0.8406866666666667\n",
      "Accuracy for val data: 0.85238\n",
      "MAE for train data: 0.22135333333333335\n",
      "MAE for val data: 0.1873\n",
      "Difference from baseline: 0.0003599999999999992\n",
      "\n",
      "\n",
      "reviewerID_helpfulRate\n",
      "Accuracy for train data: 0.8435266666666666\n",
      "Accuracy for val data: 0.85244\n",
      "MAE for train data: 0.21726666666666666\n",
      "MAE for val data: 0.18754\n",
      "Difference from baseline: 0.00011999999999998123\n",
      "\n",
      "\n",
      "reviewerID_numReviews\n",
      "Accuracy for train data: 0.83766\n",
      "Accuracy for val data: 0.8517\n",
      "MAE for train data: 0.22284666666666667\n",
      "MAE for val data: 0.18834\n",
      "Difference from baseline: -0.0006800000000000139\n",
      "\n",
      "\n",
      "rating_deviation\n",
      "Accuracy for train data: 0.8478133333333333\n",
      "Accuracy for val data: 0.86188\n",
      "MAE for train data: 0.22049333333333335\n",
      "MAE for val data: 0.17922\n",
      "Difference from baseline: 0.008440000000000003\n",
      "\n",
      "\n",
      "reviewText_posWordCount\n",
      "Accuracy for train data: 0.84484\n",
      "Accuracy for val data: 0.85468\n",
      "MAE for train data: 0.20990666666666666\n",
      "MAE for val data: 0.18504\n",
      "Difference from baseline: 0.0026199999999999835\n",
      "\n",
      "\n",
      "reviewText_negWordCount\n",
      "Accuracy for train data: 0.84026\n",
      "Accuracy for val data: 0.85478\n",
      "MAE for train data: 0.21698\n",
      "MAE for val data: 0.18544\n",
      "Difference from baseline: 0.0022199999999999998\n",
      "\n",
      "\n",
      "reviewText_posWordRate\n",
      "Accuracy for train data: 0.8500866666666667\n",
      "Accuracy for val data: 0.85806\n",
      "MAE for train data: 0.19981333333333334\n",
      "MAE for val data: 0.18134\n",
      "Difference from baseline: 0.006319999999999992\n",
      "\n",
      "\n",
      "reviewText_negWordRate\n",
      "Accuracy for train data: 0.84308\n",
      "Accuracy for val data: 0.85524\n",
      "MAE for train data: 0.20687333333333333\n",
      "MAE for val data: 0.18414\n",
      "Difference from baseline: 0.0035199999999999954\n",
      "\n",
      "\n",
      "summary_count_char\n",
      "Accuracy for train data: 0.8423466666666667\n",
      "Accuracy for val data: 0.8537\n",
      "MAE for train data: 0.21535333333333334\n",
      "MAE for val data: 0.18658\n",
      "Difference from baseline: 0.0010799999999999976\n",
      "\n",
      "\n",
      "reviewText_count_char\n",
      "Accuracy for train data: 0.8426066666666666\n",
      "Accuracy for val data: 0.85592\n",
      "MAE for train data: 0.21519333333333332\n",
      "MAE for val data: 0.18552\n",
      "Difference from baseline: 0.002140000000000003\n",
      "\n",
      "\n",
      "reviewText_count_punctu\n",
      "Accuracy for train data: 0.8433533333333333\n",
      "Accuracy for val data: 0.85396\n",
      "MAE for train data: 0.21056\n",
      "MAE for val data: 0.1868\n",
      "Difference from baseline: 0.0008599999999999997\n",
      "\n",
      "\n",
      "summary_count_punctu\n",
      "Accuracy for train data: 0.8426066666666666\n",
      "Accuracy for val data: 0.85308\n",
      "MAE for train data: 0.21532666666666667\n",
      "MAE for val data: 0.18678\n",
      "Difference from baseline: 0.0008799999999999919\n",
      "\n",
      "\n",
      "summary_posWordCount\n",
      "Accuracy for train data: 0.84316\n",
      "Accuracy for val data: 0.85818\n",
      "MAE for train data: 0.20502\n",
      "MAE for val data: 0.18122\n",
      "Difference from baseline: 0.006440000000000001\n",
      "\n",
      "\n",
      "summary_negWordCount\n",
      "Accuracy for train data: 0.8405133333333333\n",
      "Accuracy for val data: 0.85598\n",
      "MAE for train data: 0.20649333333333333\n",
      "MAE for val data: 0.18362\n",
      "Difference from baseline: 0.004039999999999988\n",
      "\n",
      "\n",
      "summary_posWordRate\n",
      "Accuracy for train data: 0.8459066666666667\n",
      "Accuracy for val data: 0.85822\n",
      "MAE for train data: 0.2017\n",
      "MAE for val data: 0.1817\n",
      "Difference from baseline: 0.005959999999999993\n",
      "\n",
      "\n",
      "summary_negWordRate\n",
      "Accuracy for train data: 0.84158\n",
      "Accuracy for val data: 0.85596\n",
      "MAE for train data: 0.2058\n",
      "MAE for val data: 0.18408\n",
      "Difference from baseline: 0.00358\n",
      "\n",
      "\n",
      "reviewText_count_firstCapital\n",
      "Accuracy for train data: 0.8424533333333334\n",
      "Accuracy for val data: 0.85552\n",
      "MAE for train data: 0.21170666666666665\n",
      "MAE for val data: 0.18588\n",
      "Difference from baseline: 0.0017800000000000038\n",
      "\n",
      "\n",
      "summary_count_firstCapital\n",
      "Accuracy for train data: 0.8450266666666667\n",
      "Accuracy for val data: 0.85454\n",
      "MAE for train data: 0.21211333333333332\n",
      "MAE for val data: 0.18484\n",
      "Difference from baseline: 0.002819999999999989\n",
      "\n",
      "\n",
      "reviewText_avgWordLength\n",
      "Accuracy for train data: 0.8434666666666667\n",
      "Accuracy for val data: 0.85172\n",
      "MAE for train data: 0.21454666666666666\n",
      "MAE for val data: 0.18816\n",
      "Difference from baseline: -0.0005000000000000004\n",
      "\n",
      "\n",
      "summary_avgWordLength\n",
      "Accuracy for train data: 0.8373266666666667\n",
      "Accuracy for val data: 0.85058\n",
      "MAE for train data: 0.22196\n",
      "MAE for val data: 0.18908\n",
      "Difference from baseline: -0.0014200000000000046\n",
      "\n",
      "\n",
      "unixReviewTime_delta_firstreview\n",
      "Accuracy for train data: 0.84362\n",
      "Accuracy for val data: 0.85246\n",
      "MAE for train data: 0.21502666666666667\n",
      "MAE for val data: 0.18634\n",
      "Difference from baseline: 0.0013199999999999878\n",
      "\n",
      "\n",
      "summary_reviewText_charRatio\n",
      "Accuracy for train data: 0.8432733333333333\n",
      "Accuracy for val data: 0.8536\n",
      "MAE for train data: 0.20844\n",
      "MAE for val data: 0.18692\n",
      "Difference from baseline: 0.0007399999999999907\n",
      "\n",
      "\n",
      "summary_reviewText_wordsRatio\n",
      "Accuracy for train data: 0.84336\n",
      "Accuracy for val data: 0.8537\n",
      "MAE for train data: 0.20946\n",
      "MAE for val data: 0.18876\n",
      "Difference from baseline: -0.0011000000000000176\n",
      "\n",
      "\n",
      "votes_time\n",
      "Accuracy for train data: 0.8415666666666667\n",
      "Accuracy for val data: 0.8522\n",
      "MAE for train data: 0.21814666666666666\n",
      "MAE for val data: 0.18754\n",
      "Difference from baseline: 0.00011999999999998123\n",
      "\n",
      "\n",
      "itemID_numReviews\n",
      "Accuracy for train data: 0.8442\n",
      "Accuracy for val data: 0.85172\n",
      "MAE for train data: 0.21948666666666666\n",
      "MAE for val data: 0.18792\n",
      "Difference from baseline: -0.0002600000000000102\n",
      "\n",
      "\n",
      "reviewText_capitalwords\n",
      "Accuracy for train data: 0.8431666666666666\n",
      "Accuracy for val data: 0.85288\n",
      "MAE for train data: 0.20797333333333334\n",
      "MAE for val data: 0.18586\n",
      "Difference from baseline: 0.001799999999999996\n",
      "\n",
      "\n",
      "summary_capitalwords\n",
      "Accuracy for train data: 0.84266\n",
      "Accuracy for val data: 0.85252\n",
      "MAE for train data: 0.21591333333333335\n",
      "MAE for val data: 0.1875\n",
      "Difference from baseline: 0.00015999999999999348\n",
      "\n",
      "\n",
      "reviewText_ExclQue_countchar\n",
      "Accuracy for train data: 0.8395866666666667\n",
      "Accuracy for val data: 0.85228\n",
      "MAE for train data: 0.22028666666666666\n",
      "MAE for val data: 0.18714\n",
      "Difference from baseline: 0.0005199999999999927\n",
      "\n",
      "\n",
      "summary_ExclQue_countchar\n",
      "Accuracy for train data: 0.8407466666666666\n",
      "Accuracy for val data: 0.85254\n",
      "MAE for train data: 0.22092666666666666\n",
      "MAE for val data: 0.18716\n",
      "Difference from baseline: 0.0005000000000000004\n",
      "\n",
      "\n",
      "reviewText_PunctChar_ratio\n",
      "Accuracy for train data: 0.8466533333333334\n",
      "Accuracy for val data: 0.85464\n",
      "MAE for train data: 0.20296\n",
      "MAE for val data: 0.1862\n",
      "Difference from baseline: 0.001459999999999989\n",
      "\n",
      "\n",
      "summary_PunctChar_ratio\n",
      "Accuracy for train data: 0.84318\n",
      "Accuracy for val data: 0.85328\n",
      "MAE for train data: 0.21513333333333334\n",
      "MAE for val data: 0.18662\n",
      "Difference from baseline: 0.0010399999999999854\n",
      "\n",
      "\n",
      "unixReviewTime_delta_lastreview\n",
      "Accuracy for train data: 0.8425466666666667\n",
      "Accuracy for val data: 0.85424\n",
      "MAE for train data: 0.2209\n",
      "MAE for val data: 0.18594\n",
      "Difference from baseline: 0.0017199999999999993\n",
      "\n",
      "\n",
      "CPU times: user 11min 51s, sys: 9.79 s, total: 12min\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "feature_MAE = []\n",
    "\n",
    "#################################### Baseline ####################################\n",
    "# define original feature lists\n",
    "original_features = ['itemID', 'reviewerID', 'outOf_feature']\n",
    "\n",
    "X_train_temp = X_train_filtered[original_features]\n",
    "# X_val_temp = X_val_1[original_features]\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0, n_jobs=-1)\n",
    "regr.fit(X_train_temp, y_train_filtered)\n",
    "\n",
    "y_pred = regr.predict(X_val[original_features])*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train[original_features])*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('Baseline Features')\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "baseline_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "feature_MAE.append(('baseline',baseline_mae))\n",
    "print('MAE for val data: {}'.format(baseline_mae))\n",
    "print('\\n')\n",
    "\n",
    "#################################### New Features ####################################\n",
    "# define new feature lists\n",
    "new_feature_list = ['rating', 'unixReviewTime', 'price',\n",
    "                    'categoryID','categories_count', 'category_numtrans','summary_count_words', \n",
    "                    'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "                    'reviewerID_numReviews', 'rating_deviation', 'reviewText_posWordCount', \n",
    "                    'reviewText_negWordCount','reviewText_posWordRate', 'reviewText_negWordRate', \n",
    "                    'summary_count_char', 'reviewText_count_char', 'reviewText_count_punctu',\n",
    "                    'summary_count_punctu','summary_posWordCount', \n",
    "                    'summary_negWordCount', 'summary_posWordRate','summary_negWordRate', \n",
    "                    'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "                    'reviewText_avgWordLength','summary_avgWordLength', 'unixReviewTime_delta_firstreview',\n",
    "                    'summary_reviewText_charRatio', 'summary_reviewText_wordsRatio',\n",
    "                    'votes_time', 'itemID_numReviews', 'reviewText_capitalwords', 'summary_capitalwords',\n",
    "                    'reviewText_ExclQue_countchar', 'summary_ExclQue_countchar',\n",
    "                    'reviewText_PunctChar_ratio', 'summary_PunctChar_ratio', 'unixReviewTime_delta_lastreview']\n",
    "\n",
    "features_tokeep = []\n",
    "for feature in new_feature_list:\n",
    "    \n",
    "    X_train_temp = X_train_filtered[original_features + [feature]]\n",
    "#     X_val = X_val_1[original_features + [feature]]\n",
    "    \n",
    "    regr = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    regr.fit(X_train_temp, y_train_filtered)\n",
    "\n",
    "    y_pred = regr.predict(X_val[original_features + [feature]])*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "    y_pred_train = regr.predict(X_train[original_features + [feature]])*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "    # round to the nearest integer\n",
    "    y_pred = [int(round(i)) for i in y_pred]\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "    print(feature)\n",
    "    \n",
    "    print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "    print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "    \n",
    "    print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "    feature_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "    feature_MAE.append((feature,feature_mae))\n",
    "    print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))\n",
    "    print('Difference from baseline: {}'.format(baseline_mae-feature_mae))\n",
    "    print('\\n')\n",
    "    \n",
    "    # keep features with lower MAE than baseline\n",
    "    if feature_mae < baseline_mae:\n",
    "        features_tokeep.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rating',\n",
       " 'unixReviewTime',\n",
       " 'price',\n",
       " 'categoryID',\n",
       " 'categories_count',\n",
       " 'category_numtrans',\n",
       " 'summary_count_words',\n",
       " 'reviewText_count_words',\n",
       " 'itemID_helpfulRate',\n",
       " 'reviewerID_helpfulRate',\n",
       " 'rating_deviation',\n",
       " 'reviewText_posWordCount',\n",
       " 'reviewText_negWordCount',\n",
       " 'reviewText_posWordRate',\n",
       " 'reviewText_negWordRate',\n",
       " 'summary_count_char',\n",
       " 'reviewText_count_char',\n",
       " 'reviewText_count_punctu',\n",
       " 'summary_count_punctu',\n",
       " 'summary_posWordCount',\n",
       " 'summary_negWordCount',\n",
       " 'summary_posWordRate',\n",
       " 'summary_negWordRate',\n",
       " 'reviewText_count_firstCapital',\n",
       " 'summary_count_firstCapital',\n",
       " 'unixReviewTime_delta_firstreview',\n",
       " 'summary_reviewText_charRatio',\n",
       " 'votes_time',\n",
       " 'reviewText_capitalwords',\n",
       " 'summary_capitalwords',\n",
       " 'reviewText_ExclQue_countchar',\n",
       " 'summary_ExclQue_countchar',\n",
       " 'reviewText_PunctChar_ratio',\n",
       " 'summary_PunctChar_ratio',\n",
       " 'unixReviewTime_delta_lastreview']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print features that help improve\n",
    "features_tokeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itemID_numReviews', 'summary_avgWordLength', 'reviewText_avgWordLength', 'reviewerID_numReviews', 'summary_reviewText_wordsRatio'}\n"
     ]
    }
   ],
   "source": [
    "# print features that did not help improve\n",
    "print(set(new_feature_list)-set(features_tokeep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rating', 0.17534),\n",
       " ('rating_deviation', 0.17922),\n",
       " ('summary_posWordCount', 0.18122),\n",
       " ('reviewText_posWordRate', 0.18134),\n",
       " ('summary_posWordRate', 0.1817),\n",
       " ('summary_negWordCount', 0.18362),\n",
       " ('summary_negWordRate', 0.18408),\n",
       " ('reviewText_negWordRate', 0.18414),\n",
       " ('summary_count_firstCapital', 0.18484),\n",
       " ('unixReviewTime', 0.185),\n",
       " ('categoryID', 0.18502),\n",
       " ('reviewText_posWordCount', 0.18504),\n",
       " ('price', 0.18532),\n",
       " ('reviewText_negWordCount', 0.18544),\n",
       " ('reviewText_count_char', 0.18552),\n",
       " ('category_numtrans', 0.18574),\n",
       " ('reviewText_capitalwords', 0.18586),\n",
       " ('reviewText_count_firstCapital', 0.18588),\n",
       " ('unixReviewTime_delta_lastreview', 0.18594),\n",
       " ('reviewText_count_words', 0.186),\n",
       " ('reviewText_PunctChar_ratio', 0.1862),\n",
       " ('unixReviewTime_delta_firstreview', 0.18634),\n",
       " ('summary_count_char', 0.18658),\n",
       " ('summary_PunctChar_ratio', 0.18662),\n",
       " ('summary_count_punctu', 0.18678),\n",
       " ('reviewText_count_punctu', 0.1868),\n",
       " ('summary_reviewText_charRatio', 0.18692),\n",
       " ('categories_count', 0.18704),\n",
       " ('reviewText_ExclQue_countchar', 0.18714),\n",
       " ('summary_ExclQue_countchar', 0.18716),\n",
       " ('summary_count_words', 0.18722),\n",
       " ('itemID_helpfulRate', 0.1873),\n",
       " ('summary_capitalwords', 0.1875),\n",
       " ('reviewerID_helpfulRate', 0.18754),\n",
       " ('votes_time', 0.18754),\n",
       " ('baseline', 0.18766),\n",
       " ('itemID_numReviews', 0.18792),\n",
       " ('reviewText_avgWordLength', 0.18816),\n",
       " ('reviewerID_numReviews', 0.18834),\n",
       " ('summary_reviewText_wordsRatio', 0.18876),\n",
       " ('summary_avgWordLength', 0.18908)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(feature_MAE, key= lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize\n",
    "# X_train_norm = X_train.apply(lambda x : (x-x.mean())/x.std())\n",
    "# X_val_norm = X_val.apply(lambda x : (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # apply pca\n",
    "# pca = PCA(n_components=18)\n",
    "# pca.fit(X_train_norm)\n",
    "# X_train_transformed = pca.fit_transform(X_train_norm)\n",
    "# X_val_transformed = pca.fit_transform(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cumulative explained variance ratio\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# print('Total Variance Explained Ratio: {}'.format(np.sum(pca.explained_variance_ratio_)))\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [5, 11, 17, 23, 30, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [50, 150, 250, 350, 450]}\n"
     ]
    }
   ],
   "source": [
    "# randomized search CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 450, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 73.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 51s, sys: 1.87 s, total: 2min 52s\n",
      "Wall time: 1h 16min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [5, 11, 17, 23, 30, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 150, 250, 350,\n",
       "                                                         450]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gio/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=27. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 33.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md:12, ne:500\n",
      "Accuracy for train data: 0.6317658025744263\n",
      "Accuracy for val data: 0.870475\n",
      "MAE for train data: 0.43832682123802535\n",
      "MAE for val data: 0.16515\n",
      "CPU times: user 4min 24s, sys: 1.58 s, total: 4min 26s\n",
      "Wall time: 37min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# apply random forest for votes > 2\n",
    "X_train = X_train_1[original_features + features_tokeep]\n",
    "X_val = X_val_1[original_features + features_tokeep]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': [400,500,600],\n",
    "               'max_depth': [8,10,12]\n",
    "                }\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "regr = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 9 cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('md:{}, ne:{}'.format(md,ne))\n",
    "\n",
    "print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400, 'max_depth': 12}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md:10, ne:100\n",
      "Accuracy for train data: 0.86622\n",
      "Accuracy for val data: 0.86768\n",
      "MAE for train data: 0.18704666666666667\n",
      "MAE for val data: 0.16884\n",
      "CPU times: user 1min 26s, sys: 1.13 s, total: 1min 27s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# apply random forest for votes > 2\n",
    "X_train_temp = X_train_filtered[original_features + features_tokeep]\n",
    "# X_val_temp = X_val_1[original_features]\n",
    "\n",
    "for md in [10]:\n",
    "    for ne in [100]:\n",
    "\n",
    "        regr = RandomForestRegressor(max_depth=md,n_estimators=ne, random_state=0, n_jobs=-1, criterion='mse')\n",
    "        # regr = RandomForestRegressor(n_estimators=450, min_samples_split=2, min_samples_leaf=2, random_state=0, \n",
    "        #                             max_features='auto', max_depth=11, bootstrap=True)\n",
    "        regr.fit(X_train_temp, y_train_filtered)\n",
    "\n",
    "        y_pred = regr.predict(X_val[original_features + features_tokeep])*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "        y_pred_train = regr.predict(X_train[original_features + features_tokeep])*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "        # round to the nearest integer\n",
    "        y_pred = [int(round(i)) for i in y_pred]\n",
    "        y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "        print('md:{}, ne:{}'.format(md,ne))\n",
    "        \n",
    "        print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "        print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "        \n",
    "        print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "        print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>outOf_feature</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewText_count_firstCapital</th>\n",
       "      <th>summary_count_firstCapital</th>\n",
       "      <th>unixReviewTime_delta_firstreview</th>\n",
       "      <th>summary_reviewText_charRatio</th>\n",
       "      <th>itemID_numReviews</th>\n",
       "      <th>summary_capitalwords</th>\n",
       "      <th>summary_ExclQue_countchar</th>\n",
       "      <th>reviewText_PunctChar_ratio</th>\n",
       "      <th>summary_PunctChar_ratio</th>\n",
       "      <th>unixReviewTime_delta_lastreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130248</th>\n",
       "      <td>15265</td>\n",
       "      <td>20193</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1329004800</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>551</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>139881600</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>4924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182454</th>\n",
       "      <td>10110</td>\n",
       "      <td>20969</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1404691200</td>\n",
       "      <td>22.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>437</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29894400</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176029</th>\n",
       "      <td>2813</td>\n",
       "      <td>6219</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1376092800</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26352000</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>11768</td>\n",
       "      <td>14780</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1383177600</td>\n",
       "      <td>59.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1104</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1123200</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25017</th>\n",
       "      <td>5445</td>\n",
       "      <td>1962</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1296604800</td>\n",
       "      <td>19.88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2276</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5097600</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5097600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        itemID  reviewerID  outOf_feature  rating  unixReviewTime   price  \\\n",
       "130248   15265       20193             13     4.0      1329004800 -999.00   \n",
       "182454   10110       20969              1     2.0      1404691200   22.99   \n",
       "176029    2813        6219              1     5.0      1376092800   12.99   \n",
       "13049    11768       14780              6     5.0      1383177600   59.99   \n",
       "25017     5445        1962              1     1.0      1296604800   19.88   \n",
       "\n",
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "130248           0                 2                551                    3   \n",
       "182454           0                 1                437                    3   \n",
       "176029           0                 1                327                    1   \n",
       "13049            0                 1               1104                    1   \n",
       "25017            0                 2               2276                    2   \n",
       "\n",
       "        ...  reviewText_count_firstCapital  summary_count_firstCapital  \\\n",
       "130248  ...                             24                           1   \n",
       "182454  ...                              4                           1   \n",
       "176029  ...                              3                           0   \n",
       "13049   ...                              8                           1   \n",
       "25017   ...                              7                           1   \n",
       "\n",
       "        unixReviewTime_delta_firstreview  summary_reviewText_charRatio  \\\n",
       "130248                         139881600                      0.022203   \n",
       "182454                          29894400                      0.234783   \n",
       "176029                          26352000                      0.076433   \n",
       "13049                            1123200                      0.024922   \n",
       "25017                            5097600                      0.057471   \n",
       "\n",
       "        itemID_numReviews  summary_capitalwords  summary_ExclQue_countchar  \\\n",
       "130248                 49                     0                          0   \n",
       "182454                  5                     0                          0   \n",
       "176029                 10                     0                          1   \n",
       "13049                   5                     0                          0   \n",
       "25017                   4                     0                          0   \n",
       "\n",
       "        reviewText_PunctChar_ratio  summary_PunctChar_ratio  \\\n",
       "130248                    0.021349                 0.038462   \n",
       "182454                    0.043478                 0.111111   \n",
       "176029                    0.025478                 0.083333   \n",
       "13049                     0.037383                 0.000000   \n",
       "25017                     0.030651                 0.066667   \n",
       "\n",
       "        unixReviewTime_delta_lastreview  \n",
       "130248                          4924800  \n",
       "182454                          1036800  \n",
       "176029                           172800  \n",
       "13049                             86400  \n",
       "25017                           5097600  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130248    13\n",
       "182454     1\n",
       "176029     1\n",
       "13049      6\n",
       "25017      1\n",
       "          ..\n",
       "140296     9\n",
       "174074     2\n",
       "16241      2\n",
       "37597      4\n",
       "181568     8\n",
       "Name: outOf_feature, Length: 50419, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.outOf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train data: 0.8843714130369117\n",
      "Accuracy for val data: 0.8773821388662378\n",
      "MAE for train data: 0.11562858696308827\n",
      "MAE for val data: 0.12261786113376219\n",
      "CPU times: user 931 ms, sys: 92 ms, total: 1.02 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# apply logistic regression to votes equal to 0 and 1\n",
    "\n",
    "X_train = X_train_1[original_features + features_tokeep]\n",
    "X_val = X_val_1[original_features + features_tokeep]\n",
    "\n",
    "# parameters = { 'penalty': ['l1','l2'], \n",
    "#               'C':[0.1, 0.5, 1, 2, 3, 4, 5, 10]}\n",
    "clf = LogisticRegression(penalty='l2', C=1, n_jobs=-1)\n",
    "# clf = GridSearchCV(logreg, parameters, verbose=True, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = clf.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "# print('md:{}, ne:{}'.format(md,ne))\n",
    "\n",
    "print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>outOf_feature</th>\n",
       "      <th>rating</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>reviewerID_numReviews</th>\n",
       "      <th>reviewText_posWordCount</th>\n",
       "      <th>reviewText_count_char</th>\n",
       "      <th>reviewText_count_firstCapital</th>\n",
       "      <th>summary_avgWordLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62732</th>\n",
       "      <td>16904</td>\n",
       "      <td>18201</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182454</th>\n",
       "      <td>2023</td>\n",
       "      <td>28682</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158745</th>\n",
       "      <td>1940</td>\n",
       "      <td>11231</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176029</th>\n",
       "      <td>12868</td>\n",
       "      <td>14824</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64520</th>\n",
       "      <td>6313</td>\n",
       "      <td>12493</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>15188</td>\n",
       "      <td>37367</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105595</th>\n",
       "      <td>13476</td>\n",
       "      <td>2891</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93553</th>\n",
       "      <td>17844</td>\n",
       "      <td>30564</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94735</th>\n",
       "      <td>16321</td>\n",
       "      <td>21837</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83209</th>\n",
       "      <td>13859</td>\n",
       "      <td>17990</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132424 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        itemID  reviewerID  outOf_feature  rating  categories_count  \\\n",
       "62732    16904       18201              0     5.0                 3   \n",
       "182454    2023       28682              1     2.0                 1   \n",
       "158745    1940       11231              0     4.0                 1   \n",
       "176029   12868       14824              1     5.0                 1   \n",
       "64520     6313       12493              0     5.0                 3   \n",
       "...        ...         ...            ...     ...               ...   \n",
       "9372     15188       37367              0     5.0                 1   \n",
       "105595   13476        2891              0     4.0                 1   \n",
       "93553    17844       30564              0     4.0                 5   \n",
       "94735    16321       21837              0     3.0                 2   \n",
       "83209    13859       17990              0     5.0                 6   \n",
       "\n",
       "        reviewText_count_words  reviewerID_numReviews  \\\n",
       "62732                       17                      7   \n",
       "182454                       9                     18   \n",
       "158745                      25                      9   \n",
       "176029                      14                      3   \n",
       "64520                       22                      5   \n",
       "...                        ...                    ...   \n",
       "9372                         8                     14   \n",
       "105595                       9                      5   \n",
       "93553                       10                      3   \n",
       "94735                        8                      5   \n",
       "83209                       10                      4   \n",
       "\n",
       "        reviewText_posWordCount  reviewText_count_char  \\\n",
       "62732                         0                    219   \n",
       "182454                        0                    115   \n",
       "158745                        0                    255   \n",
       "176029                        4                    157   \n",
       "64520                         6                    249   \n",
       "...                         ...                    ...   \n",
       "9372                          2                     87   \n",
       "105595                        3                    102   \n",
       "93553                         3                     99   \n",
       "94735                         4                    111   \n",
       "83209                         3                    122   \n",
       "\n",
       "        reviewText_count_firstCapital  summary_avgWordLength  \n",
       "62732                               5                    4.0  \n",
       "182454                              4                    5.0  \n",
       "158745                              9                    4.0  \n",
       "176029                              3                    6.0  \n",
       "64520                               8                    6.0  \n",
       "...                               ...                    ...  \n",
       "9372                                3                    6.5  \n",
       "105595                              5                    4.0  \n",
       "93553                               3                    4.0  \n",
       "94735                               4                    2.0  \n",
       "83209                               3                    5.0  \n",
       "\n",
       "[132424 rows x 11 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132424, 11)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.5872984390805054\n",
      "MAE for val data: 0.189175\n",
      "CPU times: user 2min 17s, sys: 475 ms, total: 2min 17s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# USING PCA\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=450, min_samples_split=2, min_samples_leaf=2, random_state=0, \n",
    "                            max_features='auto', max_depth=11, bootstrap=True)\n",
    "regr.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_val_transformed)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train_transformed)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.5644895773418751\n",
      "MAE for val data: 0.19455\n",
      "CPU times: user 1min 15s, sys: 328 ms, total: 1min 15s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# USING PCA\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "regr.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_val_transformed)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train_transformed)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 1\n",
      "MAE for train data: 0.7409111644419762\n",
      "MAE for val data: 0.228675\n",
      "max depth: 2\n",
      "MAE for train data: 0.624407465439616\n",
      "MAE for val data: 0.191625\n",
      "max depth: 3\n",
      "MAE for train data: 0.5931692417541007\n",
      "MAE for val data: 0.179825\n",
      "max depth: 4\n",
      "MAE for train data: 0.5688728455542553\n",
      "MAE for val data: 0.1715\n",
      "max depth: 5\n",
      "MAE for train data: 0.5607013229139809\n",
      "MAE for val data: 0.1689\n",
      "max depth: 6\n",
      "MAE for train data: 0.5589162815605229\n",
      "MAE for val data: 0.1689\n",
      "max depth: 7\n",
      "MAE for train data: 0.5465003272575815\n",
      "MAE for val data: 0.167325\n",
      "max depth: 8\n",
      "MAE for train data: 0.5397766714928895\n",
      "MAE for val data: 0.167175\n",
      "max depth: 9\n",
      "MAE for train data: 0.5195660366131816\n",
      "MAE for val data: 0.16975\n",
      "max depth: 10\n",
      "MAE for train data: 0.5061187250837977\n",
      "MAE for val data: 0.172975\n",
      "max depth: 100\n",
      "MAE for train data: 0.0\n",
      "MAE for val data: 0.2337\n",
      "CPU times: user 7.36 s, sys: 184 ms, total: 7.55 s\n",
      "Wall time: 7.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for md in [1,2,3,4,5,6,7,8,9,10,100]:\n",
    "    regr = DecisionTreeRegressor(max_depth=md, random_state=0)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "    y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "    # round to the nearest integer\n",
    "    y_pred = [int(round(i)) for i in y_pred]\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "    print('max depth: {}'.format(md))\n",
    "    print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "    print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # USING PCA\n",
    "# for md in [5, 10, 15]:\n",
    "#     regr = DecisionTreeRegressor(max_depth=md, random_state=0)\n",
    "#     regr.fit(X_train_transformed, y_train)\n",
    "\n",
    "#     y_pred = regr.predict(X_val_transformed)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "#     y_pred_train = regr.predict(X_train_transformed)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "#     # round to the nearest integer\n",
    "#     y_pred = [int(round(i)) for i in y_pred]\n",
    "#     y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "#     print('max depth: {}'.format(md))\n",
    "#     print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "#     print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter: 100, alpha: 0.0001\n",
      "MAE for train data: 14318.49576875\n",
      "MAE for val data: 14191.3678\n",
      "max_iter: 100, alpha: 0.01\n",
      "MAE for train data: 34262.94459375\n",
      "MAE for val data: 33958.750725\n"
     ]
    }
   ],
   "source": [
    "for i in [100]:\n",
    "    for j in [0.0001,0.01]:\n",
    "        regr = MLPRegressor(random_state=1, max_iter=i, alpha=j)\n",
    "        regr.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "        y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "        # round to the nearest integer\n",
    "        y_pred = [int(round(i)) for i in y_pred]\n",
    "        y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "        print('max_iter: {}, alpha: {}'.format(i,j))\n",
    "        print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "        print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.89464375\n",
      "MAE for val data: 0.975725\n"
     ]
    }
   ],
   "source": [
    "# Least squares regression\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = np.dot(X_val, theta)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = np.dot(X_train, theta)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.8164625\n",
      "MAE for val data: 0.878375\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.47206410281838196\n",
      "MAE for val data: 0.1754\n",
      "CPU times: user 7min 58s, sys: 2.3 s, total: 8min\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Forests\n",
    "X_train = X_train_1[original_features + features_tokeep]\n",
    "X_val = X_val_1[original_features + features_tokeep]\n",
    "\n",
    "regr = AdaBoostRegressor(RandomForestRegressor(max_depth=12,n_estimators=120, random_state=0), \n",
    "                         n_estimators = 120, random_state=10)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.18184375\n",
      "MAE for val data: 0.19145\n",
      "MAE for train data: 0.19706875\n",
      "MAE for val data: 0.207225\n",
      "CPU times: user 2min 15s, sys: 3.13 s, total: 2min 18s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Decision Trees\n",
    "for i in [10,100]:\n",
    "\n",
    "    regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=10, random_state=0), n_estimators = i, random_state=10)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regr.predict(X_val)*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "    y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "    # round to the nearest integer\n",
    "    y_pred = [int(round(i)) for i in y_pred]\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "    print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "    print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 58s, sys: 5.83 s, total: 4min 4s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "# get indices\n",
    "idx = np.array([i['outOf'] for i in df_features.helpful]) > 0\n",
    "\n",
    "# Get features\n",
    "X_train = Get_features(df_features)\n",
    "X_test = Get_features(test_df)\n",
    "\n",
    "# find filtered test data\n",
    "X_train_filt = Get_features(df_features.loc[idx,:])\n",
    "y_train_filt = Get_labels(list(compress(df_labels, idx))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove reviews where votes are zero - training data only\n",
    "# from itertools import compress\n",
    "\n",
    "# idx = X_train.outOf_feature != 0\n",
    "\n",
    "# X_train = X_train.loc[idx,:]\n",
    "# y_train = list(compress(y_train, idx))\n",
    "\n",
    "# df_features = df_features.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories_count</th>\n",
       "      <th>category_numtrans</th>\n",
       "      <th>summary_count_words</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText_count_words</th>\n",
       "      <th>itemID_helpfulRate</th>\n",
       "      <th>reviewerID_helpfulRate</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_reviewText_charRatio</th>\n",
       "      <th>summary_reviewText_wordsRatio</th>\n",
       "      <th>itemID_numReviews</th>\n",
       "      <th>reviewText_capitalwords</th>\n",
       "      <th>summary_capitalwords</th>\n",
       "      <th>reviewText_ExclQue_countchar</th>\n",
       "      <th>summary_ExclQue_countchar</th>\n",
       "      <th>reviewText_PunctChar_ratio</th>\n",
       "      <th>summary_PunctChar_ratio</th>\n",
       "      <th>unixReviewTime_delta_lastreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1672</td>\n",
       "      <td>2</td>\n",
       "      <td>1958</td>\n",
       "      <td>22815</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>5788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1801</td>\n",
       "      <td>2</td>\n",
       "      <td>10744</td>\n",
       "      <td>19800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025943</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1374</td>\n",
       "      <td>2</td>\n",
       "      <td>7557</td>\n",
       "      <td>17278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>989</td>\n",
       "      <td>4</td>\n",
       "      <td>2451</td>\n",
       "      <td>2578</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060453</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2630</td>\n",
       "      <td>3</td>\n",
       "      <td>15427</td>\n",
       "      <td>10285</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1146</td>\n",
       "      <td>2</td>\n",
       "      <td>16056</td>\n",
       "      <td>901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>2</td>\n",
       "      <td>11341</td>\n",
       "      <td>13277</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2095</td>\n",
       "      <td>3</td>\n",
       "      <td>14605</td>\n",
       "      <td>22718</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1372</td>\n",
       "      <td>4</td>\n",
       "      <td>15611</td>\n",
       "      <td>17021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050132</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>7430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1708</td>\n",
       "      <td>2</td>\n",
       "      <td>15481</td>\n",
       "      <td>22715</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63016 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryID  categories_count  category_numtrans  summary_count_words  \\\n",
       "2                0                 3               1672                    2   \n",
       "4                0                 3               1801                    2   \n",
       "5                0                 2               1374                    2   \n",
       "14               3                 2                989                    4   \n",
       "20               0                 4               2630                    3   \n",
       "...            ...               ...                ...                  ...   \n",
       "199979           0                 1               1146                    2   \n",
       "199984           0                 1                445                    2   \n",
       "199992           1                 3               2095                    3   \n",
       "199996           1                 1               1372                    4   \n",
       "199998           0                 2               1708                    2   \n",
       "\n",
       "        itemID  reviewerID  rating  reviewText_count_words  \\\n",
       "2         1958       22815     3.0                      15   \n",
       "4        10744       19800     5.0                      43   \n",
       "5         7557       17278     4.0                      44   \n",
       "14        2451        2578     4.0                      44   \n",
       "20       15427       10285     5.0                      14   \n",
       "...        ...         ...     ...                     ...   \n",
       "199979   16056         901     5.0                      12   \n",
       "199984   11341       13277     5.0                      42   \n",
       "199992   14605       22718     4.0                      42   \n",
       "199996   15611       17021     2.0                      83   \n",
       "199998   15481       22715     4.0                      18   \n",
       "\n",
       "        itemID_helpfulRate  reviewerID_helpfulRate  ...  \\\n",
       "2                 0.850045                0.850045  ...   \n",
       "4                 0.850045                0.850045  ...   \n",
       "5                 0.850045                0.850045  ...   \n",
       "14                0.850045                0.850045  ...   \n",
       "20                0.850045                0.850045  ...   \n",
       "...                    ...                     ...  ...   \n",
       "199979            0.850045                0.850045  ...   \n",
       "199984            0.850045                0.850045  ...   \n",
       "199992            0.850045                0.850045  ...   \n",
       "199996            0.850045                0.850045  ...   \n",
       "199998            0.850045                0.850045  ...   \n",
       "\n",
       "        summary_reviewText_charRatio  summary_reviewText_wordsRatio  \\\n",
       "2                           0.118056                       0.133333   \n",
       "4                           0.025943                       0.046512   \n",
       "5                           0.051502                       0.045455   \n",
       "14                          0.060453                       0.090909   \n",
       "20                          0.143939                       0.214286   \n",
       "...                              ...                            ...   \n",
       "199979                      0.158333                       0.166667   \n",
       "199984                      0.042654                       0.047619   \n",
       "199992                      0.083333                       0.071429   \n",
       "199996                      0.050132                       0.048193   \n",
       "199998                      0.071429                       0.111111   \n",
       "\n",
       "        itemID_numReviews  reviewText_capitalwords  summary_capitalwords  \\\n",
       "2                       7                        0                     0   \n",
       "4                       4                        1                     0   \n",
       "5                      50                        2                     0   \n",
       "14                      2                        2                     0   \n",
       "20                      5                        1                     0   \n",
       "...                   ...                      ...                   ...   \n",
       "199979                  4                        1                     0   \n",
       "199984                  6                        2                     1   \n",
       "199992                  3                        1                     0   \n",
       "199996                 11                        1                     0   \n",
       "199998                 24                        1                     0   \n",
       "\n",
       "        reviewText_ExclQue_countchar  summary_ExclQue_countchar  \\\n",
       "2                                  0                          0   \n",
       "4                                  1                          0   \n",
       "5                                  0                          0   \n",
       "14                                 0                          0   \n",
       "20                                 0                          0   \n",
       "...                              ...                        ...   \n",
       "199979                             0                          0   \n",
       "199984                             0                          0   \n",
       "199992                             1                          0   \n",
       "199996                             0                          0   \n",
       "199998                             0                          0   \n",
       "\n",
       "        reviewText_PunctChar_ratio  summary_PunctChar_ratio  \\\n",
       "2                         0.048611                 0.176471   \n",
       "4                         0.047170                 0.000000   \n",
       "5                         0.021459                 0.000000   \n",
       "14                        0.027708                 0.000000   \n",
       "20                        0.022727                 0.000000   \n",
       "...                            ...                      ...   \n",
       "199979                    0.041667                 0.000000   \n",
       "199984                    0.014218                 0.055556   \n",
       "199992                    0.019380                 0.000000   \n",
       "199996                    0.026385                 0.026316   \n",
       "199998                    0.029762                 0.000000   \n",
       "\n",
       "        unixReviewTime_delta_lastreview  \n",
       "2                               5788800  \n",
       "4                              17625600  \n",
       "5                                950400  \n",
       "14                               172800  \n",
       "20                                    0  \n",
       "...                                 ...  \n",
       "199979                                0  \n",
       "199984                                0  \n",
       "199992                                0  \n",
       "199996                          7430400  \n",
       "199998                                0  \n",
       "\n",
       "[63016 rows x 43 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(pred):\n",
    "    \n",
    "    predictions = open(\"predictions_Helpful.txt\", 'w')\n",
    "    \n",
    "    count = 0\n",
    "    for l in open(\"pairs_Helpful.txt\"):\n",
    "        \n",
    "        if l.startswith(\"userID\"):\n",
    "            #header``````````a\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        \n",
    "        u,i,outOf = l.strip().split('-')\n",
    "        \n",
    "        predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(pred[count]) + '\\n')\n",
    "        \n",
    "        count+=1\n",
    "    \n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 108.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train data: 0.6700361812872921\n",
      "MAE for train data: 0.3850926748762219\n",
      "CPU times: user 9min 46s, sys: 3.04 s, total: 9min 49s\n",
      "Wall time: 1h 57min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# apply random forest for votes > 2\n",
    "X_train = X_train[original_features + features_tokeep]\n",
    "X_test = X_test[original_features + features_tokeep]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': [50,100,150,200,400,600],\n",
    "               'max_depth': [8,10,12,14]\n",
    "                }\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "regr = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20,cv = 5, verbose=2, random_state=0, n_jobs = -1)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)*np.array([i['outOf'] for i in test_df['helpful']])\n",
    "y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in df_features['helpful']])\n",
    "\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "# print(C)\n",
    "print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in df_features['helpful']], \n",
    "                                                          y_pred_train)))\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in df_features['helpful']], \n",
    "                                                          y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600, 'max_depth': 14}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train data: 0.8683\n",
      "MAE for train data: 0.176825\n",
      "CPU times: user 1min 12s, sys: 847 ms, total: 1min 12s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_temp = X_train_filt[original_features + features_tokeep]\n",
    "# X_test = X_test[original_features + features_tokeep]\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0)\n",
    "regr.fit(X_train_temp, y_train_filt)\n",
    "\n",
    "y_pred = regr.predict(X_test[original_features + features_tokeep])*np.array([i['outOf'] for i in test_df['helpful']])\n",
    "y_pred_train = regr.predict(X_train[original_features + features_tokeep])*np.array([i['outOf'] for i in df_features['helpful']])\n",
    "\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "# print(C)\n",
    "print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in df_features['helpful']], \n",
    "                                                          y_pred_train)))\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in df_features['helpful']], \n",
    "                                                          y_pred_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data: 0.4795924844483941\n",
      "CPU times: user 3min 23s, sys: 1.34 s, total: 3min 25s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = RandomForestRegressor(n_estimators=450, min_samples_split=2, min_samples_leaf=2, random_state=0, \n",
    "                            max_features='auto', max_depth=11, bootstrap=True)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)*np.array([i['outOf'] for i in test_df['helpful']])\n",
    "y_pred_train = regr.predict(X_train)*np.array([i['outOf'] for i in df_features['helpful']])\n",
    "\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "# print(C)\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in df_features['helpful']], \n",
    "                                                          y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
