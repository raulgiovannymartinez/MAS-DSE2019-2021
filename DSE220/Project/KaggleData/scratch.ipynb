{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "feature_MAE = []\n",
    "\n",
    "#################################### Baseline ####################################\n",
    "# define original feature lists\n",
    "original_features = ['itemID', 'reviewerID', 'outOf_feature']\n",
    "\n",
    "X_train_temp = X_train_filtered[original_features]\n",
    "# X_val_temp = X_val_1[original_features]\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0, n_jobs=-1)\n",
    "regr.fit(X_train_temp, y_train_filtered)\n",
    "\n",
    "y_pred = regr.predict(X_val[original_features])*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "y_pred_train = regr.predict(X_train[original_features])*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "# round to the nearest integer\n",
    "y_pred = [int(round(i)) for i in y_pred]\n",
    "y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "print('Baseline Features')\n",
    "print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "baseline_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "feature_MAE.append(('baseline',baseline_mae))\n",
    "print('MAE for val data: {}'.format(baseline_mae))\n",
    "print('\\n')\n",
    "\n",
    "#################################### New Features ####################################\n",
    "# define new feature lists\n",
    "new_feature_list = ['rating', 'unixReviewTime', 'price',\n",
    "                    'categoryID','categories_count', 'category_numtrans','summary_count_words', \n",
    "                    'reviewText_count_words', 'itemID_helpfulRate', 'reviewerID_helpfulRate',\n",
    "                    'reviewerID_numReviews', 'rating_deviation', 'reviewText_posWordCount', \n",
    "                    'reviewText_negWordCount','reviewText_posWordRate', 'reviewText_negWordRate', \n",
    "                    'summary_count_char', 'reviewText_count_char', 'reviewText_count_punctu',\n",
    "                    'summary_count_punctu','summary_posWordCount', \n",
    "                    'summary_negWordCount', 'summary_posWordRate','summary_negWordRate', \n",
    "                    'reviewText_count_firstCapital', 'summary_count_firstCapital',\n",
    "                    'reviewText_avgWordLength','summary_avgWordLength', 'unixReviewTime_delta_firstreview',\n",
    "                    'summary_reviewText_charRatio', 'summary_reviewText_wordsRatio',\n",
    "                    'votes_time', 'itemID_numReviews', 'reviewText_capitalwords', 'summary_capitalwords',\n",
    "                    'reviewText_ExclQue_countchar', 'summary_ExclQue_countchar',\n",
    "                    'reviewText_PunctChar_ratio', 'summary_PunctChar_ratio', 'unixReviewTime_delta_lastreview']\n",
    "\n",
    "features_tokeep = []\n",
    "for feature in new_feature_list:\n",
    "    \n",
    "    X_train_temp = X_train_filtered[original_features + [feature]]\n",
    "#     X_val = X_val_1[original_features + [feature]]\n",
    "    \n",
    "    regr = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    regr.fit(X_train_temp, y_train_filtered)\n",
    "\n",
    "    y_pred = regr.predict(X_val[original_features + [feature]])*np.array([i['outOf'] for i in X_val_raw['helpful']])\n",
    "    y_pred_train = regr.predict(X_train[original_features + [feature]])*np.array([i['outOf'] for i in X_train_raw['helpful']])\n",
    "\n",
    "    # round to the nearest integer\n",
    "    y_pred = [int(round(i)) for i in y_pred]\n",
    "    y_pred_train = [int(round(i)) for i in y_pred_train]\n",
    "\n",
    "    print(feature)\n",
    "    \n",
    "    print('Accuracy for train data: {}'.format(accuracy_score([i['nHelpful'] for i in y_train_raw],y_pred_train)))\n",
    "    print('Accuracy for val data: {}'.format(accuracy_score([i['nHelpful'] for i in y_val_raw],y_pred)))\n",
    "    \n",
    "    print('MAE for train data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_train_raw], y_pred_train)))\n",
    "    feature_mae = mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)\n",
    "    feature_MAE.append((feature,feature_mae))\n",
    "    print('MAE for val data: {}'.format(mean_absolute_error([i['nHelpful'] for i in y_val_raw], y_pred)))\n",
    "    print('Difference from baseline: {}'.format(baseline_mae-feature_mae))\n",
    "    print('\\n')\n",
    "    \n",
    "    # keep features with lower MAE than baseline\n",
    "    if feature_mae < baseline_mae:\n",
    "        features_tokeep.append(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
